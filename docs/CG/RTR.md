# Computer Graphics Note

《Real-time Rendering 4th Edition》读书笔记

## Chapter 1 - Introduction - 概述
> Real-time rendering is concerned with rapidly making images on the computer. <br>It is the most highly interactive area of computer graphics. 

### 什么是实时渲染
<strong>实时渲染（Real-time rendering）</strong>指的是在计算机上快速生成图像。它是计算机图形学中最具交互性的领域。首先一幅图像显示在屏幕上，然后观察者做出动作与反应，并且其动作反馈会影响接下来的生成内容。由于这种反馈、渲染的循环速度足够快，观察者就不会只看到独立的图像，而是会沉浸在这种动态过程中。

### 符号和定义 (Notation and Definitions)
<br>
<center><img width="70%" src="CG/RTR/1.png"/></center>
<center>书中使用的数学符号总结</center>

<br>
<center><img width="70%" src="CG/RTR/2.png"/></center>
<center>一些数学运算符的符号</center>

其中运算符8和9是限制（clamping）运算符，通常用于着色计算中。运算符8将负值限制为0：
<center><img width="24%" src="CG/RTR/3.png"/></center>

运算符9将值限制在0和1之间：
<center><img width="26%" src="CG/RTR/4.png"/></center>

第11个运算符，即二项式因子：
<center><img width="20%" src="CG/RTR/5.png"/></center>

<br>
<center><img width="70%" src="CG/RTR/6.png"/></center>
<center>一些特殊数学函数的符号</center>


## Chapter 2 - The Graphics Rendering Pipeline - 图形绘制流水线
> 实时渲染的核心是一系列变换步骤，这些步骤将场景的数学描述转换成我们能看到的东西（图像信息）

### 渲染管线
渲染管线的基本构造包括四个阶段：
- 应用程序阶段（application）
- 几何处理阶段（geometry processing）
- 光栅化阶段（rasterization）
- 像素处理阶段（pixel processing）

这些阶段中的每个阶段本身也可以是管线化或并行化的：
<br>
<center><img width="90%" src="CG/RTR/7.png"/></center>
<center>渲染管线的基本构造</center>

### 应用程序阶段（application）
应用程序阶段（application）由应用程序驱动，因此通常由在通用 CPU 上运行的软件实现。这些 CPU 通常包括多个内核，这些内核能够并行处理多个线程。这使 CPU 可以有效地运行应用程序阶段负责的各种任务。传统上通常在 CPU 执行包括碰撞检测、全局加速算法、动画、物理模拟还有许多其他任务，任务具体取决于应用程序的类型。

在应用程序阶段结束时，要渲染的几何图形被移交到几何处理阶段。因为此阶段是基于软件的实现，所以它不像几何处理阶段、光栅化阶段和像素处理阶段那样能够划分为多个子阶段（从而提升处理效率）。但是，为了提高性能表现，应用程序阶段通常会在多个处理器核心上并行执行。在CPU设计中，这被称为超标量构造（superscalar construction），因为它能在同一阶段同时执行多个进程。

### 几何处理阶段（geometry processing）
此阶段会处理变换，投影以及所有其他类型的几何处理。另外，此阶段会计算所需要绘制的内容，并判断应如何绘制以及应在何处绘制。几何处理阶段通常在包含许多可编程内核以及固定操作硬件的图形处理单元（GPU）上执行。
GPU 上的几何处理阶段（Geometry Processing）负责大部分的逐三角形和逐顶点的操作。该阶段进一步分为以下功能阶段（functional stages）：
- 顶点着色（vertex shading）
- 投影（projection）
- 裁剪（clipping）
- 屏幕映射（screen mapping）
<br>
<center><img width="90%" src="CG/RTR/8.png"/></center>
<center>几何处理阶段中的渲染管线</center>

### 光栅化阶段（rasterization）
此阶段通常会依次将三个顶点输入，形成三角形，然后找到该三角形内所有需要计算的像素，将它们发送到下一个阶段。我们称这种过程为光栅化，它被分为两个功能子阶段：三角形设置（triangle setup，也称为基本装配）和三角形遍历（triangle traversal）：
<center><img width="70%" src="CG/RTR/9.png"/></center>
<center>光栅化的两个阶段</center>

#### 三角形设置（triangle setup，也称为基本装配）
在这一阶段，计算了三角形的微分、边缘方程和其他数据。 这些数据可用于三角形遍历以及几何阶段产生的各种着色数据的插值。

#### 三角形遍历（triangle traversal）
这个阶段将检查每个像素（或样本）中心被三角形覆盖的情况，并为与三角形重叠的像素部分生成一个片元（fragment）。

### 像素处理阶段（pixel processing）
在此阶段，经过之前所有阶段的处理，已经找到了在三角形或其他图元内部应考虑的所有像素，于是此阶段为每个像素执行一段程序以确定其颜色，并可以进行深度测试，以判断该像素是否可见。它还可以对每个像素进行其他操作，例如将新计算的颜色与之前的颜色混合。光栅化和像素处理阶段都是完全在 GPU 上进行处理。


## Chapter 3 - The Graphics Processing Unit - 图形处理单元
> 现代GPU使用固定功能和可编程单元的组合来实现渲染管线(Rendering Pipeline)的各个阶段

专用图形硬件相对于CPU的唯一优势是计算速度，但速度至关重要。GPU通过专注于一组高度可并行化的任务而获得了卓越的速度。在过去的二十年中，图形硬件经历了不可思议的转变。

### 数据并行架构 (Data-Parallel Architectures)
<strong>延迟（latency）</strong>是所有处理器都面临的问题。访问数据需要花费一些时间。考虑延迟长短的一种基本方法是，信息所处位置离处理器越远，等待时间就越长。

不同的处理器体系结构使用各种策略来避免延迟。

一个CPU可以包含多个处理器，但是每个处理器都以串行方式运行代码，为了最大程度地减少延迟，许多CPU芯片都由快速本地缓存组成，这些缓存中填充了下一步可能需要的数据。CPU还通过使用诸如<strong>分支预测（branch prediction），指令重新排序（instruction reordering），寄存器重命名（register renaming）和缓存预取（cache prefetching ）</strong>之类的巧妙技术来避免停顿。

GPU采用不同的方法避免延迟。GPU的大部分芯片区域专用于称为<strong>着色器核心（shader cores）</strong>的大量处理器，通常数量多达数千个。GPU是流处理器，其中依次处理相似数据的有序集合。由于这种相似性（例如，一组顶点或像素），GPU可以大规模并行地处理这些数据。另一个重要的部分是这些调用要尽可能地独立，这样它们就不需要来自相邻调用的信息，并且不共享可写的存储位置。有时我们会打破该规则来实现新的功能，但是代价是潜在的延迟，因为一个处理器可能会等待另一个处理器完成其工作。

GPU针对吞吐量（throughput）进行了优化，吞吐量定义为可以处理数据的最大速率。但是，这种快速处理具有成本，由于专用于高速缓存存储器和控制逻辑的芯片面积较小，因此每个着色器内核的等待时间通常比CPU处理器遇到的等待时间长得多。

假设网格已光栅化，并且我们现在有2000个要处理的片元（fragments），像素着色器程序将被调用2000次。想象现在我们只有一个处理器，这是世界上最弱的GPU。它开始为2000个片元的第一个片元执行着色器程序。着色器处理器对寄存器中的值执行一些算术运算。寄存器是本地的，可以快速访问，因此不会发生停顿。然后，着色器处理器会执行一条指令，例如纹理访问。由于纹理是一个完全独立的资源，而不是像素程序本地内存的一部分，所以内存提取可能需要数百到数千个时钟周期，在此期间GPU处理器不执行任何操作。<strong>此时，着色器处理器将停止运行，等待纹理的颜色值返回。</strong>

为了缓解这种情况，我们为每个片元提供一些用于其本地寄存器的存储空间。现在，允许着色器处理器切换并执行另一个片元，而不是在采样纹理期间停下来。切换的速度非常快，现在执行第二个片元，与第一个相同，执行一些算术函数，然后再次遇到纹理获取。着色器核心现在再次切换到另一个片元，即第三个片元。最终，所有两千个片元都以这种方式处理。此时，着色器处理器将返回片元一，此时纹理颜色已被获取并且可以使用，因此着色器程序可以继续执行。处理器以相同的方式进行处理，直到遇到另一个已知会暂停执行的指令，或者程序完成。与着色器处理器（shader processor）始终专注于一个片元相比，执行单个片元所需的时间更长，但是整个片元的总体执行时间将大大减少。

在这种架构中，通过切换到另一个片元使GPU保持忙碌来隐藏延迟。GPU通过将指令执行逻辑与数据分离开来，使该设计更进一步。称为<strong>单指令多数据（SIMD，single instruction, multiple data）</strong>的这种安排可以在固定数量的着色器程序上以锁定步骤执行同一命令。SIMD的优点是，与使用单独的逻辑和调度单元运行每个程序相比，用于处理数据和交换的硅（和功率）要少得多。将我们的2000片元示例转换为现代GPU术语，每个片元的像素着色器调用都称为线程。这种类型的线程与CPU线程不同。它由用于着色器输入值的一点内存以及着色器执行所需的任何寄存器空间组成。使用相同着色器程序的线程被分为几组，被NVIDIA称为<strong>warp</strong>，被AMD称为<strong>wavefronts</strong>。一个 warp/wavefront 被 计划用于SIMD处理，由8至64之间的任意数量的GPU着色器内核执行。每个线程都映射到SIMD通道。

假设我们有两千个线程要执行。NVIDIA GPU的 warps 包含32个线程。这将产生2000/32 = 62.5个 warps，这意味着分配了63个warps，其中一个 warps 是一半为空。warp 的执行类似于我们的单个GPU处理器示例。着色器程序在所有32个处理器上以固定步骤执行。因为对所有线程执行相同的指令，遇到内存提取时，所有线程都会同时遇到它。提取信号表明线程warp将停止，所有线程都在等待它们的（不同的）结果。此时不会停顿，而是将warp换成32个线程的另一个warp，然后由32个内核执行。这种交换的速度与我们的单处理器系统一样快，因为在将warp换入或换出时，每个线程内的数据都不会被触及。每个线程都有自己的寄存器，每个warp都跟踪其正在执行的指令。交换新线程只是将一组核心指向另一组要执行的线程即可。没有其他开销。warp执行或换出，直到全部完成。

<center><img width="70%" src="CG/RTR/10.png"/></center>
<center>简化的着色器执行示例</center>

与每个线程相关联的着色器程序所需的寄存器越多，则线程中可以驻留的线程越少，因此warp也就越少。warps 不足可能意味着无法通过交换来减轻失速。驻留的 warps 被称为“飞行中”（in flight），这个数字称为占用率（occupancy）。高占用率意味着有许多可用于处理的 warp，因此空闲处理器的可能性较小。占用率低通常会导致性能不佳。

影响整体效率的另一个因素是由“if”语句和循环引起的动态分支。假设在着色器程序中遇到 “if” 语句。如果所有线程求值并采用同一分支，则warp可以继续进行而不必担心其他分支。但是，如果某些线程甚至一个线程采用了替代路径，那么warp必须执行两个分支，从而丢弃每个特定线程不需要的结果。这个问题称为<strong>线程发散（thread divergence）</strong>，其中一些线程可能需要执行循环迭代或执行warp中其他线程不执行的 “if” 路径，从而使它们在此期间处于空闲状态。

### GPU管线概述 (GPU Pipeline Overview)
GPU实现了第2章中描述的概念如几何处理，光栅化和像素处理管线阶段。这些阶段分为几个硬件阶段，这些阶段具有不同程度的可配置性或可编程性。

这些阶段根据用户对其操作的控制程度进行颜色编码。绿色阶段是完全可编程的。虚线表示可选阶段。黄色阶段是可配置的，但不是可编程的，例如，可以为合并阶段设置各种混合模式。蓝色阶段的功能完全固定。

<center><img width="80%" src="CG/RTR/11.png"/></center>
<center>渲染管线的GPU实现</center>

随着时间的流逝，GPU管道已从硬编码操作阶段演变到增加灵活性和控制能力的阶段。可编程着色器阶段的引入是这一发展过程中最重要的一步。

### 可编程着色器阶段 (The Programmable Shader Stage)
现代着色器程序使用统一的着色器设计。这意味着与顶点，像素，几何和曲面细分相关的着色器共享一个公共的编程模型。在内部，它们具有相同的<strong>指令集体系结构（ISA，instruction set architecture）</strong>。实现此模型的处理器在 DirectX 中称为“通用着色器核心”（common-shader core）。

着色器使用类似C的<strong>着色语言（shading languages）</strong>进行编程，例如DirectX的高级着色语言（HLSL，High-Level Shading Language）和OpenGL着色语言（GLSL，OpenGL Shading Language）。DirectX 的 HLSL 可以编译为虚拟机字节码，也称为中间语言（IL或DXIL），以提供硬件独立性。中间表示还可以允许着色器程序被编译和离线存储。驱动程序将此中间语言转换为特定GPU的ISA。

一次 Draw Call 调用图形API来绘制一组图元（primitives），从而使图形管线执行并运行其着色器（shaders）。每个可编程着色器阶段都有<strong>两种类型的输入</strong>：

- <strong>uniform inputs</strong>: 其值在整个绘制调用期间保持不变（但可以在绘制调用之间进行更改）；
- <strong>varying inputs</strong>: 即来自三角形顶点或光栅化的数据。例如，纹理或任何大型数据数组。

基础虚拟机（The underlying virtual machine）为不同类型的输入和输出提供特殊的寄存器。用于uniforms的可用寄存器的数量比用于varying的输入或输出的可用寄存器的数量多得多。

<center><img width="70%" src="CG/RTR/12.png"/></center>
<center>Shader Model 4.0下的统一虚拟机体系结构和寄存器布局</center>

### 流控制（flow control）
术语<strong>“流控制”（flow control）</strong>是指使用分支指令来更改代码执行流。

与流控制相关的指令用于实现高级语言构造，例如“if”和“ case”语句，以及各种类型的循环。着色器支持两种类型的流控制。

<strong>静态流控制（Static flflow control）</strong>分支基于统一输入的值。这意味着代码流在绘图调用中是恒定的。静态流控制的主要好处是允许将相同的着色器用于各种不同的情况（例如，不同数量的灯光）。由于所有调用都采用相同的代码路径，因此没有线程差异。

<strong>动态流控制（Dynamic flflow control）</strong>基于变化的输入的值，这意味着每个片段可以不同地执行代码。这比静态流控制功能强大得多，但会降低性能，尤其是在着色器调用之间代码流发生不规则变化时。

### 顶点着色器 (Vertex Shader)
顶点着色器是处理三角形网格的第一阶段，顶点着色器提供了一种修改、创建或忽略与每个三角形的顶点关联的值的方法，例如其颜色、法线、纹理坐标和位置。通常，顶点着色器程序会将顶点从模型空间转换为<strong>齐次裁剪空间（homogeneous clip space）</strong>。顶点着色器至少必须始终输出此位置。

顶点着色器的输出将发送到像素着色器程序以进行继续处理。在某些GPU上，数据也可以发送到细分阶段或几何着色器，或存储在内存中。

### 曲面细分阶段 (The Tessellation Stage)
细分阶段允许我们渲染曲面，此阶段是可选的GPU功能，该功能首先在DirectX 11中可用，OpenGL4.0 和 OpenGL ES 3.2也支持该功能。

细分阶段由三个部分组成： DirectX中，它们是：外壳着色器（hull shader），细分（tessellator）和域着色器（domain shader）。在OpenGL中，外壳着色器对应曲面细分控制着色器（the tessellation control shader），而域着色器对应曲面细分评估着色器（tessellation evaluation shader）。

hull shader的输入是一个特殊的补丁图元（patch primitive）。它由几个控制点组成，这些控制点定义了细分曲面，例如Bezier曲面或其他类型的曲面元素。hull shader具有两个功能：首先，它告诉细分器应生成多少个三角形以及采用哪种配置。其次，它对每个控制点执行处理。同样，可选地，hull shader可以修改传入的patch数据，根据需要添加或删除控制点。

hull shader将细分因子（tessellation factors, TFs）和类型发送给固定功能细分器。控制点集由外壳着色器根据需要进行转换，并与TF和相关的修补程序常量一起发送到域着色器。曲面细分对象将创建一组顶点及其重心坐标。然后由域着色器对其进行处理，从而生成三角形网格（显示控制点以供参考）。

<center><img width="70%" src="CG/RTR/13.png"/></center>
<center>细分阶段</center>

### 几何着色器 (Geometry Shader)
几何着色器可以将图元转换为其他图元，而这在细分阶段是无法完成的。几何着色器是在2006年底随 DirectX 10 发行版添加到硬件加速的图形管道中的。它位于管道中的细分着色器之后，并且使用与否是可选的。OpenGL 3.2和OpenGL ES 3.2也支持这种类型的着色器。

几何着色器设计用于修改传入的数据或制作有限数量的副本（copies），几何着色器的行为是最不可预测的，因为它是完全可编程的。实际上，几何着色器通常用得很少，因为它无法很好地展现GPU的优势。在某些移动设备上，它是通过软件实现的，因此强烈建议不要使用它。

### 像素着色器 (Pixel Shader)
顶点，曲面细分和几何体着色器执行完操作后，便会裁剪并设置图元以进行光栅化，流水线的这一部分在其处理步骤中是相对固定的，即不是可编程的，但是高度可配置的。在OpenGL中，像素着色器称为片元着色器。

顶点着色器程序的输出实际上是像素着色器程序的输入，通常像素着色器会计算并输出片元的颜色，但它还可能会产生透明度值（opacity value），并可以选择修改z深度。像素着色器还具有丢弃传入片元（即不生成任何输出）的独特功能。

最初，像素着色器只能输出到合并阶段，以进行最终显示。随着时间的推移，像素着色器可以执行的指令数量已大大增加。于是出现了<strong>多目标渲染（multiple render targets，MRT）</strong>，这使得不仅可以将像素着色器程序的结果发送到颜色缓冲和z缓冲区，还可以为每个片元生成多组值并将其保存到不同的缓冲区，每个缓冲区称为<strong>渲染目标（render target）</strong>。

!> 一些架构要求渲染目标必须具有相同的位深，甚至可能具有相同的数据格式。取决于GPU，可用的渲染目标数量为四个或八个。

另一种类型的基于MRT的渲染管线被称为延迟着色（deferred shading），其中可见性和着色是在单独的通道（passes）中完成的。第一遍渲染存储有关每个像素处对象位置和材质的数据。然后，照明和其他效果在后续的passes中完成。

像素着色器的局限性在于，它通常只能在传递给目标的片元位置上写入渲染目标，而不能从相邻像素读取当前结果。也就是说，执行像素着色器程序时，它无法将其输出直接发送到相邻像素，也无法访问其他像素的最新更改。

像素着色器无法知道或影响相邻像素的结果的规则是有例外的。诸如纹理过滤之类的操作，因为我们想知道多少图像覆盖了一个像素，所有现代GPU都通过以2×2为一组处理片元（称为四边形）来实现此功能。当像素着色器请求梯度值时，将返回相邻片元之间的差异。

DirectX 11引入了一种缓冲区类型，该类型允许对任何位置（<strong>无序访问视图（unordered access view，UAV）</strong>）的写访问。这最初仅适用于像素和计算着色器，DirectX 11.1中对UAV的访问已扩展到的所有着色器。OpenGL 4.3将此称为<strong>着色器存储缓冲区对象（shader storage buffer object，SSBO）</strong>。像素着色器以任意顺序并行运行，并且此存储缓冲区在它们之间共享。

<center><img width="70%" src="CG/RTR/14.png"/></center>
<center>左侧为栅格化，每组2 × 2像素。右侧显示了像素的梯度计算过程</center>

### 合并阶段 (Merging Stage)
合并阶段是将各个片段（在像素着色器中生成）的深度和颜色与帧缓冲区组合在一起的阶段。DirectX将此阶段称为输出合并（output merger）； OpenGL将其称为逐样本操作（per-sample operations）。

在大多数传统管线上，此阶段是模板缓冲区（stencil-buffer）和z缓冲区（z-buffer）操作发生的地方。如果片元可见，则此阶段中发生的另一种操作是颜色混合。

想象一下，通过光栅化生成的片元通过像素着色器运行，然后在应用z缓冲区时被某些先前渲染的片元隐藏。这样就不需要在像素着色器中进行所有处理。为了避免这种浪费，许多GPU在执行像素着色器之前执行一些合并测试。片元的z深度用于测试可见性。如果隐藏该片元，则将其剔除。此功能称为 Early-z。

合并阶段占据了固定功能阶段（例如三角形设置）和完全可编程着色器阶段之间的中间地带。尽管它不是可编程的，但它的操作是高度可配置的。可以将颜色混合设置为执行大量不同的操作。最常见的是涉及颜色和Alpha值的乘法，加法和减法的组合，但是其他操作（例如最小值和最大值）以及按位逻辑运算也是可能的。

### 计算着色器 (Compute Shader)
除了实现传统的图形管线外，GPU还可以用于更多用途。在计算领域，有许多非图形用途，例如计算股票期权的估计价值和训练用于深度学习的神经网络。以这种方式使用硬件称为GPU计算。诸如 CUDA 和 OpenCL 之类的平台可作为大型并行处理器来控制 GPU，而无需真正的需求或访问特定于图形的功能。这些框架通常使用带有扩展功能的 C 或 C++ 等语言以及为 GPU 制作的库。

DirectX 11中引入了计算着色器，它是GPU计算的一种形式，因为它是未锁定在图形管线中某个位置的着色器。它与渲染过程紧密相关，因为它由图形API调用。它与顶点，像素和其他着色器一起使用。它使用与管道中使用的统一着色器处理器池相同的池。与其他着色器一样，它是着色器，因为它具有一组输入数据，并且可以访问缓冲区（例如纹理）以进行输入和输出。

每个调用都会获取一个可以访问的线程索引。还有一个线程组的概念，它由DirectX 11中的1到1024个线程组成。这些线程组由x，y和z坐标指定，主要是为了简化在着色器代码中的使用。每个线程组都有少量的内存，这些内存在线程之间共享。在DirectX 11中，这等于32 kB。计算着色器由线程组执行，因此保证该组中的所有线程可以同时运行。

!> 计算着色器的一个重要优点是它们可以访问在GPU上生成的数据。需要注意的是，从 GPU 向 CPU 发送数据会产生延迟。


## Chapter 4 - Transforms - 变换
> 操纵对象的位置、方向、大小、形状，相机的位置和视图的基本工具

变换（transform）是一种操作，它接受点（points），向量（vectors）或颜色（colors）之类的实体（entities），并且以某种方式变换它们。

#### 线性变换（linear transform）
线性变换（linear transform）是保留向量加法和标量乘法的变换：

<center><img width="20%" src="CG/RTR/15.png"/></center>

#### 仿射变换（affine transform）
仿射变换（affine transform）将线性变换（linear transforms）和平移（translations）结合起来，仿射变换通常存储为4 × 4矩阵。仿射变换是先执行线性变换然后执行平移变换。

所有平移（translation），旋转（rotation），缩放（scaling），反射（reflflection）和剪切矩阵（shearing matrices）都是仿射（affine）。仿射矩阵（affine matrix）的主要特征就是它保留了线的平行性，但不一定保留长度和角度。仿射变换（affine transform）也可以是各个仿射变换级联（concatenations）的任何序列。

### 基本变换 (Basic Transforms)
<br>
<center><img width="80%" src="CG/RTR/16.png"/></center>
<center>各种变换的小结</center>

#### 平移 (Translation)
从一个位置到另一个位置的变化由平移矩阵<strong>T</strong>表示。此矩阵通过向量  去平移实体。

<center><img width="36%" src="CG/RTR/17.png"/></center>

#### 旋转 (Rotation)
旋转变换将一个向量（位置或方向）绕经过原点的给定轴旋转指定的角度。像平移矩阵一样，它是一个刚体变换（rigid-body transform），换句话说，它保留了变换后的点之间的距离，并保留了惯用性（handedness）（即从不导致左右两侧互换）。在计算机图形学中，这两种类型的变换对于定位和定向对象显然很有用。方向矩阵（orientation matrix）是与摄像机视图（camera view）或对象相关联的旋转矩阵，它定义了其在空间中的方向，即其向上和向前的方向。

绕X，Y和Z轴旋转实体的矩阵如下：

<center><img width="30%" src="CG/RTR/18.png"/></center>

如果从4 × 4矩阵中删除最底行和最右列，则将获得 3 × 3 矩阵。对于每个绕任意轴旋转phi弧度的3 × 3矩阵<strong>R</strong>，它的迹（trace，矩阵中对角元素的总和）与轴无关，是恒定的，计算公式为：tr(<strong>R</strong>) = 1 + 2cos(phi)。

所有旋转矩阵的行列式（determinant）均为 1，并且是正交的（orthogonal）。这对于任意数量的这些变换的级联（concatenations）也成立。还有另一种求逆的方法：R^-1(phi) = R(-phi)，即绕同一轴沿相反方向旋转。

#### 缩放 (Scaling)
缩放矩阵S，分别沿x，y和z方向按s_x，s_y和s_z的缩放因子去缩放实体。

<center><img width="26%" src="CG/RTR/19.png"/></center>

如果 s_x=s_y=s_z，则缩放操作称为统一操作（uniform），否则称为非统一操作（nonuniform）。

进行反缩放有两种方法：
第一种是求逆：
<center><img width="26%" src="CG/RTR/20.png"/></center>

第二种是使用齐次坐标，并在每次使用矩阵S之前进行归一化：
<center><img width="50%" src="CG/RTR/21.png"/></center>

#### 剪切 (Shearing)
剪切矩阵可以用于扭曲游戏中整个场景，以产生迷幻效果或扭曲模型的外观。剪切矩阵的第一个下标用于表示剪切矩阵正在更改哪个坐标，而第二个下标表示进行剪切的坐标：
<center><img width="26%" src="CG/RTR/22.png"/></center>
<center><img width="80%" src="CG/RTR/23.png"/></center>

### 级联变换 (Concatenation of Transforms)
由于矩阵上乘法运算的不可交换性，因此矩阵出现的顺序很重要。因此，变换的级联被认为是顺序相关的：

<center><img width="80%" src="CG/RTR/24.png"/></center>

将一系列矩阵的连接转换为单个矩阵的明显原因是为了提高效率。例如，假设你的游戏场景具有数百万个顶点，并且场景中的所有对象都必须缩放，旋转并最终平移。现在，不是将所有顶点与这三个矩阵中的每一个相乘，而是将这三个矩阵连接到一个矩阵中。然后将此单个矩阵应用于顶点。该复合矩阵为M = TRS。

注意这里的顺序。比例矩阵S应该首先应用于顶点，因此在合成中显示在右侧。该排序意味着TRSp = (T(R(Sp)))，其中p是要变换的点。顺便说一句，TRS是场景图系统（scene graph systems）常用的顺序。

### 刚体变换 (Rigid-Body Transform)
当一个人抓住一个坚固的物体时，例如从桌子上用笔将其移动到另一个位置，也许移动到衬衫的口袋里，只有物体的方向和位置会发生变化，而物体的形状通常不会受到影响。这种仅由平移和旋转的级联组成的变换称为刚体变换。

可以将任何刚体矩阵X表示为平移矩阵T(t)和旋转矩阵R的串联：

<center><img width="30%" src="CG/RTR/25.png"/></center>

#### LookAt矩阵
计算机图形中的常见任务是调整相机的方向，使其对准特定位置。

假设照相机位于c处，我们希望照相机看着目标l，并且照相机的给定方向为u'。我们要计算一个由三个向量{r,u,v}组成的基数。我们从计算视点向量为v=(c-1)/||c-1||开始，即从目标到摄像机位置的归一化向量。然后可以将向右看的向量计算为r=-(v×u')/||v×u'||。通常不能保证u'向量指向正上方，因此最终的向上向量是另一个叉积u=v×r。

<center><img width="70%" src="CG/RTR/26.png"/></center>

### 法线变换 (Normal Transform)
单个矩阵可用于一致地变换点，线，三角形和其他几何形状。矩阵还可以沿这些线或在三角形的曲面上变换切向量。但是，矩阵不能始终用于变换一个重要的几何特性，即表面法线（和顶点照明法线）。

下图左侧是原始几何图形，三角形以及从侧面显示的法线。中间的插图显示了如果模型沿 x 轴缩放 0.5，法线使用相同的矩阵会发生什么。右图显示了法线的正确变换：

<center><img width="70%" src="CG/RTR/27.png"/></center>

适当的方法不是使用矩阵本身相乘，而是使用矩阵的伴随项的转置相乘。

### 逆的计算 (Computation of Inverses)
在许多情况下都需要逆（inverses）。例如在坐标系之间来回切换时， 根据有关变换的可用信息，我们可以使用以下三种方法之一来计算矩阵的逆：
- 如果矩阵是单个变换或具有给定参数的简单变换序列，则该矩阵可以通过“反转参数”和矩阵顺序轻松地计算。举个例子，如果M=T(t)R(phi)，则M^(-1)=R(-phi)T(-t)。这很简单，并且保留了变换的准确性，这在渲染大世界时很重要。
- 如果已知矩阵是正交的，则M^(-1)=M^T，即转置为逆。旋转的任何序列都是旋转，因此是正交的。
- 如果没有任何已知条件，则可以使用伴随方法（the adjoint method），克莱姆法则（Cramer’s rule），LU分解（LU decomposition）或高斯消除法（Gaussian elimination）来计算逆。通常最好使用克莱姆法则和伴随方法，因为它们的分支操作较少； 在现代体系结构上最好避免使用“if”测试。

### 特殊矩阵变换与运算 (Special Matrix Transforms and Operations)
#### 欧拉变换 (The Euler Transform)
这种变换是构造矩阵以将自己（即相机）或任何其他实体定向到某个方向的一种直观方法。它的名字来自伟大的瑞士数学家莱昂哈德·欧拉（Leonhard Euler，1707–1783年）。

欧拉变换是三个矩阵的乘积，矩阵的顺序可以以24种不同的方式选择，这可以通过选择矩阵的顺序来实现。

由于E是旋转的串联，因此它也显然是正交的。因此，它的逆可以表示为E^(-1)=E^T=(R_zR_xR_y)^T=(R_x)^T(R_y)^T(R_z)^T，当然，直接使用E的转置会更容易。

欧拉角 ， 和  分别表示 head，pitch 和 roll 应按其顺序旋转以及绕其各自的轴旋转多少。有时，所有角度都称为“rolls”，例如，我们的“head”为“ y-roll”，而我们的“pitch”为“ x-roll”。另外，“head”有时也称为“yaw”，例如在飞行模拟中。

<center><img width="50%" src="CG/RTR/28.png"/></center>
<center>欧拉变换及其与更改 head，pitch 和 roll 的方式之间的关系</center>

#### 从欧拉变换中提取参数 (Extracting Parameters from the Euler Transform)
在某些情况下，使用从正交矩阵中提取欧拉参数 h，p 和 r 的过程很有用：

<center><img width="50%" src="CG/RTR/29.png"/></center>

将三个旋转矩阵串联起来：

<center><img width="90%" src="CG/RTR/30.png"/></center>

由此可见，pitch 参数由 sin(p)=e_21 给出。同样，将 e_01 除以 e_11，并类似地将 e_20 除以 e_22，会产生以下用于 head 和 roll 参数的提取公式：

<center><img width="60%" src="CG/RTR/31.png"/></center>

因此，如下所示，使用函数 atan2（y，x）从矩阵E提取欧拉参数h（head），p（pitch）和r（roll）：

<center><img width="20%" src="CG/RTR/32.png"/></center>

由于p不影响第一列中的值，因此当cos(p)=0时，我们可以使用sin(r)/cos(r)=tan(r)=e_10/e_00，得出r=atan2(e_01,e_00)。

!>根据反正弦的定义，-pi/2≤p≤pi/2，这意味着如果使用该间隔之外的p值创建E，则无法提取原始参数，因为h，p 和 r 不是唯一的。

!>使用欧拉变换时，可能会发生万向节死锁（gimbal lock），也就是旋转时，会失去一个自由度。举个例子，变换的顺序是 x/y/z。假设第二次旋转我们绕 y 轴旋转 pi/2，这样会旋转局部 z 轴以使其与原始 x 轴对齐，因此围绕 z 的最终旋转是不正确的。

#### 矩阵分解 (Matrix Decomposition)
到目前为止，我们一直在假设我们知道所使用的变换矩阵的初始状态和历史记录的情况下进行工作。通常情况下并非如此。例如，仅连接的矩阵可以与某个变换后的对象相关联。从级联矩阵中提取各种变换的任务称为<strong>矩阵分解（matrix decomposition）</strong>。

提取变换的原因有很多。用途包括：

- 为对象提取比例因子。
- 查找特定系统所需的变换。（例如，某些系统可能不允许使用任意 4×4 矩阵）
- 确定模型是否仅经历了刚体变换。
- 在动画中的关键帧之间进行插值，其中仅对象的矩阵可用。
- 从旋转矩阵中删除剪切。

#### 绕任意轴旋转 (Rotation about an Arbitrary Axis)
假设旋转轴 r 已归一化，并且我们需要创建一个围绕 e 旋转 alpha 弧度的变换。为此，我们首先变换到旋转轴所在的空间，这是通过一个 M 旋转矩阵完成的，然后执行实际的旋转，之后使用 M^-1 进行变换。

<center><img width="13%" src="CG/RTR/33.png"/></center>

该矩阵将向量 r 变换为 x 轴，将 s 变换为 y 轴，将 t 变换为 z 轴。因此，然后使围绕标准化向量 r 旋转 alpha 弧度的最终变换为：

<center><img width="20%" src="CG/RTR/34.png"/></center>

换句话说，这意味着首先我们进行变换，使 r 为 x 轴（使用 M），然后围绕该 x 轴旋转 alpha 弧度（使用 R_x(alpha)），然后使用 M 的逆函数进行变换 ，在这种情况下为 M^T，因为 M 是正交的。

Goldman提出了另一种通过 phi 弧度绕任意归一化轴 r 旋转的方法：

<center><img width="90%" src="CG/RTR/35.png"/></center>

### 四元数 (Quaternions)
四元数是复数的扩展，尽管它是威廉·罗恩·汉密尔顿爵士（Sir William Rowan Hamilton）于1843年发明的，但直到1985年，Shoemake才将它们引入计算机图形学领域。

>四元数用于表示旋转和方向。它们在几种方面都优于欧拉角和矩阵。任何三维定向都可以表示为围绕特定轴的单个旋转。四元数可用于稳定方向和恒定插值，而欧拉角无法很好地完成这些操作。

#### 数学背景 Mathematical Background
#### 定义
四元数q可以用以下所有等效的方式定义：

<center><img width="60%" src="CG/RTR/36.png"/></center>

变量q_w被称为四元数q的实部（real part）。虚部（imaginary part）为q_v，i，j和k称为虚单位（imaginary units）。
对于虚部q，我们可以使用所有法向向量运算，例如加法，缩放，点积，叉积等等。使用四元数的定义，得出两个四元数q和r之间的乘法运算，如下所示。注意，虚部的乘法是不可交换的。

#### 乘法（Multiplication）
我们使用叉积和点积来计算两个四元数的乘法:

<center><img width="50%" src="CG/RTR/37.png"/></center>

#### 加法（Addition）

<center><img width="50%" src="CG/RTR/38.png"/></center>

#### 共轭（Conjugate）

<center><img width="30%" src="CG/RTR/39.png"/></center>


#### 归一化（Norm）

<center><img width="40%" src="CG/RTR/40.png"/></center>


#### 恒等式（Identity）

<center><img width="13%" src="CG/RTR/41.png"/></center>

#### 逆（Inverse）

<center><img width="18%" src="CG/RTR/42.png"/></center>

#### 共轭规则（Conjugate rules）

<center><img width="20%" src="CG/RTR/43.png"/></center>


#### 归一化规则（Norm rules）

<center><img width="20%" src="CG/RTR/44.png"/></center>

#### 乘法定律（Laws of Multiplication）- 线性度（Linearity）

<center><img width="26%" src="CG/RTR/45.png"/></center>

#### 乘法定律（Laws of Multiplication）- 关联性（Associativity）

<center><img width="16%" src="CG/RTR/46.png"/></center>

#### 对数运算

<center><img width="30%" src="CG/RTR/47.png"/></center>

#### 幂运算

<center><img width="60%" src="CG/RTR/48.png"/></center>

#### 四元数变换 (Quaternion Transforms)

<center><img width="30%" src="CG/RTR/49.png"/></center>
<center>由单位四元数<img width="20%" src="CG/RTR/50.png"/>表示的旋转变换</center>

q的任何非零实数倍也表示相同的变换，这意味着q和-q表示相同的旋转。也就是说，取反轴u_q和实部q_w，将生成一个四元数，该四元数的旋转与原始四元数的旋转完全相同。这也意味着从矩阵中提取四元数可以返回q或 -q。

#### 矩阵转换（Matrix Conversion）
由于通常需要组合几个不同的变换，并且大多数变换都是矩阵形式，因此需要一种将四元数转换为矩阵的方法。四元数 q可以转换成矩阵M^q：

<center><img width="55%" src="CG/RTR/51.png"/></center>

在此，标量为 s=2/(nq)。对于单位四元数，这简化为：

<center><img width="55%" src="CG/RTR/52.png"/></center>

一旦构建了四元数，就无需计算三角函数（trigonometric functions），因此转换过程实际上是有效的。

从正交矩阵M^q到单位四元数q的反向转换要复杂得多：

<center><img width="20%" src="CG/RTR/53.png"/></center>

这些等式的含义是，如果q_w是已知的，则可以计算向量v_q的值，从而得出q：

<center><img width="55%" src="CG/RTR/54.png"/></center>

<center><img width="40%" src="CG/RTR/55.png"/></center>

为了具有稳定的数值，应该避免小数除法。因此，首先设置<img width="20%" src="CG/RTR/56.png"/>，由此得出：

<center><img width="40%" src="CG/RTR/57.png"/></center>

这又意味着 m_00,m_11,m_22 和 u 中的最大值确定 q_x, q_y, q_z, 和 q_w 中的哪个最大。如果 q_w 不是最大，则使用下式计算q_x,q_y,q_z的最大值：

<center><img width="38%" src="CG/RTR/58.png"/></center>

#### 球面线性插值（Spherical Linear Interpolation）
球面线性插值是在给定两个单元四元数q和r以及参数t∈[0,1]的情况下，计算插值四元数。

该运算的代数形式由下面的复合四元数s表示：

<center><img width="20%" src="CG/RTR/59.png"/></center>

但是，对于软件实现，以下形式更合适：

<center><img width="60%" src="CG/RTR/60.png"/></center>

slerp 代表球面线性插值(spherical linear interpolation)，为了计算该方程式所需的phi，可以使用以下事实：

<center><img width="40%" src="CG/RTR/61.png"/></center>

对于t∈[0,1]，slerp 函数计算（唯一）内插四元数，它们共同构成从q到r的二维单位球面上的最短弧。圆弧位于由q,r和原点之间的平面与三维单位球面的交点形成的圆上。计算出的旋转四元数以固定速度绕固定轴旋转。这样的曲线具有恒定速度，因此加速度为零，称为<strong>测地曲线（geodesic curve）</strong>。球体上的大圆是通过原点和球体的平面相交而生成的，这种圆的一部分称为<strong>大圆弧（great arc）</strong>。

<center><img width="30%" src="CG/RTR/62.png"/></center>
<center>单位四元数表示为单位球面上的点。slerp函数用于在四元数之间进行插值，并且插值路径是球面上的大弧</center>

!> 实际上，直接计算一个 slerp 是昂贵的操作，因为它涉及调用三角函数（trigonometric functions）

#### 从一个向量旋转到另一个向量（Rotation from One Vector to Another）
常见的操作是通过最短路径从一个方向s转换到另一个方向t。四元数的数学极大地简化了此过程，并显示了四元数与该表示形式的密切关系。

首先，将s和t归一化。然后计算称为u的单位旋转轴，其计算公式为u=(s×t)/||s×t||。接下来，e=s·t=cos(2phi)和||s×t||=sin(2phi),其中2phi是s和t之间的角度。那么表示从s到t的旋转的四元数为q=(sin(phi u),cos(phi)),使用半角关系和三角恒等式简化：

<center><img width="30%" src="CG/RTR/63.png"/></center>
<center><img width="50%" src="CG/RTR/64.png"/></center>

当s和t指向几乎相同的方向时，以这种方式直接生成四元数（相对于叉积s×t的归一化）避免了数值不稳定。当s和t指向相反的方向时，这两种方法都会出现稳定性问题，因为它们会被零除。当检测到这种特殊情况时，可以使用任何垂直于s的旋转轴旋转到t。

有时我们需要从s到t旋转的矩阵表示：

<center><img width="50%" src="CG/RTR/65.png"/></center>

在此等式中，我们使用了以下中间计算（intermediate calculations）：

<center><img width="38%" src="CG/RTR/66.png"/></center>

可以看出，由于简化，所有平方根和三角函数都消失了，因此这是创建矩阵的有效方法。

请注意，当s和t平行或接近平行时必须小心，因为||s×t||≈0。如果phi≈0，那么我们可以返回单位矩阵。但是，如果2phi≈pi，那么我们可以绕任何轴旋转pi弧度。该轴可以作为s与不平行于s的任何其他向量之间的叉积找到。

#### 顶点混合 (Vertex Blending)
顶点混合（Vertex blending）是解决柔性形变问题的一种流行解决方案。该技术还有其他几个名称，例如线性混合蒙皮（linear-blend skinning），包络（enveloping）或骨架子空间变形（skeleton-subspace deformation）。

<center><img width="70%" src="CG/RTR/67.png"/></center>

上图中，手臂由前臂和上臂组成，使用左侧的两个独立对象的刚体变换进行动画处理。肘部看起来不现实。在右侧，对一个对象使用顶点混合。最右边的手臂说明了当简单的蒙皮将两个部分直接覆盖以覆盖肘部时发生的情况。最右边的手臂说明了使用顶点混合时发生的情况，并且某些顶点以不同的权重进行了混合：（2/3，1/3）表示顶点对上臂的变换的权重为2/3，对前臂的变换的权重为。1/3。该图在最右边的插图中还显示了顶点混合的缺点。在这里，可以看到肘部内部的折叠。使用更多的骨骼和更精心选择的权重可以达到更好的效果。

通过进一步执行这一步骤，可以使单个顶点可以通过几种不同的矩阵进行变换，并将得到的位置加权并混合到一起。这是通过为动画对象设置骨骼来完成的，其中每个骨骼的变换可能会通过用户定义的权重影响每个顶点。由于整个手臂可能是“弹性的”，即所有顶点可能受到多个矩阵的影响，因此整个网格（mesh）通常称为（骨骼上的）蒙皮（skin）。

在数学上，这用如下公式表示，其中p是原始顶点，而u(t)是变换后的顶点，其位置取决于时间t：

<center><img width="60%" src="CG/RTR/68.png"/></center>

有 n个骨骼影响p的位置，这在世界坐标中表示出来。值w_i是顶点p的骨骼i的权重。M_i矩阵从初始骨骼的坐标系转换为世界坐标。通常，骨骼的控制关节位于其坐标系的原点。例如，前臂骨骼将其肘关节移动到原点，而动画旋转矩阵将手臂的这一部分绕关节移动。B_i(t)矩阵是第i个骨骼的世界变换，会随着时间变化以对对象进行动画处理，并且通常是多个矩阵的串联，例如以前的骨骼变换的层次结构和局部动画矩阵。

在实践中，对于动画的每一帧，为每个骨骼连接矩阵B_i(t)和(M_i)^-1，并且每个结果矩阵都用于变换顶点。顶点P由不同骨骼的级联矩阵转换，然后使用权重W_i进行混合，因此称为顶点混合（vertex blending）。权重是非负的，并且总和为1，因此发生的事情是将顶点转换到几个位置，然后在其中进行插值。这样，对于所有的i=0...n-1，变换后的点u将位于点集B_i(t)·(M_i)^-1·p(固定的t)的凸包中。

顶点混合非常适合在 GPU 上使用。网格中的顶点集可以放置在静态缓冲区中，该缓冲区会一次发送到 GPU 并重新使用。在每个框架中，只有骨骼矩阵会发生变化，而顶点着色器会计算它们对存储的网格的影响。这样，可以最大程度地减少在 CPU 上处理和从 CPU 传输的数据量，从而使 GPU 可以有效地渲染网格。如果可以将模型的整个骨矩阵一起使用，则是最简单的。否则，必须拆分模型并复制一些骨骼。或者，可以将骨骼变换存储在顶点访问的纹理中，从而避免达到寄存器存储限制。通过使用四元数表示旋转，每个变换可以仅存储在两个纹理中。如果可用，无序访问视图存储将允许重新使用蒙皮结果。

> 我们可以指定超出 [0,1] 范围或不等于 1 的权重集。但是，这仅在使用某些其他混合算法（例如变形目标，morph targets）时才有意义。

!> 基本顶点融合的一个缺点是可能发生不必要的折叠，扭曲和自相交。更好的解决方案是使用四元数。

基于四元数的蒙皮技术有助于保持原始变换的刚度，因此避免了四肢关节的扭曲。计算量不到线性蒙皮混合的成本的 1.5倍，并且效果很好：

<center><img width="60%" src="CG/RTR/69.png"/></center>
<center>左侧显示了使用线性混合蒙皮时关节处的问题。在右侧，使用双四元数混合可以改善外观</center>

#### 变形 (Morphing)
变形（Morphing）涉及解决两个主要问题，即顶点对应问题（the vertex correspondence problem）和插值问题（the interpolation problem）。给定两个任意模型，这些模型可能具有不同的拓扑（topologies），不同的顶点数量和不同的网格连接性，通常必须从建立这些顶点对应关系开始，这是一个困难的问题。

但是，如果两个模型之间已经存在一对一的顶点对应关系，则可以在每个顶点的基础上进行插值。也就是说，对于第一个模型中的每个顶点，在第二个模型中必须仅存在一个顶点，反之亦然。这使插值变得容易。例如，线性插值可以直接在顶点上使用。

为了计算时间t∈[t0,t1]的变形顶点，我们首先计算s=(t-t0)/(t1-t0)，然后进行线性顶点混合：

<center><img width="20%" src="CG/RTR/70.png"/></center>

其中p0和p1对应于同一顶点，但是处在不同的时间t0和t1。

用户具有更直观控制的变形变体称为变形目标（morph targets）或混合形状（blend shapes）：

<center><img width="80%" src="CG/RTR/71.png"/></center>

我们从一个中性模型开始，在这种情况下，它是一张脸。让我们用 N 表示该模型。此外，我们还有一组不同的脸部姿势。在示例中只有一个姿势，即一张笑脸。通常我们可以允许 k≥1 个不同的姿势，表示为 P_i,i∈[1...k]。作为预处理，“差异面”的计算公式为：D_i=P_i-N，即，从每个姿势中减去中性模型。

在这一点上，我们有一个中性模型 N 和一组差异姿势 D_i。然后可以使用以下公式获得变形模型 M：

<center><img width="20%" src="CG/RTR/72.png"/></center>

变形目标（Morph targets）是一种强大的技术，可为动画师提供很多控制，因为模型的不同特征可以独立于其他特征进行操纵。

#### 几何缓存回放 (Geometry Cache Playback)
在剪辑场景（cut scenes）中，可能希望使用极高质量的动画，例如，对于无法使用上述任何方法表示的运动。天真的方法是存储所有帧的所有顶点，从磁盘读取它们并更新网格。但是，对于短动画中使用的 30,000 个顶点的简单模型，这可能达到50 MB / s。

首先，使用量化（quantization）。例如，位置和纹理坐标使用每个坐标的 16 位整数存储。在执行压缩后无法恢复原始数据的意义上，这一步骤是有损的。为了进一步减少数据，进行了空间和时间预测，并对差异进行了编码。对于空间压缩，可以使用平行四边形预测。对于三角形带（triangle strip），下一个顶点的预测位置就是当前三角形在边缘周围的三角形平面中反射的三角形，从而形成平行四边形（parallelogram）。与新位置的差异接下来会被编码（encoded）。有了良好的预测，大多数值将接近零，这对于许多常用的压缩方案是十分理想的。与 MPEG 压缩类似，在时间维度上也会进行预测。也就是说，每  帧执行一次空间压缩。在这两者之间，将在时间维度上进行预测，例如，如果某个特定顶点通过增量向量从帧  移动到帧 ，则很可能以与帧  相似的量移动。这些技术减少了存储量，从而足以使该系统用于实时流数据。

### 投影 (Projections)
在实际渲染场景之前，必须将场景中的所有相关对象投影到某种平面或某种简单体积上。此后，执行裁剪和渲染。

#### 正交投影 (Orthographic Projection)
正交投影的特征是平行线在投影之后保持平行。当使用正交投影观看场景时，无论与相机的距离如何，对象都保持相同的大小。

用于执行正交投影的矩阵由六元组 (l,r,b,t,n,f) 表示，分别表示左侧（left），右侧（right），底部（bottom），顶部（top），近侧（near）和远侧（far）平面。该矩阵缩放并将由这些平面形成的与轴对齐的边界框（axis-aligned bounding box, AABB）转换为以原点为中心的与轴对齐的立方体。AABB 的最小角为 (l,b,n)，最大角为
是 (r,t,f)。重要的是要意识到 n>f，因为我们正在向下看 z 轴的负空间。我们的常识是，接近值应该比远端值低，因此，可以让用户按原样提供它们，然后在内部对它们取反（negate）。

在 OpenGL 中，与轴对齐的立方体的最小角为(-1,-1,-1)，最大角为(1,1,1)。在 DirectX 中，范围是(-1,-1,0)到(1,1,1)。此立方体称为规范视图体（canonical view volume），而该体积中的坐标称为规范化设备坐标（normalized device coordinates）。变换为标准视图体积的原因是在此处能够更有效地执行裁剪（clipping）。

<center><img width="80%" src="CG/RTR/73.png"/></center>
<center>变换规范视图体（canonical view volume）上的轴对齐框（axis-aligned box）。首先平移左侧的框，使其中心与原点重合。然后将其缩放以获取规范视图体的大小，如右侧所示</center>

变换为标准视图体（canonical view volume）后，将要渲染的几何图形的顶点裁剪（clipped）到该立方体上。最后，通过将剩余的单位正方形映射到屏幕来渲染不在立方体之外的几何图形。此正交变换如下所示：

<center><img width="70%" src="CG/RTR/74.png"/></center>

在计算机图形学中，投影后最常使用左手坐标系（left-hand coordinate system），即对于视口，x 轴向右，y 轴向上，而 z 轴进入视口。

DirectX 将 z 深度（z-depth）映射到 [0,1] 范围，而不是OpenGL的 [-1,1]。这可以通过在正交矩阵之后应用简单的缩放和平移矩阵来实现，即

<center><img width="30%" src="CG/RTR/75.png"/></center>

因此，DirectX中使用的正交矩阵为:

<center><img width="40%" src="CG/RTR/76.png"/></center>

#### 透视投影 (Perspective Projection)
透视投影比正交投影更复杂的变换是透视投影，它通常在大多数计算机图形应用程序中使用。在这里，平行线在投影后通常不平行； 相反，它们可能会在极端情况下收敛到单个点。透视更紧密地匹配我们如何感知世界，即，更远的物体更小。

<center><img width="80%" src="CG/RTR/77.png"/></center>
<center>使用相似三角形导出透视投影矩阵（perspective projection matrix）</center>

假设摄像机（视点）位于原点，并且我们要将一个点 p 投影到平面 z=-d,d>0，从而产生一个新点 q=(q_x,q_y,-d) 。图4.19 描绘了这种情况。从该图所示的相似三角形中，得出 q 的 x 分量的以下推导：

<center><img width="25%" src="CG/RTR/78.png"/></center>

q 的其他分量的表达式为 q_y=-dp_y/p_z（类似于 q_x 获得），q_z=-d。与上面的公式一起，它们给出了透视投影矩阵 P_p，如下所示：

<center><img width="20%" src="CG/RTR/79.png"/></center>

该矩阵可产生正确的透视投影，可通过以下方式确认:

<center><img width="60%" src="CG/RTR/80.png"/></center>

最后一步来自以下事实：整个矢量除以 w 分量（在这种情况下为 -p_z/d），最后得到 1。由于我们要投影到该平面上，因此所得的  z 值始终为 -d。

从直觉上讲，很容易理解为什么齐次坐标允许投影。齐次化过程的一种几何解释是将点 (p_x, p_y, p_z) 投影到平面 w = 1 上。

与正交变换（orthographic transformation）一样，还有一个透视变换（perspective transform），而不是实际投影到平面（不可逆）上，而是将视锥从视锥变换为前述的规范视像体。在这里，视锥视点假定从z=n开始并在z=f结束，且0>n>f。z=n处的矩形的最小角为(l, b, n)，最大角为(r, t, n)。

<center><img width="80%" src="CG/RTR/81.png"/></center>
<center>矩阵 P_p 将视锥体（view frustum）转换为单位立方体，称为标准视域（canonical view volume）</center>

参数(l,r,b,t,n,f)确定摄像机的视锥（view frustum）。水平视野由视锥的左右平面（由l和r决定）之间的角度确定。以相同的方式，垂直视野由顶平面和底平面之间的角度（由t和b确定）确定。视野越大，相机“看得越多”。可以通过r≠-l或t≠-b来创建不对称视锥（Asymmetric frusta）。不对称视锥可用于立体观看（stereo viewing）和虚拟现实（virtual reality）。

视野（the field of view）是提供场景感的重要因素。与计算机屏幕相比，眼睛本身具有物理视野。这种关系是：phi=2arctan(w/2d),其中 \phi 是视野，w 是垂直于视线的物体的宽度，d 是到物体的距离。

与物理设置相比，使用更窄的视野将减少透视效果，因为观看者将放大场景。设置较宽的视野将使对象看起来失真（例如使用广角相机镜头），尤其是在屏幕边缘附近，并且会放大附近对象的比例。然而，较宽的视野使观看者感觉到物体更大并且更令人印象深刻，并且具有向用户提供有关周围环境的更多信息的优点。

<center><img width="30%" src="CG/RTR/82.png"/></center>
<center>将视锥转化为单位立方体的透视变换矩阵</center>

将转换应用到一个点后，我们将得到另一个点q=(q_x, q_y, q_z, q_w)^T。此时的 w 分量 q_w（通常）将为非零且不等于1。要获得投影点p，我们需要除以 q_w。矩阵 P_p 总是将 z=f 映射为 +1，z=n 映射为 -1。

远平面以外的对象将被裁切，因此不会出现在场景中。另外，透视投影可以令远平面取到无穷远：

<center><img width="30%" src="CG/RTR/83.png"/></center>

综上所述，应用透视变换（以任何形式）P_p，然后进行裁剪和齐次化（除以 w），从而得到标准化的设备坐标。

以下是 OpenGL 中的透视投影矩阵公式：

<center><img width="35%" src="CG/RTR/84.png"/></center>

一个更简单的设置是仅提供垂直视场 phi，宽高比 a=w/h（其中 w×h 是屏幕分辨率），n'和 f'，于是：

<center><img width="35%" src="CG/RTR/85.png"/></center>

这是 DirectX 公式(将近平面映射到 z=0（而不是 z=-1），而将远平面映射到 z=1)：

<center><img width="35%" src="CG/RTR/86.png"/></center>

!> 近平面和远平面的放置会影响 z 缓冲区的精度

#### 增加深度精度的方法
有几种增加深度精度的方法。一种常见的方法（我们称为反向 z， reversed z）是使用浮点深度或整数存储1.0-z_NDC。

<center><img width="80%" src="CG/RTR/87.png"/></center>

使用 DirectX 变换设置深度缓冲区的不同方法，即z_NDC∈[0,+1]。

左上方：标准整数深度缓冲区，此处显示为4位精度（因此 y 轴上有 16 个标记）。

右上角：远平面设置为 ∞，两个轴上的微小偏移表明这样做不会损失太多精度。

左下：具有3个指数位和 3 个尾数位用于浮点深度。由于分布在y轴上是非线性的，这使得在x轴上的分布更糟。

右下角：反转的浮点深度，即1-z_NDC，结果分布更好。

Lloyd提出使用深度值的对数来提高阴影贴图的精度。Lauritzen等使用前一帧的 z 缓冲区（z-buffer）来确定最大近平面和最小远平面。对于屏幕空间深度，Kemen建议对每个顶点使用以下重新映射：

<center><img width="50%" src="CG/RTR/88.png"/></center>

其中w是投影矩阵之后的顶点的 w 值，而 z 是顶点着色器的输出 z。常数 f_{c} 为 f_{c}=2/\textrm{log}_{2}(f+1)，其中 f 为远平面。当仅在顶点着色器中应用此变换时，深度仍将由 GPU 在顶点的非线性变换深度之间在三角形上线性插值。由于对数是单调函数，因此只要分段线性插值与精确的非线性变换深度值之间的差异较小，遮挡剔除硬件和深度压缩技术仍将起作用。在大多数情况下，具有足够的几何细分的情况是正确的。但是，也可以对每个片段应用转换。这是通过输出每个顶点的值 e=1+w 来完成的，然后由 GPU 在三角形上进行插值。然后，像素着色器将片段深度修改为 log^2(e_i)f_c/2，其中 e_i 是 e 的内插值。当 GPU 中没有浮点深度并且使用深度较大的距离进行渲染时，此方法是不错的选择。

Cozzi建议使用多视锥（multiple frusta），这可以提高准确度以有效地达到任何期望的比率。视锥在深度方向上分为几个不重叠的较小的子视锥，它们的联合恰好是视锥。子视锥表以从后到前的顺序渲染。首先，清除颜色和深度缓冲区，并将所有要渲染的对象分类到它们重叠的每个子视锥中。对于每个子视锥，设置其投影矩阵，清除深度缓冲区，然后渲染与子视锥重叠的对象。


## Chapter 5 - Shading Basics - 着色基础
> 无论是写实（realistic）还是风格化（stylized），我们都会先讨论材质和光源的定义，还有它们是如何呈现出我们期望的表面外观（appearance）。<br>此章节介绍一些表面外观相关的话题，例如通过抗锯齿（也称反走样，Antialiasing）、透明度(Transparency)、伽马校正（Gamma Correction）来提供更高质量的图像

渲染三维对象的图像时，模型不仅应具有适当的几何形状，而且还应具有所需的视觉外观。根据应用程序的不同，其范围可以从照片写实（外观与真实对象的照片几乎相同）到出于创造性原因选择的各种类型的风格化外观。

### 着色模型 (Shading Models)
决定渲染物体的外观的第一步是选择一个渲染模型（shading model）用来描述物体的颜色应该怎样变化，相关的因素有表面方向（surface orientation），视角方向（view direction），以及光照（lighting）等等。

### 光源 (Light Sources)
现实世界中的光照可能非常复杂，可以有多个光源，每个光源都有自己的大小，形状，颜色和强度，而且间接光照会带来更多变化。但实时渲染中通常我们只考虑有限数量个主要光源对表面着色的影响。

着色模型通常可以被拆解为亮部和暗部，光照强度k_light线性地改变亮部颜色：

<center><img width="40%" src="CG/RTR/89.png"/></center>

它可以被简单地扩展到多光源形式：

<center><img width="40%" src="CG/RTR/90.png"/></center>

无光照部分f_unlit将光视为二进制的着色模型的“不受光影响时的外观”。它可以具有各种形式，具体取决于所需的视觉效果和应用程序的需求。

<center><img width="60%" src="CG/RTR/91.png"/></center>
<center>大多数着色模型所使用的单位长度向量表示：表面法线n，视图向量v和光照方向l</center>

如果光照方向l与表面法线n的距离大于90°，则光源不会影响表面点，因此光照的计算结果通常需要被clamp到[0,1]范围。

### 实现着色模型 (Implementing Shading Models)
#### 计算频率 (Frequency of Evaluation)
当设计一个着色实现时，首先，要确定给出的计算结果是否总是在一个绘制调用（draw call）中保持恒定。例如：一个常量表达式，它的计算可能在着色器编译的时候就完成了，这种情况下甚至不需设置一个uniform着色器输入，用一个离线的预计算pass来计算这个常量即可。另一种情况是，着色计算的结果在应用程序执行时不断变化，但是这个变化很慢，以至于不需要在每一帧都进行更新。

其他情况下，每帧执行一次的计算，例如透视矩阵；或每个模型执行一次的计算，例如根据位置更新模型的光照参数；或每次绘制调用（draw call）执行一次的计算，例如更新模型中每种材质的参数等。基于计算频率，我们将uniform输入着色器分组，这样有助于提高应用程序的效率，并且还可以通过最小化常量更新（minimizing constant updates）来提高 GPU 的性能。

如果着色计算的结果在一个绘制调用中不断变化，那么它就不能由一个统一的着色器输入传到着色器中。取而代之的是，它必须在可编程着色阶段之一中被计算，并且如果需要的话，会通过不同的着色器输入传到其他阶段。理论上，着色计算能在任何一个可编程阶段上执行，其中每个都对应着不同的计算频率：
- 顶点着色器（Vertex shader） —— 计算每个曲面细分前的顶点
- 外壳着色器（Hull shader） —— 计算每个表面补丁
- 域着色器（Domain shader） —— 计算每个曲面细分后的顶点
- 几何着色器（Geometry shader）—— 计算每个图元
- 像素着色器（Pixel shader）—— 计算每个像素

大部分着色计算是逐像素执行的。尽管这些通常是在像素着色器中实现的，但是计算着色器的实现正变得越来越普遍。

原则上来说，可以在像素着色器中仅计算着色模型的镜面高光部分（specular highlight），而在顶点着色器中计算其余部分。这可能不会导致视觉伪像（visual artifacts），并且理论上将节省一些计算。然而在实践中，这种混合实现通常不是最佳的。着色模型的线性变化部分往往在计算上花费最少，并且以这种方式拆分着色计算往往会增加相当多的开销，例如重复计算和额外的变化输入，从而导致弊大于利。

!> 需要注意的是，即使顶点着色器总是生成单位长度表面法线，插值也是能改变其长度的。因此，法线需要在像素着色器中重新归一化（缩放至长度为 1）。

<center><img width="80%" src="CG/RTR/92.png"/></center>
<center>在左侧，我们看到跨越表面的单位法线的线性插值将导致插值后的向量长度小于1。在右侧，我们看到法线的线性插值有着明显不同的长度，这导致了插值后的方向朝着两个法线中较长的倾斜</center>

> 与表面法线不同，指向特殊位置的向量，例如视图向量（view vector）和精确光的光向量（light vector），通常是不进行插值的。取而代之的是，在像素着色器中插值后的表面位置将被用来计算这些向量。

<center><img width="80%" src="CG/RTR/93.png"/></center>
<center>两个光向量间的插值。在左侧，在插值前将它们归一化将导致归一化后方向不正确。在右侧，对未归一化向量插值，得到了正确的结果</center>

#### 平面着色 (flat shading)
原则上，可以在几何着色器中执行平面着色（flat shading），但是近年来相关的实现通常是使用顶点着色器。这是通过将每个图元的属性与其第一个顶点相关联并禁用顶点值插值来完成的。

> 禁用插值（可以为每个顶点值分别处理）将使得第一个顶点的值传递到图元中的所有像素。

#### 材质系统 (Material Systems)
渲染框架很少只实现单个着色器。通常来说，需要一个专用的系统来处理大量的材质，着色模型，以及应用程序所使用的着色器。

一个着色器是用于 GPU 的可编程着色阶段之一的一个程序。因此，着色器是低级的图形 API 资源，并且不是美术人员会直接接触的。相反，材质是面向美术人员封装的表面的视觉表现。

虽然材质通过着色器被实现，但这不是一个简单的一对一对应。在不同的渲染情况下，相同的材质可能使用不同的着色器。一个着色器也可能被多种材质共用。最普遍的情况是材质参数化。在它的最简单形式中，材质参数化需要两种类型的材质实体： 材质模板（material templates）与材质实例（material instances）。每个材质模板描述一类材质并且有一个参数的集合，它可以根据参数类型的不同去分配不同的值，有数值，颜色，或者贴图。每个材质实例对应着一个材质模板与所有参数的一组特定值。

参数可以在运行时被解析，通过统一的输入传递到其他着色器程序，或者也可以在编译时，通过在着色器编译前替换值来解析参数。一个常见的编译时参数类型是布尔开关，它用来控制激活给定材质的特征。这可以由美术人员通过材质 UI 的勾选框去设置，或者由材质系统在程序上去设置，例如远处的物体，它们的视觉效果特征可以忽略不计，此情况设置关闭可以减少着色器消耗。

尽管材质参数可以与着色模型参数一对一匹配，但我们不是总会遇到这种情况。一个材质可能会修改一个给定着色模型参数的值，例如表面颜色，可修改为一个常量。或者，可以将多个材质参数以及插值的顶点或纹理值作为输入，通过一系列复杂的操作来计算着色模型参数。在地形材质中，基于表面位置与方向的着色是尤为普遍的。举个例子，高度与表面法线可以被用来控制积雪特效，做法是在高处的水平面和接近水平面的表面以白色表面颜色做混合。基于时间的着色通常用于动画材质，例如闪烁的霓虹灯标志。

材质系统的最重要任务之一是将多种着色器函数划分为单独的元素，并控制这些元素的组合方式。在许多情况下，这种组合是很有用的，包括以下几种情况：

- 将表面着色与几何处理组合在一起，例如刚体变换，顶点混合，变形，曲面细分，实例化，以及裁剪。这些功能都是各不相同的：表面着色器依赖于材质，几何处理依赖于模型网格。所以，分开编写他们以及让材质系统根据需求组合他们是很方便的。
- 将表面着色与一些组合操作例如像素丢弃（discard）与混合（blending）组合在一起。这与移动端 GPU 是尤为相关的，在移动端 GPU 的像素着色器里，混合是一种普遍执行的操作。通常我们希望独立于表面着色用材质来选择这些操作。
- 将用来计算着色模型参数的操作与着色模型自身的计算组合在一起。这种方式允许编写一次着色模型的实现，并且与多种不同计算着色模型参数的方式组合在一起去重用它。
- 将独立可选的材质特征相互组合，以及与选择逻辑、剩余的着色器组合在一起。这种方式允许分开编写每个特征的实现。
- 将着色模型、其参数的计算与光源计算组合在一起：在每个光源的着色点计算c_light与l的值。例如延迟渲染的技术改变了这个组合的结构体。在支持该技术的渲染框架里，这种方式将额外增加复杂度。

> 早期的渲染系统有着相对较小数量的着色器变体，并且通常是手动去编写每个变体。这也有一些好处的。例如，可以在充分了解最终的着色器程序的基础上去优化每个变体。然而，这种手动编写的方法随着着色器变体数量的增加而变得不切实际。当我们将所有不同部分和选项都纳入考虑时，所有可能的不同着色器变体数量是巨大的。这就是为什么模块化和可组合性是如此的关键。

当设计一个系统用来处理着色器变体时，第一个需要解决的问题是，不同选项间的选择是否是通过动态分支（dynamic branching）在运行时执行，或者是在编译时通过条件预处理（conditional preprocessing）执行。在较老的硬件上，动态分支通常是不可能的或者是速度极慢的，所以运行时的选择是不可行的。随后所有变体都在编译阶段被处理，包括不同光源类型计数的所有可能组合。

相反，如今的 GPU 能够很好地处理动态分支，尤其是当分支行为对于一个绘制调用中所有像素都是相同的情况下。现在许多功能性变体，例如光源的数量，都在运行时被处理。然而，为一个着色器添加大量的功能变体将产生一个不同的消耗：寄存器计数（register count）的增加和占用率的相应降低，进而导致性能下降。

举个例子，让我们想象一个支持三种不同类型光源的应用程序。其中两种光源类型很简单：点光源与方向光。第三种类型是通用的聚光灯，它支持列表照明模式以及其他复杂的功能，这需要大量的着色器代码去实现。然而，这个通用的聚光灯使用率相对较小，此应用程序中只有不到 5% 的光源是这种类型。在过去，一个单独的着色器变体会为每个可能的三类光源计数的组合去编译，以避免动态分支。尽管在如今这种方式已不再需要，但是编译两个单独的变体仍然是有好处的，一个变体适用于通用聚光灯数量大于等于一时，另一个变体适用于此类聚光灯数量正好为 0 时。由于它更简单的代码，第二个变体（更常使用）可能有着更低的寄存器占用率，并且因此有着更高的性能表现。

> 现代材质系统同时使用了运行时着色器变体和编译时着色器变体。即使完整的负载已经不会仅在编译时处理，但总体的复杂度与变体的数量仍然保持增长，所以还是需要编译大量的着色器变体。

### 走样与反走样 (Aliasing and Antialiasing)
三角形在像素里的显示是要么存在，要么不存在。线的绘制也有类似的问题。因此，边缘有着锯齿状的外观，这种视觉伪像（visual artifact）被称作“锯齿”（the jaggies），当物体运动时则被称作“爬虫”（crawlies）。关于此问题的更正式的称呼为“走样”（aliasing），并且，旨在避免这个问题的相关技术我们称为“反走样”（antialiasing）。

在计算机图形中走样的普遍案例有光栅化的线与三角形边的“锯齿”，被称为“萤火虫”（fireflies）的闪烁的高光，以及缩小具有方格图案的纹理时发生的走样。

<center><img width="50%" src="CG/RTR/94.png"/></center>
<center>三个不同反走样级别的三角形、线、点。下排图像是上排图像的放大。最左列每个像素仅用一个采样，这意味着没有使用反走样技术。中间列的图像以每像素四个采样（以网格模式）的方式渲染，最右列则是使用每像素八个采样</center>

#### 采样与滤波理论 (Sampling and Filtering Theory)
渲染图像的处理本身便是一个采样任务。之所以这样是因为图像的生成就是三维场景采样的处理过程，其目的是为图像中的每个像素（一个离散的像素数组） 去获取相应的颜色值。

> 注：纹素（英语：Texel，即textureelement或texture pixel的合成字）是纹理元素的简称，它是计算机图形纹理空间中的基本单元。如同图像是由像素排列而成，纹理是由纹素排列表示的。

下图展示了一个连续的信号是怎样以均匀的间隔被采样的，即离散化（discretized）。采样处理的目标是数字化地去呈现信息。这样做可以减少信息量。然而采样的信号需要被重建（reconstructed）以恢复原始信号。这是通过对采样信号进行滤波来完成的。

<center><img width="80%" src="CG/RTR/95.png"/></center>
<center>一个连续信号（左图）被采样（中图），并且接下来原始信号通过重建以恢复（右图）</center>

无论何时进行采样，都可能出现走样。这是我们不想造成的伪像（artifacts），并且我们需要与走样进行战斗以生成令人满意的图像。老的西方人见过的一个关于走样的经典案例，是电影摄像机拍摄的一个旋转的马车车轮。由于车轮辐条移动得比摄像机记录图像的速度快得多，车轮看起来像是在向后或向前缓慢旋转，或者甚至有可能看起来根本没有转动。之所以会出现这种现象，是因为车轮的图像是以一系列时间步长被记录的，这被称作时间走样（temporal aliasing）。

当一个信号被以过慢的频率采样时，走样就会出现。为了使一个信号被合适地采样（换句话说，这样就能够从样本中重建原始信号），采样频率必须大于被采样信号最大频率的两倍。这通常被称作采样定理（sampling theorem），并且该采样频率以一位在 1928 年发现此频率的瑞典科学家 哈里·奈奎斯特（Harry Nyquist） (1889–1976) 命名，被称为奈奎斯特率（Nyquist rate）或奈奎斯特极限（Nyquist limit）。该定理使用术语“最大频率”的这一事实暗示着信号应该受到频带限制（band-limited），这仅仅意味着任何频率都不能超过特定限制。换句话说，信号相对于相邻样本间的间隔应该足够平滑。

#### 重建 (Reconstruction)
给定一个频带限制的采样信号后，我们现在来讨论原始信号是怎样从采样信号去重建的。为了做到这点，我们必须用到一个滤波器。三个普遍使用的滤波器如下图所示。需要注意的是，滤波器的区域应该总是为单个的，否则重建的信号可能会扩大或收缩。

<center><img width="80%" src="CG/RTR/96.png"/></center>
<center>左上图为 box 滤波器（box filter），右上图为 tent 滤波器（tent filter）。底部为 sinc 滤波器（在这里已经 clamped 在 x 轴上）</center>

如下图，采样后的信号（左侧）使用 box 滤波器进行重建。这是通过以下步骤完成的：首先在每个采样点上放置 box 滤波器，并且在 y方向上将其缩放，这样滤波器的高度与采样点就是相同的。之后求出的和就是重建后的信号（右侧）。

<center><img width="80%" src="CG/RTR/97.png"/></center>
<center>采样后的信号（左侧）使用 box 滤波器进行重建</center>

box 滤波器（最近的相邻处）是最糟糕的滤波器，因为产生的信号是一个非连续的阶梯状。然而由于它很简单，所以仍然经常在计算机图形学中使用。如上图所示，box 滤波器被放置在每个采样点上，并且之后会被缩放，这样滤波器最上方的点就可以与样本上的点重合。所有这些缩放与平移后的 box 函数之和就是右侧所示的重建后的信号。

box 滤波器可以替换成任意其他滤波器。例如，tent 滤波器，也被称作三角形滤波器，被用来重建采样后的信号。需要注意的是这个滤波器在相邻采样点之间实现了线性插值，所以它比 box 滤波器要更好，因为重建的信号现在是连续的。

<center><img width="80%" src="CG/RTR/98.png"/></center>
<center>采样后的信号（左侧）使用 tent 滤波器去进行重建。重建后的信号如右侧所示</center>

然而，使用 tent 滤波器重建的信号的平滑程度并不好；在采样点有着突然的斜率改变。这与以下事实有关： tent 滤波器并不是一个完美的重建滤波器。为了得到完美的重建，必须使用理想的低通滤波器。其中信号的频率分量是正弦波：sin(2pi·f)，f是该分量的频率。鉴于此，低通滤波器将去除频率高于滤波器定义的某个频率的所有频率分量。直觉上来看，低通滤波器移除了信号的尖锐特征，即滤波器对信号进行了模糊处理。理想的低通滤波器是 sinc 滤波器。

<center><img width="80%" src="CG/RTR/99.png"/></center>
<center>这里 sinc 滤波器被用来重建信号。sinc 滤波器是理想的低通滤波器</center>

傅里叶分析的理论解释了为什么 sinc 滤波器是理想的低通滤波器。简单来说，理由如下：理想的低通滤波器是频率域的 box 滤波器，当它与信号相乘时，移除了所有高于滤波器宽度的频率。将 box 滤波器从频率域转到空间域会得到 sinc 函数。与此同时，乘法操作被转换为了卷积（convolution）函数，卷积是我们在本节中一直使用的，但没有实际描述过的术语。

正如上图所示，使用 sinc 滤波器去重建信号能得到更平滑的结果。采样过程在信号中引入了高频部分（突变），并且低频滤波器的任务是移除这些高频部分。事实上， sinc 滤波器用频率高于 1/2 的采样率计算了所有的正弦波。sinc 函数，如公式 5.22 所示，当采样频率是 1.0 时（即采样信号的最大频率必须小于 1/2），它是完美的重建滤波器。更普遍地来说，假设采样频率是f_s，也就是说，相邻样本间隔为1/f_s。对这种情况来说，完美的重建滤波器是sinc(f_s(x))，并且它计算了所有高于f_s/2的频率。

!> 然而 sinc 的滤波器宽度是无限的，并且在某些区域是负值，所以它在实践中很少有用。

> 在使用任意滤波器之后，便得到了一个连续的信号。然而，在计算机图形学中我们不能直接显示一个连续的信号，但是我们可以使用它们去对连续信号进行重采样并得到另一个大小，即放大或缩小信号。

#### 重采样 (Resampling)
重采样被用来放大后者缩小一个采样信号。将设原采样点位于整数坐标系内（0,1,2,...），即样本间的间隔是单位整数。更进一步的，假设在重采样后，我们想要新的采样点以样本的间隔 a 均匀地放置。对于 a > 1，使用缩小（下采样），对于 a < 1，使用放大（上采样）。

放大是两种情况中较为简单的一个，所需要的便是以我们期望的间隔去重采样重建后的信号。

<center><img width="80%" src="CG/RTR/100.png"/></center>
<center>在左侧，是采样信号与重建新号。在右侧，重建新号已经以两倍的采样频率进行重采样，即进行了放大</center>

然而，当缩小时，这个技术不起作用。原始信号的频率对采样率来说过高，以至于无法避免走样。

sinc(x/a)被证明可以用于从采样信号中创建连续信号，之后便可以期望的间隔进行重采样。换句话说，通过使用sinc(x/a)作为滤波器，低通滤波器的宽度增加了，以至于更多的信号高频率内容被移除了。

如图所示，（独立 sinc 函数的）滤波器宽度被翻倍以减少重采样率，并使原采样率减半。将此与数字图像联系起来，这与一开始进行模糊操作（为了移除高频率部分）是相似的，然后以低分辨率对图像进行重采样。

<center><img width="80%" src="CG/RTR/101.png"/></center>
<center>在左侧是采样信号与重建信号，在右侧，滤波器宽度已经放大为原来的两倍以使样本间隔也变为原来的两倍，即进行了缩小</center>

#### 基于屏幕空间的反走样 (Screen-Based Antialiasing)
如果采样与滤波的效果不好，三角形的边缘会产生明显的伪像（artifacts）。阴影边缘，高光，以及颜色迅速变化的其他现象都可能导致类似的问题。

> 并没有最佳的反采样技术，因为对画面品质而言，这些技术都有各自的有点，例如捕捉清晰的细节或者其他现象的能力，运动时的表现，内存消耗，GPU 要求，以及速度等等。

如果只在每个像素的网格单元中心进行单个采样，通常无法得到准确的渲染结果。通过在每个屏幕网格单元使用更多的采样并以一些方式将它们混合，就能计算出更好的像素颜色。

下图中，在左侧，以像素中心的一个样本去渲染一个红色三角形。因为三角形并没有覆盖样本，像素是白色，即使像素的大部分已经被红色三角形覆盖。在右侧，对每个像素使用了四个采样点，正如我们所见，其中两个采样点被红色三角形所覆盖，因此像素为粉红色

<center><img width="70%" src="CG/RTR/102.png"/></center>
<center>多重采样</center>

基于屏幕的反走样方案的一般策略是使用一个针对屏幕的采样模式，并且对这些样本进行加权与求和，以得出像素的颜色p：

<center><img width="30%" src="CG/RTR/103.png"/></center>

其中 n 是用于单个像素的采样数。函数c(i,x,y)是一个采样颜色，w_i是权重，范围是 [0,1]，样本对整个的像素颜色有所贡献。样品的位置根据其在序列中的顺序来确定，如 1，……，n，并且可选的函数也是使用像素位置 (x,y) 的整数部分。换句话说，每个样本在屏幕网格的采样位置都是不同的，并且可选的采样模式可以对每个像素都不同。在实时渲染系统（以及大多数其他渲染系统）中，样本通常是点样本。所以，函数 c 可以被认为是两个函数。首先，函数 f(i,n) 检索屏幕上需要样本的浮点 (x_f,y_f) 。然后对屏幕上的该位置进行采样，即检索该精确点处的颜色。选择采样方案，并且配置渲染管线以计算特定子像素位置的采样，这通常基于逐帧（或逐应用）设置。

在反走样中的另一个变量是 w_i，每个样本的权重。这些权重的和为 1。大部分用于实时渲染系统的方法都对它们的样本给出了统一权重，即 w_i=1/n。图形硬件的默认模式，像素中心的单个采样，是上述反走样方程的最简单情况。只有一个项，该项的权重为 1，并且采样函数 f 总是返回被采样像素的中心。

反走样算法计算每个像素时，如果使用超过一个完整的采样，就被称作超级采样（或过采样）方法。概念上最简单地说，全场景反走样（full-scene antialiasing, FSAA），又名“超级采样反走样”（supersampling antialiasing, SSAA），以更高的分辨率渲染场景，然后对相邻的样本进行滤波以得到图像。举个例子，假设我们需要一张 1280 x 1024 像素的图像。如果你在屏幕外渲染一个 2560 x 2048 像素的图像，然后对每 2 x 2 的像素区域取平均值，之后在屏幕上显示，我们需要的图像就会以每像素四个采样，并使用 box 滤波器去进行滤波。

!> 需要注意的是，这相当于图 5.25 中的 2 x 2 网格采样。此方法较为消耗性能，因为所有的子采样必须被完整地着色与填充，其中每个样本都具有 z 缓冲区的深度信息。

FSAA 的主要优点在于简单。这种方法的其他低质量版本只在一个屏幕轴向上以两倍的速率采样，因此被称为 1 x 2 或 2 x 1 超级采样。通常来说，为了简化起见，使用二次幂分辨率和 box 滤波器。英伟达（NVIDIA）的动态超分辨率（dynamic super resolution）功能是一个更加复杂的超级采样形式，其中以更高的分辨率渲染场景，并且使用 13 个采样的高斯滤波器去生成显示图像。

<center><img width="80%" src="CG/RTR/104.png"/></center>
<center>一些像素采样方案的对比，按照逐像素采样数从少到多排列。Quincunx 共享角落的样本以及中心样本进行加权，以使其值达到像素最终颜色的一半。2 × 2 旋转网格比 2 × 2 直形网格在几乎水平的边缘上会捕获更多的灰度级。类似地，尽管使用的样本较少，但 8 rooks 图案捕获的此类线条比 4 × 4 网格捕获的灰度级别更多</center>

一个与超级采样相关的采样方法是基于累积缓冲区（accumulation buffer）的。该方法不使用一个大的屏幕外缓冲区，而是使用一个与最终期望图像具有相同分辨率的缓冲区，但是每个颜色通道使用更多的字节位。为了得到一个场景的 2 x 2 采样，生成四幅图像，视图根据需要在屏幕 x 轴或 y 轴上移动半个像素。每个生成的图像都是基于网格单元内的不同采样位置。每帧必须重新渲染场景几次，并将结果复制到屏幕上，这种额外费用使该算法在实时渲染系统中成本很高。当性能问题不关键时，这种方法对生成高质量的图像来说是很有用的，因为每个像素可以使用任何数量的样本，并且可以放置在任何地方。累积缓冲区曾经是硬件中单独的一部分。它直接被 OpenGL API 所支持 ，但是在 3.0 版本中被弃用。在现代 GPU 中，累积缓冲区这个概念可以通过在输出缓冲区使用高精度的颜色格式，从而在像素着色器中实现。

当物体边缘、镜面高光和锐利阴影等现象引起突变的颜色变化时，需要额外的采样样本。阴影通常能够变得更软，以及高光可以变得更平滑以避免走样。可以增加特定对象的大小，例如电线，以确保它们在长度上每个位置覆盖至少一个像素。物体边缘的走样仍然是一个主要的采样问题。在渲染时物体边缘被检测以及它们的影响被考虑在内时，可以使用分析方法，但是这些方法通常更为昂贵，并且相比简单地进行更多的采样，它的鲁棒性要更低。然而，GPU 的功能例如保守光栅化和光栅化顺序视图开启了新的可能性。

多重采样反走样（Multisampling antialiasing，MSAA）通过一次的逐像素计算表面着色，并在样本间共享计算结果，从而降低了高额的计算成本。每个片元有四个(x,y)样本位置，每个都有它们自己的颜色与 z 深度值，但是对于像素的每个物体的片元，像素着色器只计算一次。如果所有的 MSAA 位置样本都被片元覆盖，那么着色样本就会在像素的中心被计算。相反，如果片元覆盖较少的位置样本，则着色样本的位置可以移动，以更好地表示所覆盖的位置。举个例子，这么做可以避免纹理边缘之外的着色采样。

> 这种位置调整方法被称作质心采样（centroid sampling）或质心插值（centroidinterpolation），并且如果开启该功能的话，该过程会由 GPU 自动完成。质心采样可以避免出现三角形外的问题（off-triangle problems），但会导致导数计算返回不正确的值。

<center><img width="80%" src="CG/RTR/105.png"/></center>
<center>在中间，一个像素中的两个物体重叠。红色物体覆盖了三个样本，蓝色物体只有一个。像素着色器计算位置以绿色显示。因为红色三角形覆盖了像素的中心，这个位置被用作着色器计算。用于蓝色物体的像素着色器在对应的样本位置进行计算。对于 MSAA 来说，分离的颜色与深度值被储存在所有四个位置中。在右侧展示了 EQAA 的 2f4x 模式。四个样本现在有四个 ID 值，这些 ID 索引了一张存储起来的表，表内有两种颜色和深度的信息</center>

MSAA 比纯粹的超级采样方案快是因为<strong>片元只进行一次着色</strong>。它致力于以高频率对片元的像素覆盖区域进行采样，以及共享计算出的着色数据。通过进一步分离采样和覆盖范围，可以节省更多的内存，这反过来又可以使反走样的速度更快——使用的内存越少，渲染速度就越快。英伟达（NVIDIA）在 2006 年推出了覆盖采样反走样（coverage sampling antialiasing，CSAA），并且 AMD 随后推出了增强质量反走样（enhanced quality antialiasing，EQAA）。这些技术通过以更高的采样率并且仅储存片元的覆盖范围来实现。举个例子，EQAA 的 “2f4x” 模式存储了两个颜色与深度值，在四个样本位置之间共享。颜色与深度值信息不再储存在特定的位置里，而是储存在一张表中。四个样本每个只需要一位（bit）空间用来指定两个存储值中的哪个与其位置相关联。

一旦所有的几何体被渲染到一个多重采样缓冲区时，会执行一个解析（resolve）操作。这段程序会将样本颜色总体进行平均以决定像素的颜色。值得注意的是，当使用具有高动态范围颜色值的多重采样时，可能会出现一个问题。在这种情况下，为了避免伪像（artifacts），在进行解析操作前，通常需要对值进行<strong>色调映射(Tone Mapping)</strong>。

默认的情况下，MSAA 通过 box 滤波器进行解析。在 2007，ATI 推出了自定义滤波器反走样（CFAA），它能够使用更狭窄或更宽的 tent 滤波器并且稍微拓展到其他像素格。之后支持了EQAA，从而取代了这个模式。在现代 GPU 上，像素或者计算着色器能够访问 MSAA 的样本并且使用任何我们所期望的重建滤波器，包括从周围像素中采样的样本。

虽然一个更宽的滤波器会丢失锐利的细节，但它能够减少走样。佩蒂诺（Pettineo）发现立方体的 smoothstep 以及有着 2 或 3 像素宽度的 B 样条滤波器在总体上得出了最好的结果。当然还有性能消耗，因为即使使用自定义着色器模拟默认的 box 滤波器解析也会花费很长的时间，而一个更宽的滤波器核心意味着增加了样本的访问成本。

英伟达（NVIDIA）的内置支持的 TXAA ，类似地在比单个像素更大的区域上使用了更好的重建滤波器，以提供更好的结果。它和更新的 MFAA（多帧反走样，multiframe antialiasing）方案都使用了 TAA（时间性反走样，temporal antialiasing），这是一类通用技术，它可以使用之前帧的结果用来改进图像。由于程序员能够逐帧设置 MSAA 采样模式的功能，这种技术在某种程度上成为了可能。这种技术可以解决例如旋转的马车车轮等反走样问题，并且能够改进边缘渲染质量。

> 想象通过生成一系列图像来“手动”执行采样模式，其中每次渲染使用不同的位置进行采样。这种偏移是通过在投影矩阵上附加一个微小的平移来完成的。

生成和取平均的图像越多，结果就越好。这种使用多个偏移图像的概念被用于时间性反走样算法。可能使用 MSAA 或其他方法生成单个图像，然后将之前的图像做混合。通常只有 2-4 帧被使用。

<strong>较旧的图像被赋予的权重可能呈指数减小</strong>，尽管如果观看者和场景不移动，这可能会导致帧闪烁，因此通常只对前一帧和当前帧赋予相同的权重。由于每帧的样本位于不同的子像素位置，因此这些样本的权重总和估计的边缘覆盖率比单帧更好。因此，使用前两帧平均的系统可以提供更好的结果。每帧都不需要额外得样本，这就是此方法如此吸引人的原因。我们甚至可以使用时间性采样来生成较低分辨率的图像，该图像将放大到显示器的分辨率的大小。此外，需要很多样本才能获得良好结果的照明方法，或者其他的技术，这两者可以用每帧使用更少样本的方法来代替，因为其结果将在多帧中混合。

在不增加额外采样成本的情况下为静态场景提供反走样功能时，这种类型的算法在用于时间性反走样功能时会遇到一些问题。如果没有对帧进行均等的加权，则静态场景中的对象可能会出现微光（shimmer）。快速移动的物体或快速的摄像机移动会导致鬼影（ghosting），即由于先前帧的影响而在物体后方留下痕迹。

- 鬼影的一种解决方案是仅对缓慢移动的对象执行这种反走样处理；
- 另一个重要的方法是使用重投影（reprojection）来更好地关联先前和当前帧的对象。在这种方案中，对象生成运动向量，这些运动向量存储在单独的“速度缓冲区”（velocity buffer）中。这些向量用于将前一帧与当前帧相关联，即从当前像素位置减去该向量，以找到该对象表面位置前一帧的彩色像素。在当前帧中不太可能成为表面一部分的样本将被丢弃。

由于时间性反走样不需要额外的样本，因此也就不需要多少额外的工作，因此近年来人们对这种算法产生了浓厚的兴趣，并且该算法也得到了广泛的应用。

#### 采样模式 (Sampling Patterns)
有效的采样模式是减少走样、时间以及其他方面的关键要素。Naiman的研究表明，在水平和垂直边缘附近的走样对人类视觉的影响最大。旋转栅格超级采样（Rotated grid supersampling，RGSS）使用旋转正方形图案来在像素内提供更多垂直和水平分辨率。

RGSS 模式是一种拉丁超立方体（Latin hypercube）或 N-rooks 采样的形式，其中 n 个采样放置在 n × n 的网格中，每行和每列一个采样。使用 RGSS时，这四个样本分别位于 4 × 4 的子像素网格中的单独行和列中。与常规 2 × 2 的采样模式相比，此类模式特别适合捕获几乎水平和垂直的边缘，在常规采样模式下，此类边缘可能覆盖偶数个样本，因此有效程度较低。

!> N-rooks 是创建良好采样模式的开始，但这还不够。例如这些样本可能都沿着子像素网格的对角线放置，因此对于几乎平行于该对角线的边缘，会得出较差的结果。

<center><img width="70%" src="CG/RTR/106.png"/></center>
<center>N-rooks 采样。左侧是一个符合规则的 N-rooks 图案，但是它在捕捉沿对角线的三角形边缘上表现较差。因为随着该三角形的移动，所有采样位置都将位于三角形的内部或外部。右侧是一种图案，它可以更有效地捕获此边缘和其他边缘</center>

为了获得更好的采样，我们要避免将两个采样彼此靠近。我们还希望分布均匀，将样本均匀分布在整个区域。为了形成这样的图案，我们会将例如拉丁超立方体采样的分层采样技术，与其他例如抖动、霍尔顿序列和泊松磁盘采样的方法相结合。

实际上，GPU 制造商通常将此类采样模式硬连接到其硬件中，以进行多重采样反走样。对于时间性反走样，因为样本位置会逐帧变化，所以其覆盖范围是程序员无论如何都想获取的。例如，Karis 发现基本的 Halton 序列（Halton sequence）比 GPU 提供的任何 MSAA 模式效果更好。霍尔顿序列会在空间中生成样本，这些样本看起来是随机的，但差异很小，也就是说，它们在空间中分布均匀，并且没有聚集（clustered）的现象。

虽然子像素网格图案可以更好地近似每个三角形如何覆盖网格单元，但这并不是理想的。场景可以由屏幕上任意小的物体组成，这意味着没有采样率可以完美地捕获它们。如果这些微小的物体或特征形成图案，则以恒定间隔进行采样可能会导致莫尔条纹和其他干涉图案。超级采样中使用的网格图案特别容易产生走样。

一种解决方案是使用随机采样，这样可以提供更加随机的图案。在过去的几十年中，偶尔会在硬件中支持交错采样（Interleaved sampling）、索引采样（index sampling），其中一组像素的每个像素都有不同的采样模式。

<center><img width="80%" src="CG/RTR/107.png"/></center>
<center>RGSS 采样模式。 每像素花费四个样本。 通过将这些位置移到像素边缘，可以跨边缘进行样本共享。 但是，要解决此问题，每个其他像素必须具有镜像的采样模式，如右图所示。 所得的样本模式称为 FLIPQUAD，每个像素花费两个样本</center>

#### 形态学方法 (Morphological Methods)
走样通常是由边缘引起的，例如由几何形状，尖锐阴影或明亮高光形成的边缘。 走样具有与边缘相关的结构，可以利用这些知识来提供更好的反走样结果。

2009年，Reshetov 沿着这些思路提出了一种算法，称其为形态学反走样（morphological antialiasing ，MLAA）。其中“形态”是指“与结构或形状有关”。早在1983年，Bloomenthal 就在这一领域做了较早的工作。之后 Reshetov 的论文重新激发了对多采样方法替代方法的研究，强调搜索和重建边缘。

这种反走样形式是在后处理（post-process）中执行的。 也就是说，以通常的方式进行渲染，然后将结果反馈到生成反走样结果的过程中去。自 2009 年以来，已经开发出了多种技术。那些依赖于其他缓冲区（例如深度和法线）的缓冲区可以提供更好的结果，例如子像素重建反走样（subpixel reconstruction antialiasing ，SRAA），但仅适用于对几何边缘进行反走样。诸如几何缓冲区反走样（geometry buffer antialiasing，GBAA）和距离边缘反走样（distance-to-edge antialiasing，DEAA）之类的分析方法，会使渲染器计算有关三角形边缘位于何处的附加信息，例如边缘距像素中心的距离有多少。

最通用的方案只需要颜色缓冲区，这意味着它们还可以从阴影，高光或之前应用的各种后处理技术（如轮廓边缘渲染）中改善边缘。 例如，方向局部反走样（directionally localized antialiasing，DLAA）是基于以下观察结果：接近垂直的边缘应水平模糊，同样，接近水平的边缘也应与其相邻像素垂直模糊。

边缘检测的更复杂形式尝试寻找可能包含任意角度的边缘的像素并确定其覆盖范围。 检查潜在边缘周围的邻域，目标是尽可能地重建原始边缘所在的位置。 然后可以使用边缘对像素的效果来融合相邻像素的颜色。

<center><img width="80%" src="CG/RTR/108.png"/></center>
<center>形态学反走样。左侧是走样图像。我们的目的是确定形成边缘的边缘的可能方向。中间，该算法通过检查相邻像素来记录其为边缘的可能性。给定样本后，显示了两个可能的边缘位置。右侧，使用最佳的推测边缘将相邻的颜色与估计的覆盖率成比例地混合到中心像素中。之后对图像中的每个像素重复此过程</center>

基于图像的算法中有几种可能会误入歧途。 首先，如果两个对象之间的色差低于算法的阈值，则可能无法检测到边缘。 具有三个或更多不同表面重叠的像素很难进行转换。颜色在像素间快速变化的，具有高对比度或高频率元素的表面，会导致算法错过边缘。特别地，当对其应用形态学反走样时，文本显示的质量通常会受到影响。 对象的角落部分可能是一个挑战，有些算法可以使它们具有圆润的外观。假设边缘是直的，曲线也会受到其不利影响。单个像素变化可能会导致边缘重建方式发生很大变化，从而在帧与帧之间产生明显的伪像（artifacts）。解决此问题的一种方法是使用 MSAA 覆盖蒙版来改善边缘确定性。

综上所述，基于图像的方法可以为较小的内存和处理成本提供反走样支持，因此它们被用于许多应用程序中。仅颜色的版本还与渲染管线分离，使其更容易修改或禁用，并且甚至可以公开为 GPU 驱动程序选项。两种最流行的算法是快速近似反走样（fast approximate antialiasing，FXAA）和子像素形态反走样（subpixel morphological antialiasing，SMAA），部分原因是它们都为各种设备提供了可靠的（以及免费的）源代码实现。两种算法都使用仅颜色的输入，SMAA 具有能够访问 MSAA 样本的优势。 每个算法都有自己可用的各种设置，以便在速度和质量之间进行权衡。 每帧消耗通常在 1-2 毫秒的范围内，主要是因为这是视频游戏所愿意花费的时间。 最后，两种算法都可以应用时间性反走样功能。 Jimenez 提出了一种改进的 SMAA 实现，比 FXAA 更快，并描述了一种时间性反走样方案。

### 透明度，Alpha值，与合成 (Transparency, Alpha, and Compositing)
光通过半透明物体的方法有许多种。对于渲染算法而言，这些方法可以大致分为基于光的效果或基于视图的效果。基于光的效果是指对象使光衰减或转移，导致场景中的其他对象被照亮和呈现不同的效果。基于视图的效果是指半透明对象自身的渲染效果。

一种制造透明感的方法称为屏幕门透明（screen-door transparency）。其思路是用像素对齐的棋盘格填充图案渲染半透明三角形。通常，屏幕上的像素足够紧凑以至于棋盘格图案本身是不易察觉的。这种方法的一个主要劣势是，通常只有一个半透明的对象可以令人信服地在屏幕的一个区域上渲染出来。举个例子，如果半透明的红色对象和半透明的绿色对象在蓝色对象之上渲染，则三种颜色中只有两种可以出现在棋盘格图案上。此外，50%的棋盘格效果是很有限的。其他更大的像素蒙版可用于给出其他百分比混合效果，但是这些倾向于创建那些可检测的图案。

这种技术的一个优势是它比较简单。半透明对象可在任意时间，以任何顺序呈现，且不需特殊的硬件支持。通过使所有对象在它覆盖的（棋盘格）像素处变为不透明，便解决了透明度的问题。同样的思路也被用于对剪切纹理的边缘进行反走样处理，但是这是在子像素级别，使用了被称为 Alpha 覆盖（alpha to coverage）的功能。

Enderton 等人提出使用随机透明（stochastic transparency）的方法使用子像素屏幕门遮罩与随机采样相结合而成。通过使用随机点画图案表示片元的 Alpha 覆盖，可以创建一个合理但含噪声的图像。为了看起来更合理，每个像素都需要大量的样本，当然，也需要为所有这些子像素样本准备相当大的内存空间。但此方法很有吸引力的是不需要进行混合操作，并且反走样，透明度，以及任何其他的创建部分覆盖像素的现象都可用此单一机制来处理。

<center><img width="80%" src="CG/RTR/109.png"/></center>
<center>随机透明。产生的噪声显示在放大区域中</center>

大多数透明度算法会将透明对象的颜色与其后面对象的颜色混合在一起。为此，我们需要 Alpha 混合的概念。当在屏幕上渲染对象时，RGB 颜色和 z 缓冲区深度这两者与每个像素都是相关联的。我们还可以为对象覆盖的每个像素定义另一个组件，称为 Alpha（α）。Alpha 是一个值，它用于描述给定像素的对象片元的不透明度和覆盖度。Alpha 为1.0 表示对象是不透明的，并且完全覆盖了像素的关注区域；0.0 表示完全不隐藏像素，即片元是完全透明的。

像素的 Alpha 值可以表示不透明度或覆盖率，或同时是两者，这具体视情况而定。举个例子，肥皂泡的边缘可能会覆盖像素的四分之三，即 0.75，并且可能几乎是透明的，从而使十分之九的光线直达眼睛，所以它的十分之一是不透明的，即 0.1。那么其 Alpha 将为 0.75 × 0.1 = 0.075。但是，如果我们使用 MSAA 或类似的反走样方案，覆盖率将通过样本自身从而被考虑在内。因此四分之三的样本将受到肥皂泡的影响。然后，在每个样本中，我们将使用 0.1 的不透明度值作为 Alpha 值。

#### 混合顺序 (Blending Order)
为了使对象看起来透明，它以小于1.0 的 Alpha 渲染到现有场景的顶部。对象覆盖的每个像素将从像素着色器接收结果 RGB_α（也称为 RGBA）。通常使用 over 运算符将此片段的值与原始像素颜色混合，如下所示：

<center><img width="50%" src="CG/RTR/110.png"/></center>

其中c_s是半透明对象的颜色（称作来源，source），α_s是对象的 Alpha 值，c_d是混合前的像素颜色（称作目标，destination），c_o是将半透明对象放置在现有场景上而产生的最终颜色。在渲染管线传入c_s和α_s的情况下，像素的原始颜色c_d被结果c_o所取代。如果传入的  实际上是不透明的（α_s = 1.0），则该公式简化为用对象的颜色完全替换像素的颜色。

over 运算符为要渲染的对象提供半透明外观。通过这种方式实现的透明性可以正常工作，即只要可以通过它看到后面的对象，我们就会将它视为透明的物体。使用 over 模拟薄纱织物的真实效果。织物背后对象的视图被部分遮挡了——织物的线是不透明的。在实践中，宽松的织物具有随角度变化的 Alpha 覆盖率。这里的重点是 Alpha 模拟了材质覆盖像素的程度。

<center><img width="70%" src="CG/RTR/111.png"/></center>
<center>红色薄纱正方形的织物与红色的塑料过滤器，它们具有不同的透明效果。注意，它们的阴影也不同</center>

over 运算符对于其他类型的半透明效果显得不是很可信，尤其是透过有色玻璃或塑料观看时。在现实世界中，放置在蓝色物体前面的红色滤镜通常会使蓝色物体看起来很暗，因为该物体反射的可以穿过红色滤镜光线很少。参见图 5.32。当使用 over 进行混合时，结果是红色和蓝色部分相加在一起。更好的方法应该是将这两种颜色相乘，并增加透明对象本身的反射。

在基本的混合阶段运算符中，over 是通常用于透明效果的运算符 [199，1429]。另一种有用的操作是加法混合（additive blending），即将像素值简单地求和。如下所示：

<center><img width="20%" src="CG/RTR/112.png"/></center>

这种混合模式能够很好地用于发光效果，例如闪电或火花，这些效果不会使后面的像素衰减，而只会使它们变得更亮。然而，此模式的透明度看起来不正确，因为不透明的表面似乎没有被过滤。对于诸如烟或火焰之类的多层分层半透明表面，加法混合具有使半透明现象的颜色更饱和的效果。

为了正确渲染半透明对象，我们需要在不透明对象之后绘制它们。首先，通过关闭混合以渲染所有不透明对象，然后开启 over 以渲染半透明对象。从理论上讲，我们总是可以让 over 开启，因为不透明的 Alpha 1.0 会给出源颜色并隐藏目标颜色，但是这样做成本更高，而且没有真正的收益。

z 缓冲区的限制是每个像素只能存储一个对象。如果多个透明对象与同一像素进行重叠，则仅 z 缓冲区无法容纳且无法在之后解决所有可见对象的影响。当使用 over 时，任何给定像素处的透明表面通常都需要以从后到前的顺序进行渲染。不这样做的话可能会给出错误的知觉暗示。一种实现这种排序的方法是，按照单个对象的质心沿相机视角的距离对其进行排序。这种粗略的分类可以很好地工作，但是在各种情况下都有许多问题。首先，这里的顺序只是一个近似值，因此分类时较远的对象可能位于较近的对象的前面。互相贯穿的对象无法针对所有视角在每个网格上都进行正确显示，除非将每个网格分解为单独的碎片。

<center><img width="80%" src="CG/RTR/113.png"/></center>
<center>在左侧，使用 z 缓冲区以透明方式渲染模型。以任意顺序渲染网格会产生严重的错误。在右侧，深度剥离可提供正确的外观，但要消耗额外的 pass 数</center>

尽管如此，由于其简单性与速度，以及它不需要额外的内存或特殊 GPU 支持，我们仍然经常使用这种对透明度进行粗糙排序的方法。如果应用了这种方法，通常最好在执行透明度时关闭 z 深度替换功能。也就是说，z 缓冲区仍然可以正常测试，但是保留下来的的曲面不会改变存储的 z 深度；最接近的不透明表面的深度保持不变。用这种方法，所有半透明物体都至少会以某种形式出现，而不是在照相机旋转导致的更改排序顺序时造成物体突然出现或消失。其他技术也可以帮助改善外观表现，例如每次绘制两次透明网格，首先渲染背面，然后渲染正面。

over 方程也可进行修改，以使从前到后混合能得到相同的结果。这种混合模式称为 under 运算符：

<center><img width="50%" src="CG/RTR/114.png"/></center>

under 要求目标保持 Alpha 值，而 over 则不需要。换句话说，目标——在它之前混合了更近的透明表面——并不是不透明的，因此需要具有 Alpha 值。under 的公式和 over 相似，但是交换了源和目标。另外需要注意的是，用于计算 Alpha 值的公式与顺序无关，因为源 Alpha 值和目标 Alpha 值可以交换，结果都是相同的最终 Alpha 值。

Alpha 公式来自将片元的 Alpha 作为覆盖率。Porter 和 Duff 注意到，由于我们不知道每个片元覆盖区域的形状，因此我们假设每个片元都按其 Alpha 值比例去覆盖另一个片元。例如，如果α_s=0.7，则以某种方式将像素分为两个区域，其中源片元覆盖 0.7，而目标片元覆盖 0.3。除非有其他新的技术，否则目标片元覆盖范围，我们称α_d=0.3，会按比例地与源片元进行重叠。该公式具有几何解释，如图：

<center><img width="80%" src="CG/RTR/115.png"/></center>
<center>一个像素和两个片元 s 和 d 。通过沿着不同的轴对齐两个片元，每个片元会按一定比例覆盖另一个片元，也就是说，它们是不相关的。两个片元覆盖的面积等于 under 输出的 Alpha 值。这意味着将两个面积相加，然后减去它们重叠的面积</center>

#### 顺序无关透明 (Order-Independent Transparency)
under 运算符的另一种用途是执行称为深度剥离（depth peeling）的与顺序无关的透明度（order-independent transparency, OIT）算法。

顺序无关意味着应用程序不需要执行排序。深度剥离的思路是使用两个 z 缓冲区和多 Pass。首先，渲染一个 Pass，以使所有表面的 z 深度（包括透明表面）都位于第一个 z 缓冲区中。在第二个 Pass 中，将会渲染所有半透明对象。如果对象的 z 深度与第一个 z 缓冲区中的值匹配，则我们就知道这是最近的半透明对象，然后将它的 RGBα 值保存到单独的颜色缓冲区中。我们还通过保存所有半透明对象（如果有）的超出第一个 z 深度并且最接近的 z 深度来“剥离”该层。此 z 深度是第二近的透明对象的距离。接下来的一系列 Pass 继续使用 under 进行剥离并添加透明层。经过一定数量的 Pass 渲染之后，我们会停下来，然后将半透明图像混合在不透明图像之上。

<center><img width="80%" src="CG/RTR/116.png"/></center>
<center>每个深度剥离 Pass 都绘制其中一个透明层。左侧是第一遍绘制，显示了直接可见的图层。中间显示的第二层在每个像素处显示了距离第二近的半透明表面，在这种情况下为对象的背面。右边的第三层是一组距离第三近的透明表面</center>

该方案的几种变体已经研发出来了。例如，Thibieroz 提供了一种从后到前计算的算法，其优点是能够立即混合透明值，这意味着我们不需要单独的 Alpha 通道。深度剥离的一个问题是需要知道究竟多少 Pass 足以捕获所有透明层。一种硬件上的解决方案是提供一个像素绘制计数器，该计数器可指示渲染过程中写入了多少个像素。当 Pass 未渲染任何像素时，渲染就直接完成了。使用 under 的好处是，最重要的半透明层——眼睛首先看到的那些——会在早期就进行渲染。每个半透明表面都会增加其覆盖的像素的 Alpha 值。如果像素的 Alpha 值接近 1.0，则混合的贡献值会使像素几乎是不透明的，因此距离较远的对象的影响可忽略不计。当通过 Pass 渲染的像素数低于某个最小值或可以指定固定数量的 Pass 时，可以减少从前到后的剥离过程。<strong>然而这对于从后到前的剥离效果不佳，因为距离最近（并且通常是最重要）的层是最后绘制的，因此可能会因早期过程的终止而丢失片元</strong>。

尽管深度剥离是有效的，但它的速度有可能很慢，因为每一层的剥离都是针对所有半透明对象的一个独立的渲染 Pass。Bavoil和Myers 提出了双重深度剥离技术，其中在每个 Pass 中剥离了两个深度剥离层，分别是最接近的和最远的剩余层，从而将渲染 Pass 的数量减少了一半。Liu 等人 探索了一种桶排序方法（bucket sort method），该方法一次可捕获多达 32 个层。这种方法的一个缺点是，它需要大量内存才能为所有层保持排序顺序。通过 MSAA 或类似方法进行反走样将极大地增加成本。

以交互速率正确地将半透明对象混合在一起的问题并不是我们缺少算法的问题，而是将这些算法有效地映射到 GPU 的问题之一。1984年，Carpenter 提出了 A 缓冲区，这是另一种多重采样的形式。在A缓冲区中，渲染的每个三角形都会为其完全或部分覆盖的每个屏幕网格创建一个覆盖蒙版（coverage mask）。每个像素存储所有相关片元的列表。不透明的片元可以清除它们后面的片元，类似于 z 缓冲区。所有片元均存储在透明表面上。一旦所有列表形成，就可以通过遍历片元和解析每个样本来产生最终结果。

A 缓冲区的优点是，仅分配每个像素所需的片元，GPU 上的链表实现也是如此。从某种意义上讲，这也可能是不利的，因为在开始渲染帧之前所需的存储量是未知的。具有头发，烟雾或其他物体的场景可能具有许多重叠的半透明表面，因此可能会产生大量的片元。Andersson 指出，对于复杂的游戏场景，最多可以重叠50个物体（例如树叶）的透明网格和最多200个半透明粒子。

<center><img width="80%" src="CG/RTR/117.png"/></center>
<center>左上方为传统的从后到前的 Alpha 混合，由于排序顺序不正确，导致渲染错误。右上方为A缓冲区用于提供完美的非交互结果。左下方显示了具有多层 Alpha 混合的渲染。右下方显示了 A 缓冲区和多层图像之间的差异，将其乘以 4 可得到可见度</center>













## Chapter 6 - Texturing - 纹理化
> 实时渲染最为强大的工具之一就是能够快速访问以及在表面(Surfaces)显示图像。这个过程被称为纹理化(Texturing)


## Chapter 7 - Shadows - 阴影
> 介绍了目前比较流行的快速计算阴影的算法


## Chapter 8 - Light and Color - 光与颜色
> 在实现基于物理的渲染之前，我们首先需要了解如何去量化光和颜色。在物理渲染过程完成后，我们需要将得到的数量值显示出来。<br>本章涵盖两个话题：计算屏幕参数（accounting for the properties of the screen）和观察环境（viewing environment）


## Chapter 9 - Physically Based Shading - 基于物理的着色
> 本章从物理现象背后的规律讲起，涵盖大量的渲染材质的模型，并且会在最后提出一个方法，此方法可以用来混合材质，对材质进行过滤以避免锯齿（走样），并且保持原有的表面外观


## Chapter 10 - Local Illumination - 局部光照
> 本章探索了描绘更精细光源的算法。在表面着色时我们会考虑到光是由具有特别形状的物理对象所发射出的


## Chapter 11 - Global Illumination - 全局光照
> 模拟光源与场景之间多重交互的算法大大提升了图像的真实感。我们会讨论环境和方向光遮挡，在漫反射和高光表面上渲染全局光照效果的实现方法，另外还有一些有前景的统一方法


## Chapter 12 - Image-Space Eﬀects - 图像空间特效
> 图形硬件擅长快速的图像处理。本章首先会讨论图像滤波（Image filtering）和重投影技术（reprojection techniques），然后会探讨几种常用的后处理效果：镜头光晕（lens flares）、动态模糊（motion blur）和景深（depth of field）


## Chapter 13 - Beyond Polygons - 多边形之外
> 三角形（Triangles）并不总是描述对象的最快或最真实的方式。基于使用图像（images）、点云（point clouds）、体素（voxels）和其他采样集的交替表现都有其各自的优点


## Chapter 14 - Volumetric and Translucency Rendering - 体积和半透明渲染
> 本章将聚焦于体积材质呈现以及其与光源相互作用的理论与实践。模拟的范围将从大尺度的大气层效果（large-scale atmospheric effects）到细的头发纤维内的光线散射（light scattering）


## Chapter 15 - Non-Photorealistic Rendering - 非真实感渲染
> 试图使场景看起来更逼真（realistic）只是渲染场景方法中的一种而已。本章会探讨一下其他的渲染风格，如卡通阴影和水彩画效果。此外，线框（line）和文本（text）生成技术也会在本章讨论


## Chapter 16 - Polygonal Techniques - 多边形技术
> 几何数据来源广泛，有时需要进行修改以便渲染得快速、准确。本章将会从多方面介绍多边形数据的呈现和压缩


## Chapter 17 - Curves and Curved Surfaces - 曲线和曲面
> 更复杂的曲面表示提供了一些优势，例如能够在图像质量和渲染速度之间进行权衡、更紧凑的描绘以及平滑的曲面生成


## Chapter 18 - Pipeline Optimization - 管线优化
> 一旦应用程序运行并使用了高效的算法，就可以使用各种优化技术使其变得更快。本章讨论的主题是怎样找到性能优化瓶颈（bottleneck）并如何去解决它。此外，本章还讨论了多进程（Multiprocessing）的相关内容


## Chapter 19 - Acceleration Algorithms - 加速算法
> 本章涵盖了各种形式的剔除（Culling）和细节层次渲染（LOD, Level Of Detail）方法


## Chapter 20 - Eﬃcient Shading - 高效着色
> 场景中的大量灯光会大大降低性能。另外，在确定表面片元（Fragment）是否会显示之前就进行完全的着色计算，也是性能浪费的一大来源。本章探索了一系列的方法来消除低效的着色操作


## Chapter 21 - Virtual and Augmented Reality - 虚拟现实与增强现实
> 这些领域有着特殊的挑战和技术，要求高效、快速、稳定地生成真实的图像


## Chapter 22 - Intersection Test Methods - 相交测试方法
> 相交测试（Intersection testing）对于渲染、用户交互和碰撞检测非常重要。本章将深度涵盖一系列最有效的通用几何相交测试算法


## Chapter 23 - Graphics Hardware - 图形硬件
> 这里的重点是一些组件（Components），如颜色深度（color depth）、帧缓冲区（framebuffers）和基本架构类型（basic architecture types）


## Chapter 24 - The Future - 展望未来
> 猜猜看未来有啥？
