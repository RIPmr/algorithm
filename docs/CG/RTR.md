# Computer Graphics Note

《Real-time Rendering 4th Edition》读书笔记

## Chapter 1 - Introduction - 概述
> Real-time rendering is concerned with rapidly making images on the computer. <br>It is the most highly interactive area of computer graphics. 

### 什么是实时渲染
<strong>实时渲染（Real-time rendering）</strong>指的是在计算机上快速生成图像。它是计算机图形学中最具交互性的领域。首先一幅图像显示在屏幕上，然后观察者做出动作与反应，并且其动作反馈会影响接下来的生成内容。由于这种反馈、渲染的循环速度足够快，观察者就不会只看到独立的图像，而是会沉浸在这种动态过程中。

### 符号和定义 (Notation and Definitions)
<br>
<center><img width="70%" src="CG/RTR/1.png"/></center>
<center>书中使用的数学符号总结</center>

<br>
<center><img width="70%" src="CG/RTR/2.png"/></center>
<center>一些数学运算符的符号</center>

其中运算符8和9是限制（clamping）运算符，通常用于着色计算中。运算符8将负值限制为0：
<center><img width="24%" src="CG/RTR/3.png"/></center>

运算符9将值限制在0和1之间：
<center><img width="26%" src="CG/RTR/4.png"/></center>

第11个运算符，即二项式因子：
<center><img width="20%" src="CG/RTR/5.png"/></center>

<br>
<center><img width="70%" src="CG/RTR/6.png"/></center>
<center>一些特殊数学函数的符号</center>


## Chapter 2 - The Graphics Rendering Pipeline - 图形绘制流水线
> 实时渲染的核心是一系列变换步骤，这些步骤将场景的数学描述转换成我们能看到的东西（图像信息）

### 渲染管线
渲染管线的基本构造包括四个阶段：
- 应用程序阶段（application）
- 几何处理阶段（geometry processing）
- 光栅化阶段（rasterization）
- 像素处理阶段（pixel processing）

这些阶段中的每个阶段本身也可以是管线化或并行化的：
<br>
<center><img width="90%" src="CG/RTR/7.png"/></center>
<center>渲染管线的基本构造</center>

### 应用程序阶段（application）
应用程序阶段（application）由应用程序驱动，因此通常由在通用 CPU 上运行的软件实现。这些 CPU 通常包括多个内核，这些内核能够并行处理多个线程。这使 CPU 可以有效地运行应用程序阶段负责的各种任务。传统上通常在 CPU 执行包括碰撞检测、全局加速算法、动画、物理模拟还有许多其他任务，任务具体取决于应用程序的类型。

在应用程序阶段结束时，要渲染的几何图形被移交到几何处理阶段。因为此阶段是基于软件的实现，所以它不像几何处理阶段、光栅化阶段和像素处理阶段那样能够划分为多个子阶段（从而提升处理效率）。但是，为了提高性能表现，应用程序阶段通常会在多个处理器核心上并行执行。在CPU设计中，这被称为超标量构造（superscalar construction），因为它能在同一阶段同时执行多个进程。

### 几何处理阶段（geometry processing）
此阶段会处理变换，投影以及所有其他类型的几何处理。另外，此阶段会计算所需要绘制的内容，并判断应如何绘制以及应在何处绘制。几何处理阶段通常在包含许多可编程内核以及固定操作硬件的图形处理单元（GPU）上执行。
GPU 上的几何处理阶段（Geometry Processing）负责大部分的逐三角形和逐顶点的操作。该阶段进一步分为以下功能阶段（functional stages）：
- 顶点着色（vertex shading）
- 投影（projection）
- 裁剪（clipping）
- 屏幕映射（screen mapping）
<br>
<center><img width="90%" src="CG/RTR/8.png"/></center>
<center>几何处理阶段中的渲染管线</center>

### 光栅化阶段（rasterization）
此阶段通常会依次将三个顶点输入，形成三角形，然后找到该三角形内所有需要计算的像素，将它们发送到下一个阶段。我们称这种过程为光栅化，它被分为两个功能子阶段：三角形设置（triangle setup，也称为基本装配）和三角形遍历（triangle traversal）：
<center><img width="70%" src="CG/RTR/9.png"/></center>
<center>光栅化的两个阶段</center>

#### 三角形设置（triangle setup，也称为基本装配）
在这一阶段，计算了三角形的微分、边缘方程和其他数据。 这些数据可用于三角形遍历以及几何阶段产生的各种着色数据的插值。

#### 三角形遍历（triangle traversal）
这个阶段将检查每个像素（或样本）中心被三角形覆盖的情况，并为与三角形重叠的像素部分生成一个片元（fragment）。

### 像素处理阶段（pixel processing）
在此阶段，经过之前所有阶段的处理，已经找到了在三角形或其他图元内部应考虑的所有像素，于是此阶段为每个像素执行一段程序以确定其颜色，并可以进行深度测试，以判断该像素是否可见。它还可以对每个像素进行其他操作，例如将新计算的颜色与之前的颜色混合。光栅化和像素处理阶段都是完全在 GPU 上进行处理。


## Chapter 3 - The Graphics Processing Unit - 图形处理单元
> 现代GPU使用固定功能和可编程单元的组合来实现渲染管线(Rendering Pipeline)的各个阶段

专用图形硬件相对于CPU的唯一优势是计算速度，但速度至关重要。GPU通过专注于一组高度可并行化的任务而获得了卓越的速度。在过去的二十年中，图形硬件经历了不可思议的转变。

### 数据并行架构 (Data-Parallel Architectures)
<strong>延迟（latency）</strong>是所有处理器都面临的问题。访问数据需要花费一些时间。考虑延迟长短的一种基本方法是，信息所处位置离处理器越远，等待时间就越长。

不同的处理器体系结构使用各种策略来避免延迟。

一个CPU可以包含多个处理器，但是每个处理器都以串行方式运行代码，为了最大程度地减少延迟，许多CPU芯片都由快速本地缓存组成，这些缓存中填充了下一步可能需要的数据。CPU还通过使用诸如<strong>分支预测（branch prediction），指令重新排序（instruction reordering），寄存器重命名（register renaming）和缓存预取（cache prefetching ）</strong>之类的巧妙技术来避免停顿。

GPU采用不同的方法避免延迟。GPU的大部分芯片区域专用于称为<strong>着色器核心（shader cores）</strong>的大量处理器，通常数量多达数千个。GPU是流处理器，其中依次处理相似数据的有序集合。由于这种相似性（例如，一组顶点或像素），GPU可以大规模并行地处理这些数据。另一个重要的部分是这些调用要尽可能地独立，这样它们就不需要来自相邻调用的信息，并且不共享可写的存储位置。有时我们会打破该规则来实现新的功能，但是代价是潜在的延迟，因为一个处理器可能会等待另一个处理器完成其工作。

GPU针对吞吐量（throughput）进行了优化，吞吐量定义为可以处理数据的最大速率。但是，这种快速处理具有成本，由于专用于高速缓存存储器和控制逻辑的芯片面积较小，因此每个着色器内核的等待时间通常比CPU处理器遇到的等待时间长得多。

假设网格已光栅化，并且我们现在有2000个要处理的片元（fragments），像素着色器程序将被调用2000次。想象现在我们只有一个处理器，这是世界上最弱的GPU。它开始为2000个片元的第一个片元执行着色器程序。着色器处理器对寄存器中的值执行一些算术运算。寄存器是本地的，可以快速访问，因此不会发生停顿。然后，着色器处理器会执行一条指令，例如纹理访问。由于纹理是一个完全独立的资源，而不是像素程序本地内存的一部分，所以内存提取可能需要数百到数千个时钟周期，在此期间GPU处理器不执行任何操作。<strong>此时，着色器处理器将停止运行，等待纹理的颜色值返回。</strong>

为了缓解这种情况，我们为每个片元提供一些用于其本地寄存器的存储空间。现在，允许着色器处理器切换并执行另一个片元，而不是在采样纹理期间停下来。切换的速度非常快，现在执行第二个片元，与第一个相同，执行一些算术函数，然后再次遇到纹理获取。着色器核心现在再次切换到另一个片元，即第三个片元。最终，所有两千个片元都以这种方式处理。此时，着色器处理器将返回片元一，此时纹理颜色已被获取并且可以使用，因此着色器程序可以继续执行。处理器以相同的方式进行处理，直到遇到另一个已知会暂停执行的指令，或者程序完成。与着色器处理器（shader processor）始终专注于一个片元相比，执行单个片元所需的时间更长，但是整个片元的总体执行时间将大大减少。

在这种架构中，通过切换到另一个片元使GPU保持忙碌来隐藏延迟。GPU通过将指令执行逻辑与数据分离开来，使该设计更进一步。称为<strong>单指令多数据（SIMD，single instruction, multiple data）</strong>的这种安排可以在固定数量的着色器程序上以锁定步骤执行同一命令。SIMD的优点是，与使用单独的逻辑和调度单元运行每个程序相比，用于处理数据和交换的硅（和功率）要少得多。将我们的2000片元示例转换为现代GPU术语，每个片元的像素着色器调用都称为线程。这种类型的线程与CPU线程不同。它由用于着色器输入值的一点内存以及着色器执行所需的任何寄存器空间组成。使用相同着色器程序的线程被分为几组，被NVIDIA称为<strong>warp</strong>，被AMD称为<strong>wavefronts</strong>。一个 warp/wavefront 被 计划用于SIMD处理，由8至64之间的任意数量的GPU着色器内核执行。每个线程都映射到SIMD通道。

假设我们有两千个线程要执行。NVIDIA GPU的 warps 包含32个线程。这将产生2000/32 = 62.5个 warps，这意味着分配了63个warps，其中一个 warps 是一半为空。warp 的执行类似于我们的单个GPU处理器示例。着色器程序在所有32个处理器上以固定步骤执行。因为对所有线程执行相同的指令，遇到内存提取时，所有线程都会同时遇到它。提取信号表明线程warp将停止，所有线程都在等待它们的（不同的）结果。此时不会停顿，而是将warp换成32个线程的另一个warp，然后由32个内核执行。这种交换的速度与我们的单处理器系统一样快，因为在将warp换入或换出时，每个线程内的数据都不会被触及。每个线程都有自己的寄存器，每个warp都跟踪其正在执行的指令。交换新线程只是将一组核心指向另一组要执行的线程即可。没有其他开销。warp执行或换出，直到全部完成。

<center><img width="70%" src="CG/RTR/10.png"/></center>
<center>简化的着色器执行示例</center>

与每个线程相关联的着色器程序所需的寄存器越多，则线程中可以驻留的线程越少，因此warp也就越少。warps 不足可能意味着无法通过交换来减轻失速。驻留的 warps 被称为“飞行中”（in flight），这个数字称为占用率（occupancy）。高占用率意味着有许多可用于处理的 warp，因此空闲处理器的可能性较小。占用率低通常会导致性能不佳。

影响整体效率的另一个因素是由“if”语句和循环引起的动态分支。假设在着色器程序中遇到 “if” 语句。如果所有线程求值并采用同一分支，则warp可以继续进行而不必担心其他分支。但是，如果某些线程甚至一个线程采用了替代路径，那么warp必须执行两个分支，从而丢弃每个特定线程不需要的结果。这个问题称为<strong>线程发散（thread divergence）</strong>，其中一些线程可能需要执行循环迭代或执行warp中其他线程不执行的 “if” 路径，从而使它们在此期间处于空闲状态。

### GPU管线概述 (GPU Pipeline Overview)
GPU实现了第2章中描述的概念如几何处理，光栅化和像素处理管线阶段。这些阶段分为几个硬件阶段，这些阶段具有不同程度的可配置性或可编程性。

这些阶段根据用户对其操作的控制程度进行颜色编码。绿色阶段是完全可编程的。虚线表示可选阶段。黄色阶段是可配置的，但不是可编程的，例如，可以为合并阶段设置各种混合模式。蓝色阶段的功能完全固定。

<center><img width="80%" src="CG/RTR/11.png"/></center>
<center>渲染管线的GPU实现</center>

随着时间的流逝，GPU管道已从硬编码操作阶段演变到增加灵活性和控制能力的阶段。可编程着色器阶段的引入是这一发展过程中最重要的一步。

### 可编程着色器阶段 (The Programmable Shader Stage)
现代着色器程序使用统一的着色器设计。这意味着与顶点，像素，几何和曲面细分相关的着色器共享一个公共的编程模型。在内部，它们具有相同的<strong>指令集体系结构（ISA，instruction set architecture）</strong>。实现此模型的处理器在 DirectX 中称为“通用着色器核心”（common-shader core）。

着色器使用类似C的<strong>着色语言（shading languages）</strong>进行编程，例如DirectX的高级着色语言（HLSL，High-Level Shading Language）和OpenGL着色语言（GLSL，OpenGL Shading Language）。DirectX 的 HLSL 可以编译为虚拟机字节码，也称为中间语言（IL或DXIL），以提供硬件独立性。中间表示还可以允许着色器程序被编译和离线存储。驱动程序将此中间语言转换为特定GPU的ISA。

一次 Draw Call 调用图形API来绘制一组图元（primitives），从而使图形管线执行并运行其着色器（shaders）。每个可编程着色器阶段都有<strong>两种类型的输入</strong>：

- <strong>uniform inputs</strong>: 其值在整个绘制调用期间保持不变（但可以在绘制调用之间进行更改）；
- <strong>varying inputs</strong>: 即来自三角形顶点或光栅化的数据。例如，纹理或任何大型数据数组。

基础虚拟机（The underlying virtual machine）为不同类型的输入和输出提供特殊的寄存器。用于uniforms的可用寄存器的数量比用于varying的输入或输出的可用寄存器的数量多得多。

<center><img width="70%" src="CG/RTR/12.png"/></center>
<center>Shader Model 4.0下的统一虚拟机体系结构和寄存器布局</center>

### 流控制（flow control）
术语<strong>“流控制”（flow control）</strong>是指使用分支指令来更改代码执行流。

与流控制相关的指令用于实现高级语言构造，例如“if”和“ case”语句，以及各种类型的循环。着色器支持两种类型的流控制。

<strong>静态流控制（Static flflow control）</strong>分支基于统一输入的值。这意味着代码流在绘图调用中是恒定的。静态流控制的主要好处是允许将相同的着色器用于各种不同的情况（例如，不同数量的灯光）。由于所有调用都采用相同的代码路径，因此没有线程差异。

<strong>动态流控制（Dynamic flflow control）</strong>基于变化的输入的值，这意味着每个片段可以不同地执行代码。这比静态流控制功能强大得多，但会降低性能，尤其是在着色器调用之间代码流发生不规则变化时。

### 顶点着色器 (Vertex Shader)
顶点着色器是处理三角形网格的第一阶段，顶点着色器提供了一种修改、创建或忽略与每个三角形的顶点关联的值的方法，例如其颜色、法线、纹理坐标和位置。通常，顶点着色器程序会将顶点从模型空间转换为<strong>齐次裁剪空间（homogeneous clip space）</strong>。顶点着色器至少必须始终输出此位置。

顶点着色器的输出将发送到像素着色器程序以进行继续处理。在某些GPU上，数据也可以发送到细分阶段或几何着色器，或存储在内存中。

### 曲面细分阶段 (The Tessellation Stage)
细分阶段允许我们渲染曲面，此阶段是可选的GPU功能，该功能首先在DirectX 11中可用，OpenGL4.0 和 OpenGL ES 3.2也支持该功能。

细分阶段由三个部分组成： DirectX中，它们是：外壳着色器（hull shader），细分（tessellator）和域着色器（domain shader）。在OpenGL中，外壳着色器对应曲面细分控制着色器（the tessellation control shader），而域着色器对应曲面细分评估着色器（tessellation evaluation shader）。

hull shader的输入是一个特殊的补丁图元（patch primitive）。它由几个控制点组成，这些控制点定义了细分曲面，例如Bezier曲面或其他类型的曲面元素。hull shader具有两个功能：首先，它告诉细分器应生成多少个三角形以及采用哪种配置。其次，它对每个控制点执行处理。同样，可选地，hull shader可以修改传入的patch数据，根据需要添加或删除控制点。

hull shader将细分因子（tessellation factors, TFs）和类型发送给固定功能细分器。控制点集由外壳着色器根据需要进行转换，并与TF和相关的修补程序常量一起发送到域着色器。曲面细分对象将创建一组顶点及其重心坐标。然后由域着色器对其进行处理，从而生成三角形网格（显示控制点以供参考）。

<center><img width="70%" src="CG/RTR/13.png"/></center>
<center>细分阶段</center>

### 几何着色器 (Geometry Shader)
几何着色器可以将图元转换为其他图元，而这在细分阶段是无法完成的。几何着色器是在2006年底随 DirectX 10 发行版添加到硬件加速的图形管道中的。它位于管道中的细分着色器之后，并且使用与否是可选的。OpenGL 3.2和OpenGL ES 3.2也支持这种类型的着色器。

几何着色器设计用于修改传入的数据或制作有限数量的副本（copies），几何着色器的行为是最不可预测的，因为它是完全可编程的。实际上，几何着色器通常用得很少，因为它无法很好地展现GPU的优势。在某些移动设备上，它是通过软件实现的，因此强烈建议不要使用它。

### 像素着色器 (Pixel Shader)
顶点，曲面细分和几何体着色器执行完操作后，便会裁剪并设置图元以进行光栅化，流水线的这一部分在其处理步骤中是相对固定的，即不是可编程的，但是高度可配置的。在OpenGL中，像素着色器称为片元着色器。

顶点着色器程序的输出实际上是像素着色器程序的输入，通常像素着色器会计算并输出片元的颜色，但它还可能会产生透明度值（opacity value），并可以选择修改z深度。像素着色器还具有丢弃传入片元（即不生成任何输出）的独特功能。

最初，像素着色器只能输出到合并阶段，以进行最终显示。随着时间的推移，像素着色器可以执行的指令数量已大大增加。于是出现了<strong>多目标渲染（multiple render targets，MRT）</strong>，这使得不仅可以将像素着色器程序的结果发送到颜色缓冲和z缓冲区，还可以为每个片元生成多组值并将其保存到不同的缓冲区，每个缓冲区称为<strong>渲染目标（render target）</strong>。

!> 一些架构要求渲染目标必须具有相同的位深，甚至可能具有相同的数据格式。取决于GPU，可用的渲染目标数量为四个或八个。

另一种类型的基于MRT的渲染管线被称为延迟着色（deferred shading），其中可见性和着色是在单独的通道（passes）中完成的。第一遍渲染存储有关每个像素处对象位置和材质的数据。然后，照明和其他效果在后续的passes中完成。

像素着色器的局限性在于，它通常只能在传递给目标的片元位置上写入渲染目标，而不能从相邻像素读取当前结果。也就是说，执行像素着色器程序时，它无法将其输出直接发送到相邻像素，也无法访问其他像素的最新更改。

像素着色器无法知道或影响相邻像素的结果的规则是有例外的。诸如纹理过滤之类的操作，因为我们想知道多少图像覆盖了一个像素，所有现代GPU都通过以2×2为一组处理片元（称为四边形）来实现此功能。当像素着色器请求梯度值时，将返回相邻片元之间的差异。

DirectX 11引入了一种缓冲区类型，该类型允许对任何位置（<strong>无序访问视图（unordered access view，UAV）</strong>）的写访问。这最初仅适用于像素和计算着色器，DirectX 11.1中对UAV的访问已扩展到的所有着色器。OpenGL 4.3将此称为<strong>着色器存储缓冲区对象（shader storage buffer object，SSBO）</strong>。像素着色器以任意顺序并行运行，并且此存储缓冲区在它们之间共享。

<center><img width="70%" src="CG/RTR/14.png"/></center>
<center>左侧为栅格化，每组2 × 2像素。右侧显示了像素的梯度计算过程</center>

### 合并阶段 (Merging Stage)
合并阶段是将各个片段（在像素着色器中生成）的深度和颜色与帧缓冲区组合在一起的阶段。DirectX将此阶段称为输出合并（output merger）； OpenGL将其称为逐样本操作（per-sample operations）。

在大多数传统管线上，此阶段是模板缓冲区（stencil-buffer）和z缓冲区（z-buffer）操作发生的地方。如果片元可见，则此阶段中发生的另一种操作是颜色混合。

想象一下，通过光栅化生成的片元通过像素着色器运行，然后在应用z缓冲区时被某些先前渲染的片元隐藏。这样就不需要在像素着色器中进行所有处理。为了避免这种浪费，许多GPU在执行像素着色器之前执行一些合并测试。片元的z深度用于测试可见性。如果隐藏该片元，则将其剔除。此功能称为 Early-z。

合并阶段占据了固定功能阶段（例如三角形设置）和完全可编程着色器阶段之间的中间地带。尽管它不是可编程的，但它的操作是高度可配置的。可以将颜色混合设置为执行大量不同的操作。最常见的是涉及颜色和Alpha值的乘法，加法和减法的组合，但是其他操作（例如最小值和最大值）以及按位逻辑运算也是可能的。

### 计算着色器 (Compute Shader)
除了实现传统的图形管线外，GPU还可以用于更多用途。在计算领域，有许多非图形用途，例如计算股票期权的估计价值和训练用于深度学习的神经网络。以这种方式使用硬件称为GPU计算。诸如 CUDA 和 OpenCL 之类的平台可作为大型并行处理器来控制 GPU，而无需真正的需求或访问特定于图形的功能。这些框架通常使用带有扩展功能的 C 或 C++ 等语言以及为 GPU 制作的库。

DirectX 11中引入了计算着色器，它是GPU计算的一种形式，因为它是未锁定在图形管线中某个位置的着色器。它与渲染过程紧密相关，因为它由图形API调用。它与顶点，像素和其他着色器一起使用。它使用与管道中使用的统一着色器处理器池相同的池。与其他着色器一样，它是着色器，因为它具有一组输入数据，并且可以访问缓冲区（例如纹理）以进行输入和输出。

每个调用都会获取一个可以访问的线程索引。还有一个线程组的概念，它由DirectX 11中的1到1024个线程组成。这些线程组由x，y和z坐标指定，主要是为了简化在着色器代码中的使用。每个线程组都有少量的内存，这些内存在线程之间共享。在DirectX 11中，这等于32 kB。计算着色器由线程组执行，因此保证该组中的所有线程可以同时运行。

!> 计算着色器的一个重要优点是它们可以访问在GPU上生成的数据。需要注意的是，从 GPU 向 CPU 发送数据会产生延迟。


## Chapter 4 - Transforms - 变换
> 操纵对象的位置、方向、大小、形状，相机的位置和视图的基本工具

变换（transform）是一种操作，它接受点（points），向量（vectors）或颜色（colors）之类的实体（entities），并且以某种方式变换它们。

#### 线性变换（linear transform）
线性变换（linear transform）是保留向量加法和标量乘法的变换：

<center><img width="20%" src="CG/RTR/15.png"/></center>

#### 仿射变换（affine transform）
仿射变换（affine transform）将线性变换（linear transforms）和平移（translations）结合起来，仿射变换通常存储为4 × 4矩阵。仿射变换是先执行线性变换然后执行平移变换。

所有平移（translation），旋转（rotation），缩放（scaling），反射（reflflection）和剪切矩阵（shearing matrices）都是仿射（affine）。仿射矩阵（affine matrix）的主要特征就是它保留了线的平行性，但不一定保留长度和角度。仿射变换（affine transform）也可以是各个仿射变换级联（concatenations）的任何序列。

### 基本变换 (Basic Transforms)
<br>
<center><img width="80%" src="CG/RTR/16.png"/></center>
<center>各种变换的小结</center>

#### 平移 (Translation)
从一个位置到另一个位置的变化由平移矩阵<strong>T</strong>表示。此矩阵通过向量  去平移实体。

<center><img width="36%" src="CG/RTR/17.png"/></center>

#### 旋转 (Rotation)
旋转变换将一个向量（位置或方向）绕经过原点的给定轴旋转指定的角度。像平移矩阵一样，它是一个刚体变换（rigid-body transform），换句话说，它保留了变换后的点之间的距离，并保留了惯用性（handedness）（即从不导致左右两侧互换）。在计算机图形学中，这两种类型的变换对于定位和定向对象显然很有用。方向矩阵（orientation matrix）是与摄像机视图（camera view）或对象相关联的旋转矩阵，它定义了其在空间中的方向，即其向上和向前的方向。

绕X，Y和Z轴旋转实体的矩阵如下：

<center><img width="30%" src="CG/RTR/18.png"/></center>

如果从4 × 4矩阵中删除最底行和最右列，则将获得 3 × 3 矩阵。对于每个绕任意轴旋转phi弧度的3 × 3矩阵<strong>R</strong>，它的迹（trace，矩阵中对角元素的总和）与轴无关，是恒定的，计算公式为：tr(<strong>R</strong>) = 1 + 2cos(phi)。

所有旋转矩阵的行列式（determinant）均为 1，并且是正交的（orthogonal）。这对于任意数量的这些变换的级联（concatenations）也成立。还有另一种求逆的方法：R^-1(phi) = R(-phi)，即绕同一轴沿相反方向旋转。

#### 缩放 (Scaling)
缩放矩阵S，分别沿x，y和z方向按s_x，s_y和s_z的缩放因子去缩放实体。

<center><img width="26%" src="CG/RTR/19.png"/></center>

如果 s_x=s_y=s_z，则缩放操作称为统一操作（uniform），否则称为非统一操作（nonuniform）。

进行反缩放有两种方法：
第一种是求逆：
<center><img width="26%" src="CG/RTR/20.png"/></center>

第二种是使用齐次坐标，并在每次使用矩阵S之前进行归一化：
<center><img width="50%" src="CG/RTR/21.png"/></center>

#### 剪切 (Shearing)
剪切矩阵可以用于扭曲游戏中整个场景，以产生迷幻效果或扭曲模型的外观。剪切矩阵的第一个下标用于表示剪切矩阵正在更改哪个坐标，而第二个下标表示进行剪切的坐标：
<center><img width="26%" src="CG/RTR/22.png"/></center>
<center><img width="80%" src="CG/RTR/23.png"/></center>

### 级联变换 (Concatenation of Transforms)
由于矩阵上乘法运算的不可交换性，因此矩阵出现的顺序很重要。因此，变换的级联被认为是顺序相关的：

<center><img width="80%" src="CG/RTR/24.png"/></center>

将一系列矩阵的连接转换为单个矩阵的明显原因是为了提高效率。例如，假设你的游戏场景具有数百万个顶点，并且场景中的所有对象都必须缩放，旋转并最终平移。现在，不是将所有顶点与这三个矩阵中的每一个相乘，而是将这三个矩阵连接到一个矩阵中。然后将此单个矩阵应用于顶点。该复合矩阵为M = TRS。

注意这里的顺序。比例矩阵S应该首先应用于顶点，因此在合成中显示在右侧。该排序意味着TRSp = (T(R(Sp)))，其中p是要变换的点。顺便说一句，TRS是场景图系统（scene graph systems）常用的顺序。

### 刚体变换 (Rigid-Body Transform)
当一个人抓住一个坚固的物体时，例如从桌子上用笔将其移动到另一个位置，也许移动到衬衫的口袋里，只有物体的方向和位置会发生变化，而物体的形状通常不会受到影响。这种仅由平移和旋转的级联组成的变换称为刚体变换。

可以将任何刚体矩阵X表示为平移矩阵T(t)和旋转矩阵R的串联：

<center><img width="30%" src="CG/RTR/25.png"/></center>

#### LookAt矩阵
计算机图形中的常见任务是调整相机的方向，使其对准特定位置。

假设照相机位于c处，我们希望照相机看着目标l，并且照相机的给定方向为u'。我们要计算一个由三个向量{r,u,v}组成的基数。我们从计算视点向量为v=(c-1)/||c-1||开始，即从目标到摄像机位置的归一化向量。然后可以将向右看的向量计算为r=-(v×u')/||v×u'||。通常不能保证u'向量指向正上方，因此最终的向上向量是另一个叉积u=v×r。

<center><img width="70%" src="CG/RTR/26.png"/></center>

### 法线变换 (Normal Transform)
单个矩阵可用于一致地变换点，线，三角形和其他几何形状。矩阵还可以沿这些线或在三角形的曲面上变换切向量。但是，矩阵不能始终用于变换一个重要的几何特性，即表面法线（和顶点照明法线）。

下图左侧是原始几何图形，三角形以及从侧面显示的法线。中间的插图显示了如果模型沿 x 轴缩放 0.5，法线使用相同的矩阵会发生什么。右图显示了法线的正确变换：

<center><img width="70%" src="CG/RTR/27.png"/></center>

适当的方法不是使用矩阵本身相乘，而是使用矩阵的伴随项的转置相乘。

### 逆的计算 (Computation of Inverses)
在许多情况下都需要逆（inverses）。例如在坐标系之间来回切换时， 根据有关变换的可用信息，我们可以使用以下三种方法之一来计算矩阵的逆：
- 如果矩阵是单个变换或具有给定参数的简单变换序列，则该矩阵可以通过“反转参数”和矩阵顺序轻松地计算。举个例子，如果M=T(t)R(phi)，则M^(-1)=R(-phi)T(-t)。这很简单，并且保留了变换的准确性，这在渲染大世界时很重要。
- 如果已知矩阵是正交的，则M^(-1)=M^T，即转置为逆。旋转的任何序列都是旋转，因此是正交的。
- 如果没有任何已知条件，则可以使用伴随方法（the adjoint method），克莱姆法则（Cramer’s rule），LU分解（LU decomposition）或高斯消除法（Gaussian elimination）来计算逆。通常最好使用克莱姆法则和伴随方法，因为它们的分支操作较少； 在现代体系结构上最好避免使用“if”测试。

### 特殊矩阵变换与运算 (Special Matrix Transforms and Operations)
#### 欧拉变换 (The Euler Transform)
这种变换是构造矩阵以将自己（即相机）或任何其他实体定向到某个方向的一种直观方法。它的名字来自伟大的瑞士数学家莱昂哈德·欧拉（Leonhard Euler，1707–1783年）。

欧拉变换是三个矩阵的乘积，矩阵的顺序可以以24种不同的方式选择，这可以通过选择矩阵的顺序来实现。

由于E是旋转的串联，因此它也显然是正交的。因此，它的逆可以表示为E^(-1)=E^T=(R_zR_xR_y)^T=(R_x)^T(R_y)^T(R_z)^T，当然，直接使用E的转置会更容易。

欧拉角 ， 和  分别表示 head，pitch 和 roll 应按其顺序旋转以及绕其各自的轴旋转多少。有时，所有角度都称为“rolls”，例如，我们的“head”为“ y-roll”，而我们的“pitch”为“ x-roll”。另外，“head”有时也称为“yaw”，例如在飞行模拟中。

<center><img width="50%" src="CG/RTR/28.png"/></center>
<center>欧拉变换及其与更改 head，pitch 和 roll 的方式之间的关系</center>

#### 从欧拉变换中提取参数 (Extracting Parameters from the Euler Transform)
在某些情况下，使用从正交矩阵中提取欧拉参数 h，p 和 r 的过程很有用：

<center><img width="50%" src="CG/RTR/29.png"/></center>

将三个旋转矩阵串联起来：

<center><img width="90%" src="CG/RTR/30.png"/></center>

由此可见，pitch 参数由 sin(p)=e_21 给出。同样，将 e_01 除以 e_11，并类似地将 e_20 除以 e_22，会产生以下用于 head 和 roll 参数的提取公式：

<center><img width="60%" src="CG/RTR/31.png"/></center>

因此，如下所示，使用函数 atan2（y，x）从矩阵E提取欧拉参数h（head），p（pitch）和r（roll）：

<center><img width="20%" src="CG/RTR/32.png"/></center>

由于p不影响第一列中的值，因此当cos(p)=0时，我们可以使用sin(r)/cos(r)=tan(r)=e_10/e_00，得出r=atan2(e_01,e_00)。

!>根据反正弦的定义，-pi/2≤p≤pi/2，这意味着如果使用该间隔之外的p值创建E，则无法提取原始参数，因为h，p 和 r 不是唯一的。

!>使用欧拉变换时，可能会发生万向节死锁（gimbal lock），也就是旋转时，会失去一个自由度。举个例子，变换的顺序是 x/y/z。假设第二次旋转我们绕 y 轴旋转 pi/2，这样会旋转局部 z 轴以使其与原始 x 轴对齐，因此围绕 z 的最终旋转是不正确的。

#### 矩阵分解 (Matrix Decomposition)
到目前为止，我们一直在假设我们知道所使用的变换矩阵的初始状态和历史记录的情况下进行工作。通常情况下并非如此。例如，仅连接的矩阵可以与某个变换后的对象相关联。从级联矩阵中提取各种变换的任务称为<strong>矩阵分解（matrix decomposition）</strong>。

提取变换的原因有很多。用途包括：

- 为对象提取比例因子。
- 查找特定系统所需的变换。（例如，某些系统可能不允许使用任意 4×4 矩阵）
- 确定模型是否仅经历了刚体变换。
- 在动画中的关键帧之间进行插值，其中仅对象的矩阵可用。
- 从旋转矩阵中删除剪切。

#### 绕任意轴旋转 (Rotation about an Arbitrary Axis)
假设旋转轴 r 已归一化，并且我们需要创建一个围绕 e 旋转 alpha 弧度的变换。为此，我们首先变换到旋转轴所在的空间，这是通过一个 M 旋转矩阵完成的，然后执行实际的旋转，之后使用 M^-1 进行变换。

<center><img width="13%" src="CG/RTR/33.png"/></center>

该矩阵将向量 r 变换为 x 轴，将 s 变换为 y 轴，将 t 变换为 z 轴。因此，然后使围绕标准化向量 r 旋转 alpha 弧度的最终变换为：

<center><img width="20%" src="CG/RTR/34.png"/></center>

换句话说，这意味着首先我们进行变换，使 r 为 x 轴（使用 M），然后围绕该 x 轴旋转 alpha 弧度（使用 R_x(alpha)），然后使用 M 的逆函数进行变换 ，在这种情况下为 M^T，因为 M 是正交的。

Goldman提出了另一种通过 phi 弧度绕任意归一化轴 r 旋转的方法：

<center><img width="90%" src="CG/RTR/35.png"/></center>

### 四元数 (Quaternions)
四元数是复数的扩展，尽管它是威廉·罗恩·汉密尔顿爵士（Sir William Rowan Hamilton）于1843年发明的，但直到1985年，Shoemake才将它们引入计算机图形学领域。

>四元数用于表示旋转和方向。它们在几种方面都优于欧拉角和矩阵。任何三维定向都可以表示为围绕特定轴的单个旋转。四元数可用于稳定方向和恒定插值，而欧拉角无法很好地完成这些操作。

#### 数学背景 Mathematical Background
#### 定义
四元数q可以用以下所有等效的方式定义：

<center><img width="60%" src="CG/RTR/36.png"/></center>

变量q_w被称为四元数q的实部（real part）。虚部（imaginary part）为q_v，i，j和k称为虚单位（imaginary units）。
对于虚部q，我们可以使用所有法向向量运算，例如加法，缩放，点积，叉积等等。使用四元数的定义，得出两个四元数q和r之间的乘法运算，如下所示。注意，虚部的乘法是不可交换的。

#### 乘法（Multiplication）
我们使用叉积和点积来计算两个四元数的乘法:

<center><img width="50%" src="CG/RTR/37.png"/></center>

#### 加法（Addition）

<center><img width="50%" src="CG/RTR/38.png"/></center>

#### 共轭（Conjugate）

<center><img width="30%" src="CG/RTR/39.png"/></center>


#### 归一化（Norm）

<center><img width="40%" src="CG/RTR/40.png"/></center>


#### 恒等式（Identity）

<center><img width="13%" src="CG/RTR/41.png"/></center>

#### 逆（Inverse）

<center><img width="18%" src="CG/RTR/42.png"/></center>

#### 共轭规则（Conjugate rules）

<center><img width="20%" src="CG/RTR/43.png"/></center>


#### 归一化规则（Norm rules）

<center><img width="20%" src="CG/RTR/44.png"/></center>

#### 乘法定律（Laws of Multiplication）- 线性度（Linearity）

<center><img width="26%" src="CG/RTR/45.png"/></center>

#### 乘法定律（Laws of Multiplication）- 关联性（Associativity）

<center><img width="16%" src="CG/RTR/46.png"/></center>

#### 对数运算

<center><img width="30%" src="CG/RTR/47.png"/></center>

#### 幂运算

<center><img width="60%" src="CG/RTR/48.png"/></center>

#### 四元数变换 (Quaternion Transforms)

<center><img width="30%" src="CG/RTR/49.png"/></center>
<center>由单位四元数<img width="20%" src="CG/RTR/50.png"/>表示的旋转变换</center>

q的任何非零实数倍也表示相同的变换，这意味着q和-q表示相同的旋转。也就是说，取反轴u_q和实部q_w，将生成一个四元数，该四元数的旋转与原始四元数的旋转完全相同。这也意味着从矩阵中提取四元数可以返回q或 -q。

#### 矩阵转换（Matrix Conversion）
由于通常需要组合几个不同的变换，并且大多数变换都是矩阵形式，因此需要一种将四元数转换为矩阵的方法。四元数 q可以转换成矩阵M^q：

<center><img width="55%" src="CG/RTR/51.png"/></center>

在此，标量为 s=2/(nq)。对于单位四元数，这简化为：

<center><img width="55%" src="CG/RTR/52.png"/></center>

一旦构建了四元数，就无需计算三角函数（trigonometric functions），因此转换过程实际上是有效的。

从正交矩阵M^q到单位四元数q的反向转换要复杂得多：

<center><img width="20%" src="CG/RTR/53.png"/></center>

这些等式的含义是，如果q_w是已知的，则可以计算向量v_q的值，从而得出q：

<center><img width="55%" src="CG/RTR/54.png"/></center>

<center><img width="40%" src="CG/RTR/55.png"/></center>

为了具有稳定的数值，应该避免小数除法。因此，首先设置<img width="20%" src="CG/RTR/56.png"/>，由此得出：

<center><img width="40%" src="CG/RTR/57.png"/></center>

这又意味着 m_00,m_11,m_22 和 u 中的最大值确定 q_x, q_y, q_z, 和 q_w 中的哪个最大。如果 q_w 不是最大，则使用下式计算q_x,q_y,q_z的最大值：

<center><img width="38%" src="CG/RTR/58.png"/></center>

#### 球面线性插值（Spherical Linear Interpolation）
球面线性插值是在给定两个单元四元数q和r以及参数t∈[0,1]的情况下，计算插值四元数。

该运算的代数形式由下面的复合四元数s表示：

<center><img width="20%" src="CG/RTR/59.png"/></center>

但是，对于软件实现，以下形式更合适：

<center><img width="60%" src="CG/RTR/60.png"/></center>

slerp 代表球面线性插值(spherical linear interpolation)，为了计算该方程式所需的phi，可以使用以下事实：

<center><img width="40%" src="CG/RTR/61.png"/></center>

对于t∈[0,1]，slerp 函数计算（唯一）内插四元数，它们共同构成从q到r的二维单位球面上的最短弧。圆弧位于由q,r和原点之间的平面与三维单位球面的交点形成的圆上。计算出的旋转四元数以固定速度绕固定轴旋转。这样的曲线具有恒定速度，因此加速度为零，称为<strong>测地曲线（geodesic curve）</strong>。球体上的大圆是通过原点和球体的平面相交而生成的，这种圆的一部分称为<strong>大圆弧（great arc）</strong>。

<center><img width="30%" src="CG/RTR/62.png"/></center>
<center>单位四元数表示为单位球面上的点。slerp函数用于在四元数之间进行插值，并且插值路径是球面上的大弧</center>

!> 实际上，直接计算一个 slerp 是昂贵的操作，因为它涉及调用三角函数（trigonometric functions）

#### 从一个向量旋转到另一个向量（Rotation from One Vector to Another）
常见的操作是通过最短路径从一个方向s转换到另一个方向t。四元数的数学极大地简化了此过程，并显示了四元数与该表示形式的密切关系。

首先，将s和t归一化。然后计算称为u的单位旋转轴，其计算公式为u=(s×t)/||s×t||。接下来，e=s·t=cos(2phi)和||s×t||=sin(2phi),其中2phi是s和t之间的角度。那么表示从s到t的旋转的四元数为q=(sin(phi u),cos(phi)),使用半角关系和三角恒等式简化：

<center><img width="30%" src="CG/RTR/63.png"/></center>
<center><img width="50%" src="CG/RTR/64.png"/></center>

当s和t指向几乎相同的方向时，以这种方式直接生成四元数（相对于叉积s×t的归一化）避免了数值不稳定。当s和t指向相反的方向时，这两种方法都会出现稳定性问题，因为它们会被零除。当检测到这种特殊情况时，可以使用任何垂直于s的旋转轴旋转到t。

有时我们需要从s到t旋转的矩阵表示：

<center><img width="50%" src="CG/RTR/65.png"/></center>

在此等式中，我们使用了以下中间计算（intermediate calculations）：

<center><img width="38%" src="CG/RTR/66.png"/></center>

可以看出，由于简化，所有平方根和三角函数都消失了，因此这是创建矩阵的有效方法。

请注意，当s和t平行或接近平行时必须小心，因为||s×t||≈0。如果phi≈0，那么我们可以返回单位矩阵。但是，如果2phi≈pi，那么我们可以绕任何轴旋转pi弧度。该轴可以作为s与不平行于s的任何其他向量之间的叉积找到。

#### 顶点混合 (Vertex Blending)
顶点混合（Vertex blending）是解决柔性形变问题的一种流行解决方案。该技术还有其他几个名称，例如线性混合蒙皮（linear-blend skinning），包络（enveloping）或骨架子空间变形（skeleton-subspace deformation）。

<center><img width="70%" src="CG/RTR/67.png"/></center>

上图中，手臂由前臂和上臂组成，使用左侧的两个独立对象的刚体变换进行动画处理。肘部看起来不现实。在右侧，对一个对象使用顶点混合。最右边的手臂说明了当简单的蒙皮将两个部分直接覆盖以覆盖肘部时发生的情况。最右边的手臂说明了使用顶点混合时发生的情况，并且某些顶点以不同的权重进行了混合：（2/3，1/3）表示顶点对上臂的变换的权重为2/3，对前臂的变换的权重为。1/3。该图在最右边的插图中还显示了顶点混合的缺点。在这里，可以看到肘部内部的折叠。使用更多的骨骼和更精心选择的权重可以达到更好的效果。

通过进一步执行这一步骤，可以使单个顶点可以通过几种不同的矩阵进行变换，并将得到的位置加权并混合到一起。这是通过为动画对象设置骨骼来完成的，其中每个骨骼的变换可能会通过用户定义的权重影响每个顶点。由于整个手臂可能是“弹性的”，即所有顶点可能受到多个矩阵的影响，因此整个网格（mesh）通常称为（骨骼上的）蒙皮（skin）。

在数学上，这用如下公式表示，其中p是原始顶点，而u(t)是变换后的顶点，其位置取决于时间t：

<center><img width="60%" src="CG/RTR/68.png"/></center>

有 n个骨骼影响p的位置，这在世界坐标中表示出来。值w_i是顶点p的骨骼i的权重。M_i矩阵从初始骨骼的坐标系转换为世界坐标。通常，骨骼的控制关节位于其坐标系的原点。例如，前臂骨骼将其肘关节移动到原点，而动画旋转矩阵将手臂的这一部分绕关节移动。B_i(t)矩阵是第i个骨骼的世界变换，会随着时间变化以对对象进行动画处理，并且通常是多个矩阵的串联，例如以前的骨骼变换的层次结构和局部动画矩阵。

在实践中，对于动画的每一帧，为每个骨骼连接矩阵B_i(t)和(M_i)^-1，并且每个结果矩阵都用于变换顶点。顶点P由不同骨骼的级联矩阵转换，然后使用权重W_i进行混合，因此称为顶点混合（vertex blending）。权重是非负的，并且总和为1，因此发生的事情是将顶点转换到几个位置，然后在其中进行插值。这样，对于所有的i=0...n-1，变换后的点u将位于点集B_i(t)·(M_i)^-1·p(固定的t)的凸包中。

顶点混合非常适合在 GPU 上使用。网格中的顶点集可以放置在静态缓冲区中，该缓冲区会一次发送到 GPU 并重新使用。在每个框架中，只有骨骼矩阵会发生变化，而顶点着色器会计算它们对存储的网格的影响。这样，可以最大程度地减少在 CPU 上处理和从 CPU 传输的数据量，从而使 GPU 可以有效地渲染网格。如果可以将模型的整个骨矩阵一起使用，则是最简单的。否则，必须拆分模型并复制一些骨骼。或者，可以将骨骼变换存储在顶点访问的纹理中，从而避免达到寄存器存储限制。通过使用四元数表示旋转，每个变换可以仅存储在两个纹理中。如果可用，无序访问视图存储将允许重新使用蒙皮结果。

> 我们可以指定超出 [0,1] 范围或不等于 1 的权重集。但是，这仅在使用某些其他混合算法（例如变形目标，morph targets）时才有意义。

!> 基本顶点融合的一个缺点是可能发生不必要的折叠，扭曲和自相交。更好的解决方案是使用四元数。

基于四元数的蒙皮技术有助于保持原始变换的刚度，因此避免了四肢关节的扭曲。计算量不到线性蒙皮混合的成本的 1.5倍，并且效果很好：

<center><img width="60%" src="CG/RTR/69.png"/></center>
<center>左侧显示了使用线性混合蒙皮时关节处的问题。在右侧，使用双四元数混合可以改善外观</center>

#### 变形 (Morphing)
变形（Morphing）涉及解决两个主要问题，即顶点对应问题（the vertex correspondence problem）和插值问题（the interpolation problem）。给定两个任意模型，这些模型可能具有不同的拓扑（topologies），不同的顶点数量和不同的网格连接性，通常必须从建立这些顶点对应关系开始，这是一个困难的问题。

但是，如果两个模型之间已经存在一对一的顶点对应关系，则可以在每个顶点的基础上进行插值。也就是说，对于第一个模型中的每个顶点，在第二个模型中必须仅存在一个顶点，反之亦然。这使插值变得容易。例如，线性插值可以直接在顶点上使用。

为了计算时间t∈[t0,t1]的变形顶点，我们首先计算s=(t-t0)/(t1-t0)，然后进行线性顶点混合：

<center><img width="20%" src="CG/RTR/70.png"/></center>

其中p0和p1对应于同一顶点，但是处在不同的时间t0和t1。

用户具有更直观控制的变形变体称为变形目标（morph targets）或混合形状（blend shapes）：

<center><img width="80%" src="CG/RTR/71.png"/></center>

我们从一个中性模型开始，在这种情况下，它是一张脸。让我们用 N 表示该模型。此外，我们还有一组不同的脸部姿势。在示例中只有一个姿势，即一张笑脸。通常我们可以允许 k≥1 个不同的姿势，表示为 P_i,i∈[1...k]。作为预处理，“差异面”的计算公式为：D_i=P_i-N，即，从每个姿势中减去中性模型。

在这一点上，我们有一个中性模型 N 和一组差异姿势 D_i。然后可以使用以下公式获得变形模型 M：

<center><img width="20%" src="CG/RTR/72.png"/></center>

变形目标（Morph targets）是一种强大的技术，可为动画师提供很多控制，因为模型的不同特征可以独立于其他特征进行操纵。

#### 几何缓存回放 (Geometry Cache Playback)
在剪辑场景（cut scenes）中，可能希望使用极高质量的动画，例如，对于无法使用上述任何方法表示的运动。天真的方法是存储所有帧的所有顶点，从磁盘读取它们并更新网格。但是，对于短动画中使用的 30,000 个顶点的简单模型，这可能达到50 MB / s。

首先，使用量化（quantization）。例如，位置和纹理坐标使用每个坐标的 16 位整数存储。在执行压缩后无法恢复原始数据的意义上，这一步骤是有损的。为了进一步减少数据，进行了空间和时间预测，并对差异进行了编码。对于空间压缩，可以使用平行四边形预测。对于三角形带（triangle strip），下一个顶点的预测位置就是当前三角形在边缘周围的三角形平面中反射的三角形，从而形成平行四边形（parallelogram）。与新位置的差异接下来会被编码（encoded）。有了良好的预测，大多数值将接近零，这对于许多常用的压缩方案是十分理想的。与 MPEG 压缩类似，在时间维度上也会进行预测。也就是说，每  帧执行一次空间压缩。在这两者之间，将在时间维度上进行预测，例如，如果某个特定顶点通过增量向量从帧  移动到帧 ，则很可能以与帧  相似的量移动。这些技术减少了存储量，从而足以使该系统用于实时流数据。

### 投影 (Projections)
在实际渲染场景之前，必须将场景中的所有相关对象投影到某种平面或某种简单体积上。此后，执行裁剪和渲染。

#### 正交投影 (Orthographic Projection)
正交投影的特征是平行线在投影之后保持平行。当使用正交投影观看场景时，无论与相机的距离如何，对象都保持相同的大小。

用于执行正交投影的矩阵由六元组 (l,r,b,t,n,f) 表示，分别表示左侧（left），右侧（right），底部（bottom），顶部（top），近侧（near）和远侧（far）平面。该矩阵缩放并将由这些平面形成的与轴对齐的边界框（axis-aligned bounding box, AABB）转换为以原点为中心的与轴对齐的立方体。AABB 的最小角为 (l,b,n)，最大角为
是 (r,t,f)。重要的是要意识到 n>f，因为我们正在向下看 z 轴的负空间。我们的常识是，接近值应该比远端值低，因此，可以让用户按原样提供它们，然后在内部对它们取反（negate）。

在 OpenGL 中，与轴对齐的立方体的最小角为(-1,-1,-1)，最大角为(1,1,1)。在 DirectX 中，范围是(-1,-1,0)到(1,1,1)。此立方体称为规范视图体（canonical view volume），而该体积中的坐标称为规范化设备坐标（normalized device coordinates）。变换为标准视图体积的原因是在此处能够更有效地执行裁剪（clipping）。

<center><img width="80%" src="CG/RTR/73.png"/></center>
<center>变换规范视图体（canonical view volume）上的轴对齐框（axis-aligned box）。首先平移左侧的框，使其中心与原点重合。然后将其缩放以获取规范视图体的大小，如右侧所示</center>

变换为标准视图体（canonical view volume）后，将要渲染的几何图形的顶点裁剪（clipped）到该立方体上。最后，通过将剩余的单位正方形映射到屏幕来渲染不在立方体之外的几何图形。此正交变换如下所示：

<center><img width="70%" src="CG/RTR/74.png"/></center>

在计算机图形学中，投影后最常使用左手坐标系（left-hand coordinate system），即对于视口，x 轴向右，y 轴向上，而 z 轴进入视口。

DirectX 将 z 深度（z-depth）映射到 [0,1] 范围，而不是OpenGL的 [-1,1]。这可以通过在正交矩阵之后应用简单的缩放和平移矩阵来实现，即

<center><img width="30%" src="CG/RTR/75.png"/></center>

因此，DirectX中使用的正交矩阵为:

<center><img width="40%" src="CG/RTR/76.png"/></center>

#### 透视投影 (Perspective Projection)
透视投影比正交投影更复杂的变换是透视投影，它通常在大多数计算机图形应用程序中使用。在这里，平行线在投影后通常不平行； 相反，它们可能会在极端情况下收敛到单个点。透视更紧密地匹配我们如何感知世界，即，更远的物体更小。

<center><img width="80%" src="CG/RTR/77.png"/></center>
<center>使用相似三角形导出透视投影矩阵（perspective projection matrix）</center>

假设摄像机（视点）位于原点，并且我们要将一个点 p 投影到平面 z=-d,d>0，从而产生一个新点 q=(q_x,q_y,-d) 。图4.19 描绘了这种情况。从该图所示的相似三角形中，得出 q 的 x 分量的以下推导：

<center><img width="25%" src="CG/RTR/78.png"/></center>

q 的其他分量的表达式为 q_y=-dp_y/p_z（类似于 q_x 获得），q_z=-d。与上面的公式一起，它们给出了透视投影矩阵 P_p，如下所示：

<center><img width="20%" src="CG/RTR/79.png"/></center>

该矩阵可产生正确的透视投影，可通过以下方式确认:

<center><img width="60%" src="CG/RTR/80.png"/></center>

最后一步来自以下事实：整个矢量除以 w 分量（在这种情况下为 -p_z/d），最后得到 1。由于我们要投影到该平面上，因此所得的  z 值始终为 -d。

从直觉上讲，很容易理解为什么齐次坐标允许投影。齐次化过程的一种几何解释是将点 (p_x, p_y, p_z) 投影到平面 w = 1 上。

与正交变换（orthographic transformation）一样，还有一个透视变换（perspective transform），而不是实际投影到平面（不可逆）上，而是将视锥从视锥变换为前述的规范视像体。在这里，视锥视点假定从z=n开始并在z=f结束，且0>n>f。z=n处的矩形的最小角为(l, b, n)，最大角为(r, t, n)。

<center><img width="80%" src="CG/RTR/81.png"/></center>
<center>矩阵 P_p 将视锥体（view frustum）转换为单位立方体，称为标准视域（canonical view volume）</center>

参数(l,r,b,t,n,f)确定摄像机的视锥（view frustum）。水平视野由视锥的左右平面（由l和r决定）之间的角度确定。以相同的方式，垂直视野由顶平面和底平面之间的角度（由t和b确定）确定。视野越大，相机“看得越多”。可以通过r≠-l或t≠-b来创建不对称视锥（Asymmetric frusta）。不对称视锥可用于立体观看（stereo viewing）和虚拟现实（virtual reality）。

视野（the field of view）是提供场景感的重要因素。与计算机屏幕相比，眼睛本身具有物理视野。这种关系是：phi=2arctan(w/2d),其中 \phi 是视野，w 是垂直于视线的物体的宽度，d 是到物体的距离。

与物理设置相比，使用更窄的视野将减少透视效果，因为观看者将放大场景。设置较宽的视野将使对象看起来失真（例如使用广角相机镜头），尤其是在屏幕边缘附近，并且会放大附近对象的比例。然而，较宽的视野使观看者感觉到物体更大并且更令人印象深刻，并且具有向用户提供有关周围环境的更多信息的优点。

<center><img width="30%" src="CG/RTR/82.png"/></center>
<center>将视锥转化为单位立方体的透视变换矩阵</center>

将转换应用到一个点后，我们将得到另一个点q=(q_x, q_y, q_z, q_w)^T。此时的 w 分量 q_w（通常）将为非零且不等于1。要获得投影点p，我们需要除以 q_w。矩阵 P_p 总是将 z=f 映射为 +1，z=n 映射为 -1。

远平面以外的对象将被裁切，因此不会出现在场景中。另外，透视投影可以令远平面取到无穷远：

<center><img width="30%" src="CG/RTR/83.png"/></center>

综上所述，应用透视变换（以任何形式）P_p，然后进行裁剪和齐次化（除以 w），从而得到标准化的设备坐标。

以下是 OpenGL 中的透视投影矩阵公式：

<center><img width="35%" src="CG/RTR/84.png"/></center>

一个更简单的设置是仅提供垂直视场 phi，宽高比 a=w/h（其中 w×h 是屏幕分辨率），n'和 f'，于是：

<center><img width="35%" src="CG/RTR/85.png"/></center>

这是 DirectX 公式(将近平面映射到 z=0（而不是 z=-1），而将远平面映射到 z=1)：

<center><img width="35%" src="CG/RTR/86.png"/></center>

!> 近平面和远平面的放置会影响 z 缓冲区的精度

#### 增加深度精度的方法
有几种增加深度精度的方法。一种常见的方法（我们称为反向 z， reversed z）是使用浮点深度或整数存储1.0-z_NDC。

<center><img width="80%" src="CG/RTR/87.png"/></center>

使用 DirectX 变换设置深度缓冲区的不同方法，即z_NDC∈[0,+1]。

左上方：标准整数深度缓冲区，此处显示为4位精度（因此 y 轴上有 16 个标记）。

右上角：远平面设置为 ∞，两个轴上的微小偏移表明这样做不会损失太多精度。

左下：具有3个指数位和 3 个尾数位用于浮点深度。由于分布在y轴上是非线性的，这使得在x轴上的分布更糟。

右下角：反转的浮点深度，即1-z_NDC，结果分布更好。

Lloyd提出使用深度值的对数来提高阴影贴图的精度。Lauritzen等使用前一帧的 z 缓冲区（z-buffer）来确定最大近平面和最小远平面。对于屏幕空间深度，Kemen建议对每个顶点使用以下重新映射：

<center><img width="50%" src="CG/RTR/88.png"/></center>

其中w是投影矩阵之后的顶点的 w 值，而 z 是顶点着色器的输出 z。常数 f_{c} 为 f_{c}=2/\textrm{log}_{2}(f+1)，其中 f 为远平面。当仅在顶点着色器中应用此变换时，深度仍将由 GPU 在顶点的非线性变换深度之间在三角形上线性插值。由于对数是单调函数，因此只要分段线性插值与精确的非线性变换深度值之间的差异较小，遮挡剔除硬件和深度压缩技术仍将起作用。在大多数情况下，具有足够的几何细分的情况是正确的。但是，也可以对每个片段应用转换。这是通过输出每个顶点的值 e=1+w 来完成的，然后由 GPU 在三角形上进行插值。然后，像素着色器将片段深度修改为 log^2(e_i)f_c/2，其中 e_i 是 e 的内插值。当 GPU 中没有浮点深度并且使用深度较大的距离进行渲染时，此方法是不错的选择。

Cozzi建议使用多视锥（multiple frusta），这可以提高准确度以有效地达到任何期望的比率。视锥在深度方向上分为几个不重叠的较小的子视锥，它们的联合恰好是视锥。子视锥表以从后到前的顺序渲染。首先，清除颜色和深度缓冲区，并将所有要渲染的对象分类到它们重叠的每个子视锥中。对于每个子视锥，设置其投影矩阵，清除深度缓冲区，然后渲染与子视锥重叠的对象。


## Chapter 5 - Shading Basics - 着色基础
> 无论是写实（realistic）还是风格化（stylized），我们都会先讨论材质和光源的定义，还有它们是如何呈现出我们期望的表面外观（appearance）。<br>此章节介绍一些表面外观相关的话题，例如通过抗锯齿（也称反走样，Antialiasing）、透明度(Transparency)、伽马校正（Gamma Correction）来提供更高质量的图像

渲染三维对象的图像时，模型不仅应具有适当的几何形状，而且还应具有所需的视觉外观。根据应用程序的不同，其范围可以从照片写实（外观与真实对象的照片几乎相同）到出于创造性原因选择的各种类型的风格化外观。

### 着色模型 (Shading Models)
决定渲染物体的外观的第一步是选择一个渲染模型（shading model）用来描述物体的颜色应该怎样变化，相关的因素有表面方向（surface orientation），视角方向（view direction），以及光照（lighting）等等。

### 光源 (Light Sources)
现实世界中的光照可能非常复杂，可以有多个光源，每个光源都有自己的大小，形状，颜色和强度，而且间接光照会带来更多变化。但实时渲染中通常我们只考虑有限数量个主要光源对表面着色的影响。

着色模型通常可以被拆解为亮部和暗部，光照强度k_light线性地改变亮部颜色：

<center><img width="40%" src="CG/RTR/89.png"/></center>

它可以被简单地扩展到多光源形式：

<center><img width="40%" src="CG/RTR/90.png"/></center>

无光照部分f_unlit将光视为二进制的着色模型的“不受光影响时的外观”。它可以具有各种形式，具体取决于所需的视觉效果和应用程序的需求。

<center><img width="60%" src="CG/RTR/91.png"/></center>
<center>大多数着色模型所使用的单位长度向量表示：表面法线n，视图向量v和光照方向l</center>

如果光照方向l与表面法线n的距离大于90°，则光源不会影响表面点，因此光照的计算结果通常需要被clamp到[0,1]范围。

### 实现着色模型 (Implementing Shading Models)
#### 计算频率 (Frequency of Evaluation)
当设计一个着色实现时，首先，要确定给出的计算结果是否总是在一个绘制调用（draw call）中保持恒定。例如：一个常量表达式，它的计算可能在着色器编译的时候就完成了，这种情况下甚至不需设置一个uniform着色器输入，用一个离线的预计算pass来计算这个常量即可。另一种情况是，着色计算的结果在应用程序执行时不断变化，但是这个变化很慢，以至于不需要在每一帧都进行更新。

其他情况下，每帧执行一次的计算，例如透视矩阵；或每个模型执行一次的计算，例如根据位置更新模型的光照参数；或每次绘制调用（draw call）执行一次的计算，例如更新模型中每种材质的参数等。基于计算频率，我们将uniform输入着色器分组，这样有助于提高应用程序的效率，并且还可以通过最小化常量更新（minimizing constant updates）来提高 GPU 的性能。

如果着色计算的结果在一个绘制调用中不断变化，那么它就不能由一个统一的着色器输入传到着色器中。取而代之的是，它必须在可编程着色阶段之一中被计算，并且如果需要的话，会通过不同的着色器输入传到其他阶段。理论上，着色计算能在任何一个可编程阶段上执行，其中每个都对应着不同的计算频率：
- 顶点着色器（Vertex shader） —— 计算每个曲面细分前的顶点
- 外壳着色器（Hull shader） —— 计算每个表面补丁
- 域着色器（Domain shader） —— 计算每个曲面细分后的顶点
- 几何着色器（Geometry shader）—— 计算每个图元
- 像素着色器（Pixel shader）—— 计算每个像素

大部分着色计算是逐像素执行的。尽管这些通常是在像素着色器中实现的，但是计算着色器的实现正变得越来越普遍。

原则上来说，可以在像素着色器中仅计算着色模型的镜面高光部分（specular highlight），而在顶点着色器中计算其余部分。这可能不会导致视觉伪像（visual artifacts），并且理论上将节省一些计算。然而在实践中，这种混合实现通常不是最佳的。着色模型的线性变化部分往往在计算上花费最少，并且以这种方式拆分着色计算往往会增加相当多的开销，例如重复计算和额外的变化输入，从而导致弊大于利。

!> 需要注意的是，即使顶点着色器总是生成单位长度表面法线，插值也是能改变其长度的。因此，法线需要在像素着色器中重新归一化（缩放至长度为 1）。

<center><img width="80%" src="CG/RTR/92.png"/></center>
<center>在左侧，我们看到跨越表面的单位法线的线性插值将导致插值后的向量长度小于1。在右侧，我们看到法线的线性插值有着明显不同的长度，这导致了插值后的方向朝着两个法线中较长的倾斜</center>

> 与表面法线不同，指向特殊位置的向量，例如视图向量（view vector）和精确光的光向量（light vector），通常是不进行插值的。取而代之的是，在像素着色器中插值后的表面位置将被用来计算这些向量。

<center><img width="80%" src="CG/RTR/93.png"/></center>
<center>两个光向量间的插值。在左侧，在插值前将它们归一化将导致归一化后方向不正确。在右侧，对未归一化向量插值，得到了正确的结果</center>

#### 平面着色 (flat shading)
原则上，可以在几何着色器中执行平面着色（flat shading），但是近年来相关的实现通常是使用顶点着色器。这是通过将每个图元的属性与其第一个顶点相关联并禁用顶点值插值来完成的。

> 禁用插值（可以为每个顶点值分别处理）将使得第一个顶点的值传递到图元中的所有像素。

#### 材质系统 (Material Systems)
渲染框架很少只实现单个着色器。通常来说，需要一个专用的系统来处理大量的材质，着色模型，以及应用程序所使用的着色器。

一个着色器是用于 GPU 的可编程着色阶段之一的一个程序。因此，着色器是低级的图形 API 资源，并且不是美术人员会直接接触的。相反，材质是面向美术人员封装的表面的视觉表现。

虽然材质通过着色器被实现，但这不是一个简单的一对一对应。在不同的渲染情况下，相同的材质可能使用不同的着色器。一个着色器也可能被多种材质共用。最普遍的情况是材质参数化。在它的最简单形式中，材质参数化需要两种类型的材质实体： 材质模板（material templates）与材质实例（material instances）。每个材质模板描述一类材质并且有一个参数的集合，它可以根据参数类型的不同去分配不同的值，有数值，颜色，或者贴图。每个材质实例对应着一个材质模板与所有参数的一组特定值。

参数可以在运行时被解析，通过统一的输入传递到其他着色器程序，或者也可以在编译时，通过在着色器编译前替换值来解析参数。一个常见的编译时参数类型是布尔开关，它用来控制激活给定材质的特征。这可以由美术人员通过材质 UI 的勾选框去设置，或者由材质系统在程序上去设置，例如远处的物体，它们的视觉效果特征可以忽略不计，此情况设置关闭可以减少着色器消耗。

尽管材质参数可以与着色模型参数一对一匹配，但我们不是总会遇到这种情况。一个材质可能会修改一个给定着色模型参数的值，例如表面颜色，可修改为一个常量。或者，可以将多个材质参数以及插值的顶点或纹理值作为输入，通过一系列复杂的操作来计算着色模型参数。在地形材质中，基于表面位置与方向的着色是尤为普遍的。举个例子，高度与表面法线可以被用来控制积雪特效，做法是在高处的水平面和接近水平面的表面以白色表面颜色做混合。基于时间的着色通常用于动画材质，例如闪烁的霓虹灯标志。

材质系统的最重要任务之一是将多种着色器函数划分为单独的元素，并控制这些元素的组合方式。在许多情况下，这种组合是很有用的，包括以下几种情况：

- 将表面着色与几何处理组合在一起，例如刚体变换，顶点混合，变形，曲面细分，实例化，以及裁剪。这些功能都是各不相同的：表面着色器依赖于材质，几何处理依赖于模型网格。所以，分开编写他们以及让材质系统根据需求组合他们是很方便的。
- 将表面着色与一些组合操作例如像素丢弃（discard）与混合（blending）组合在一起。这与移动端 GPU 是尤为相关的，在移动端 GPU 的像素着色器里，混合是一种普遍执行的操作。通常我们希望独立于表面着色用材质来选择这些操作。
- 将用来计算着色模型参数的操作与着色模型自身的计算组合在一起。这种方式允许编写一次着色模型的实现，并且与多种不同计算着色模型参数的方式组合在一起去重用它。
- 将独立可选的材质特征相互组合，以及与选择逻辑、剩余的着色器组合在一起。这种方式允许分开编写每个特征的实现。
- 将着色模型、其参数的计算与光源计算组合在一起：在每个光源的着色点计算c_light与l的值。例如延迟渲染的技术改变了这个组合的结构体。在支持该技术的渲染框架里，这种方式将额外增加复杂度。

> 早期的渲染系统有着相对较小数量的着色器变体，并且通常是手动去编写每个变体。这也有一些好处的。例如，可以在充分了解最终的着色器程序的基础上去优化每个变体。然而，这种手动编写的方法随着着色器变体数量的增加而变得不切实际。当我们将所有不同部分和选项都纳入考虑时，所有可能的不同着色器变体数量是巨大的。这就是为什么模块化和可组合性是如此的关键。

当设计一个系统用来处理着色器变体时，第一个需要解决的问题是，不同选项间的选择是否是通过动态分支（dynamic branching）在运行时执行，或者是在编译时通过条件预处理（conditional preprocessing）执行。在较老的硬件上，动态分支通常是不可能的或者是速度极慢的，所以运行时的选择是不可行的。随后所有变体都在编译阶段被处理，包括不同光源类型计数的所有可能组合。

相反，如今的 GPU 能够很好地处理动态分支，尤其是当分支行为对于一个绘制调用中所有像素都是相同的情况下。现在许多功能性变体，例如光源的数量，都在运行时被处理。然而，为一个着色器添加大量的功能变体将产生一个不同的消耗：寄存器计数（register count）的增加和占用率的相应降低，进而导致性能下降。

举个例子，让我们想象一个支持三种不同类型光源的应用程序。其中两种光源类型很简单：点光源与方向光。第三种类型是通用的聚光灯，它支持列表照明模式以及其他复杂的功能，这需要大量的着色器代码去实现。然而，这个通用的聚光灯使用率相对较小，此应用程序中只有不到 5% 的光源是这种类型。在过去，一个单独的着色器变体会为每个可能的三类光源计数的组合去编译，以避免动态分支。尽管在如今这种方式已不再需要，但是编译两个单独的变体仍然是有好处的，一个变体适用于通用聚光灯数量大于等于一时，另一个变体适用于此类聚光灯数量正好为 0 时。由于它更简单的代码，第二个变体（更常使用）可能有着更低的寄存器占用率，并且因此有着更高的性能表现。

> 现代材质系统同时使用了运行时着色器变体和编译时着色器变体。即使完整的负载已经不会仅在编译时处理，但总体的复杂度与变体的数量仍然保持增长，所以还是需要编译大量的着色器变体。

### 走样与反走样 (Aliasing and Antialiasing)
三角形在像素里的显示是要么存在，要么不存在。线的绘制也有类似的问题。因此，边缘有着锯齿状的外观，这种视觉伪像（visual artifact）被称作“锯齿”（the jaggies），当物体运动时则被称作“爬虫”（crawlies）。关于此问题的更正式的称呼为“走样”（aliasing），并且，旨在避免这个问题的相关技术我们称为“反走样”（antialiasing）。

在计算机图形中走样的普遍案例有光栅化的线与三角形边的“锯齿”，被称为“萤火虫”（fireflies）的闪烁的高光，以及缩小具有方格图案的纹理时发生的走样。

<center><img width="50%" src="CG/RTR/94.png"/></center>
<center>三个不同反走样级别的三角形、线、点。下排图像是上排图像的放大。最左列每个像素仅用一个采样，这意味着没有使用反走样技术。中间列的图像以每像素四个采样（以网格模式）的方式渲染，最右列则是使用每像素八个采样</center>

#### 采样与滤波理论 (Sampling and Filtering Theory)
渲染图像的处理本身便是一个采样任务。之所以这样是因为图像的生成就是三维场景采样的处理过程，其目的是为图像中的每个像素（一个离散的像素数组） 去获取相应的颜色值。

> 注：纹素（英语：Texel，即textureelement或texture pixel的合成字）是纹理元素的简称，它是计算机图形纹理空间中的基本单元。如同图像是由像素排列而成，纹理是由纹素排列表示的。

下图展示了一个连续的信号是怎样以均匀的间隔被采样的，即离散化（discretized）。采样处理的目标是数字化地去呈现信息。这样做可以减少信息量。然而采样的信号需要被重建（reconstructed）以恢复原始信号。这是通过对采样信号进行滤波来完成的。

<center><img width="80%" src="CG/RTR/95.png"/></center>
<center>一个连续信号（左图）被采样（中图），并且接下来原始信号通过重建以恢复（右图）</center>

无论何时进行采样，都可能出现走样。这是我们不想造成的伪像（artifacts），并且我们需要与走样进行战斗以生成令人满意的图像。老的西方人见过的一个关于走样的经典案例，是电影摄像机拍摄的一个旋转的马车车轮。由于车轮辐条移动得比摄像机记录图像的速度快得多，车轮看起来像是在向后或向前缓慢旋转，或者甚至有可能看起来根本没有转动。之所以会出现这种现象，是因为车轮的图像是以一系列时间步长被记录的，这被称作时间走样（temporal aliasing）。

当一个信号被以过慢的频率采样时，走样就会出现。为了使一个信号被合适地采样（换句话说，这样就能够从样本中重建原始信号），采样频率必须大于被采样信号最大频率的两倍。这通常被称作采样定理（sampling theorem），并且该采样频率以一位在 1928 年发现此频率的瑞典科学家 哈里·奈奎斯特（Harry Nyquist） (1889–1976) 命名，被称为奈奎斯特率（Nyquist rate）或奈奎斯特极限（Nyquist limit）。该定理使用术语“最大频率”的这一事实暗示着信号应该受到频带限制（band-limited），这仅仅意味着任何频率都不能超过特定限制。换句话说，信号相对于相邻样本间的间隔应该足够平滑。

#### 重建 (Reconstruction)
给定一个频带限制的采样信号后，我们现在来讨论原始信号是怎样从采样信号去重建的。为了做到这点，我们必须用到一个滤波器。三个普遍使用的滤波器如下图所示。需要注意的是，滤波器的区域应该总是为单个的，否则重建的信号可能会扩大或收缩。

<center><img width="80%" src="CG/RTR/96.png"/></center>
<center>左上图为 box 滤波器（box filter），右上图为 tent 滤波器（tent filter）。底部为 sinc 滤波器（在这里已经 clamped 在 x 轴上）</center>

如下图，采样后的信号（左侧）使用 box 滤波器进行重建。这是通过以下步骤完成的：首先在每个采样点上放置 box 滤波器，并且在 y方向上将其缩放，这样滤波器的高度与采样点就是相同的。之后求出的和就是重建后的信号（右侧）。

<center><img width="80%" src="CG/RTR/97.png"/></center>
<center>采样后的信号（左侧）使用 box 滤波器进行重建</center>

box 滤波器（最近的相邻处）是最糟糕的滤波器，因为产生的信号是一个非连续的阶梯状。然而由于它很简单，所以仍然经常在计算机图形学中使用。如上图所示，box 滤波器被放置在每个采样点上，并且之后会被缩放，这样滤波器最上方的点就可以与样本上的点重合。所有这些缩放与平移后的 box 函数之和就是右侧所示的重建后的信号。

box 滤波器可以替换成任意其他滤波器。例如，tent 滤波器，也被称作三角形滤波器，被用来重建采样后的信号。需要注意的是这个滤波器在相邻采样点之间实现了线性插值，所以它比 box 滤波器要更好，因为重建的信号现在是连续的。

<center><img width="80%" src="CG/RTR/98.png"/></center>
<center>采样后的信号（左侧）使用 tent 滤波器去进行重建。重建后的信号如右侧所示</center>

然而，使用 tent 滤波器重建的信号的平滑程度并不好；在采样点有着突然的斜率改变。这与以下事实有关： tent 滤波器并不是一个完美的重建滤波器。为了得到完美的重建，必须使用理想的低通滤波器。其中信号的频率分量是正弦波：sin(2pi·f)，f是该分量的频率。鉴于此，低通滤波器将去除频率高于滤波器定义的某个频率的所有频率分量。直觉上来看，低通滤波器移除了信号的尖锐特征，即滤波器对信号进行了模糊处理。理想的低通滤波器是 sinc 滤波器。

<center><img width="80%" src="CG/RTR/99.png"/></center>
<center>这里 sinc 滤波器被用来重建信号。sinc 滤波器是理想的低通滤波器</center>

傅里叶分析的理论解释了为什么 sinc 滤波器是理想的低通滤波器。简单来说，理由如下：理想的低通滤波器是频率域的 box 滤波器，当它与信号相乘时，移除了所有高于滤波器宽度的频率。将 box 滤波器从频率域转到空间域会得到 sinc 函数。与此同时，乘法操作被转换为了卷积（convolution）函数，卷积是我们在本节中一直使用的，但没有实际描述过的术语。

正如上图所示，使用 sinc 滤波器去重建信号能得到更平滑的结果。采样过程在信号中引入了高频部分（突变），并且低频滤波器的任务是移除这些高频部分。事实上， sinc 滤波器用频率高于 1/2 的采样率计算了所有的正弦波。sinc 函数，如公式 5.22 所示，当采样频率是 1.0 时（即采样信号的最大频率必须小于 1/2），它是完美的重建滤波器。更普遍地来说，假设采样频率是f_s，也就是说，相邻样本间隔为1/f_s。对这种情况来说，完美的重建滤波器是sinc(f_s(x))，并且它计算了所有高于f_s/2的频率。

!> 然而 sinc 的滤波器宽度是无限的，并且在某些区域是负值，所以它在实践中很少有用。

> 在使用任意滤波器之后，便得到了一个连续的信号。然而，在计算机图形学中我们不能直接显示一个连续的信号，但是我们可以使用它们去对连续信号进行重采样并得到另一个大小，即放大或缩小信号。

#### 重采样 (Resampling)
重采样被用来放大后者缩小一个采样信号。将设原采样点位于整数坐标系内（0,1,2,...），即样本间的间隔是单位整数。更进一步的，假设在重采样后，我们想要新的采样点以样本的间隔 a 均匀地放置。对于 a > 1，使用缩小（下采样），对于 a < 1，使用放大（上采样）。

放大是两种情况中较为简单的一个，所需要的便是以我们期望的间隔去重采样重建后的信号。

<center><img width="80%" src="CG/RTR/100.png"/></center>
<center>在左侧，是采样信号与重建新号。在右侧，重建新号已经以两倍的采样频率进行重采样，即进行了放大</center>

然而，当缩小时，这个技术不起作用。原始信号的频率对采样率来说过高，以至于无法避免走样。

sinc(x/a)被证明可以用于从采样信号中创建连续信号，之后便可以期望的间隔进行重采样。换句话说，通过使用sinc(x/a)作为滤波器，低通滤波器的宽度增加了，以至于更多的信号高频率内容被移除了。

如图所示，（独立 sinc 函数的）滤波器宽度被翻倍以减少重采样率，并使原采样率减半。将此与数字图像联系起来，这与一开始进行模糊操作（为了移除高频率部分）是相似的，然后以低分辨率对图像进行重采样。

<center><img width="80%" src="CG/RTR/101.png"/></center>
<center>在左侧是采样信号与重建信号，在右侧，滤波器宽度已经放大为原来的两倍以使样本间隔也变为原来的两倍，即进行了缩小</center>

#### 基于屏幕空间的反走样 (Screen-Based Antialiasing)
如果采样与滤波的效果不好，三角形的边缘会产生明显的伪像（artifacts）。阴影边缘，高光，以及颜色迅速变化的其他现象都可能导致类似的问题。

> 并没有最佳的反采样技术，因为对画面品质而言，这些技术都有各自的有点，例如捕捉清晰的细节或者其他现象的能力，运动时的表现，内存消耗，GPU 要求，以及速度等等。

如果只在每个像素的网格单元中心进行单个采样，通常无法得到准确的渲染结果。通过在每个屏幕网格单元使用更多的采样并以一些方式将它们混合，就能计算出更好的像素颜色。

下图中，在左侧，以像素中心的一个样本去渲染一个红色三角形。因为三角形并没有覆盖样本，像素是白色，即使像素的大部分已经被红色三角形覆盖。在右侧，对每个像素使用了四个采样点，正如我们所见，其中两个采样点被红色三角形所覆盖，因此像素为粉红色

<center><img width="70%" src="CG/RTR/102.png"/></center>
<center>多重采样</center>

基于屏幕的反走样方案的一般策略是使用一个针对屏幕的采样模式，并且对这些样本进行加权与求和，以得出像素的颜色p：

<center><img width="30%" src="CG/RTR/103.png"/></center>

其中 n 是用于单个像素的采样数。函数c(i,x,y)是一个采样颜色，w_i是权重，范围是 [0,1]，样本对整个的像素颜色有所贡献。样品的位置根据其在序列中的顺序来确定，如 1，……，n，并且可选的函数也是使用像素位置 (x,y) 的整数部分。换句话说，每个样本在屏幕网格的采样位置都是不同的，并且可选的采样模式可以对每个像素都不同。在实时渲染系统（以及大多数其他渲染系统）中，样本通常是点样本。所以，函数 c 可以被认为是两个函数。首先，函数 f(i,n) 检索屏幕上需要样本的浮点 (x_f,y_f) 。然后对屏幕上的该位置进行采样，即检索该精确点处的颜色。选择采样方案，并且配置渲染管线以计算特定子像素位置的采样，这通常基于逐帧（或逐应用）设置。

在反走样中的另一个变量是 w_i，每个样本的权重。这些权重的和为 1。大部分用于实时渲染系统的方法都对它们的样本给出了统一权重，即 w_i=1/n。图形硬件的默认模式，像素中心的单个采样，是上述反走样方程的最简单情况。只有一个项，该项的权重为 1，并且采样函数 f 总是返回被采样像素的中心。

反走样算法计算每个像素时，如果使用超过一个完整的采样，就被称作超级采样（或过采样）方法。概念上最简单地说，全场景反走样（full-scene antialiasing, FSAA），又名“超级采样反走样”（supersampling antialiasing, SSAA），以更高的分辨率渲染场景，然后对相邻的样本进行滤波以得到图像。举个例子，假设我们需要一张 1280 x 1024 像素的图像。如果你在屏幕外渲染一个 2560 x 2048 像素的图像，然后对每 2 x 2 的像素区域取平均值，之后在屏幕上显示，我们需要的图像就会以每像素四个采样，并使用 box 滤波器去进行滤波。

!> 需要注意的是，这相当于图 5.25 中的 2 x 2 网格采样。此方法较为消耗性能，因为所有的子采样必须被完整地着色与填充，其中每个样本都具有 z 缓冲区的深度信息。

FSAA 的主要优点在于简单。这种方法的其他低质量版本只在一个屏幕轴向上以两倍的速率采样，因此被称为 1 x 2 或 2 x 1 超级采样。通常来说，为了简化起见，使用二次幂分辨率和 box 滤波器。英伟达（NVIDIA）的动态超分辨率（dynamic super resolution）功能是一个更加复杂的超级采样形式，其中以更高的分辨率渲染场景，并且使用 13 个采样的高斯滤波器去生成显示图像。

<center><img width="80%" src="CG/RTR/104.png"/></center>
<center>一些像素采样方案的对比，按照逐像素采样数从少到多排列。Quincunx 共享角落的样本以及中心样本进行加权，以使其值达到像素最终颜色的一半。2 × 2 旋转网格比 2 × 2 直形网格在几乎水平的边缘上会捕获更多的灰度级。类似地，尽管使用的样本较少，但 8 rooks 图案捕获的此类线条比 4 × 4 网格捕获的灰度级别更多</center>

一个与超级采样相关的采样方法是基于累积缓冲区（accumulation buffer）的。该方法不使用一个大的屏幕外缓冲区，而是使用一个与最终期望图像具有相同分辨率的缓冲区，但是每个颜色通道使用更多的字节位。为了得到一个场景的 2 x 2 采样，生成四幅图像，视图根据需要在屏幕 x 轴或 y 轴上移动半个像素。每个生成的图像都是基于网格单元内的不同采样位置。每帧必须重新渲染场景几次，并将结果复制到屏幕上，这种额外费用使该算法在实时渲染系统中成本很高。当性能问题不关键时，这种方法对生成高质量的图像来说是很有用的，因为每个像素可以使用任何数量的样本，并且可以放置在任何地方。累积缓冲区曾经是硬件中单独的一部分。它直接被 OpenGL API 所支持 ，但是在 3.0 版本中被弃用。在现代 GPU 中，累积缓冲区这个概念可以通过在输出缓冲区使用高精度的颜色格式，从而在像素着色器中实现。

当物体边缘、镜面高光和锐利阴影等现象引起突变的颜色变化时，需要额外的采样样本。阴影通常能够变得更软，以及高光可以变得更平滑以避免走样。可以增加特定对象的大小，例如电线，以确保它们在长度上每个位置覆盖至少一个像素。物体边缘的走样仍然是一个主要的采样问题。在渲染时物体边缘被检测以及它们的影响被考虑在内时，可以使用分析方法，但是这些方法通常更为昂贵，并且相比简单地进行更多的采样，它的鲁棒性要更低。然而，GPU 的功能例如保守光栅化和光栅化顺序视图开启了新的可能性。

多重采样反走样（Multisampling antialiasing，MSAA）通过一次的逐像素计算表面着色，并在样本间共享计算结果，从而降低了高额的计算成本。每个片元有四个(x,y)样本位置，每个都有它们自己的颜色与 z 深度值，但是对于像素的每个物体的片元，像素着色器只计算一次。如果所有的 MSAA 位置样本都被片元覆盖，那么着色样本就会在像素的中心被计算。相反，如果片元覆盖较少的位置样本，则着色样本的位置可以移动，以更好地表示所覆盖的位置。举个例子，这么做可以避免纹理边缘之外的着色采样。

> 这种位置调整方法被称作质心采样（centroid sampling）或质心插值（centroidinterpolation），并且如果开启该功能的话，该过程会由 GPU 自动完成。质心采样可以避免出现三角形外的问题（off-triangle problems），但会导致导数计算返回不正确的值。

<center><img width="80%" src="CG/RTR/105.png"/></center>
<center>在中间，一个像素中的两个物体重叠。红色物体覆盖了三个样本，蓝色物体只有一个。像素着色器计算位置以绿色显示。因为红色三角形覆盖了像素的中心，这个位置被用作着色器计算。用于蓝色物体的像素着色器在对应的样本位置进行计算。对于 MSAA 来说，分离的颜色与深度值被储存在所有四个位置中。在右侧展示了 EQAA 的 2f4x 模式。四个样本现在有四个 ID 值，这些 ID 索引了一张存储起来的表，表内有两种颜色和深度的信息</center>

MSAA 比纯粹的超级采样方案快是因为<strong>片元只进行一次着色</strong>。它致力于以高频率对片元的像素覆盖区域进行采样，以及共享计算出的着色数据。通过进一步分离采样和覆盖范围，可以节省更多的内存，这反过来又可以使反走样的速度更快——使用的内存越少，渲染速度就越快。英伟达（NVIDIA）在 2006 年推出了覆盖采样反走样（coverage sampling antialiasing，CSAA），并且 AMD 随后推出了增强质量反走样（enhanced quality antialiasing，EQAA）。这些技术通过以更高的采样率并且仅储存片元的覆盖范围来实现。举个例子，EQAA 的 “2f4x” 模式存储了两个颜色与深度值，在四个样本位置之间共享。颜色与深度值信息不再储存在特定的位置里，而是储存在一张表中。四个样本每个只需要一位（bit）空间用来指定两个存储值中的哪个与其位置相关联。

一旦所有的几何体被渲染到一个多重采样缓冲区时，会执行一个解析（resolve）操作。这段程序会将样本颜色总体进行平均以决定像素的颜色。值得注意的是，当使用具有高动态范围颜色值的多重采样时，可能会出现一个问题。在这种情况下，为了避免伪像（artifacts），在进行解析操作前，通常需要对值进行<strong>色调映射(Tone Mapping)</strong>。

默认的情况下，MSAA 通过 box 滤波器进行解析。在 2007，ATI 推出了自定义滤波器反走样（CFAA），它能够使用更狭窄或更宽的 tent 滤波器并且稍微拓展到其他像素格。之后支持了EQAA，从而取代了这个模式。在现代 GPU 上，像素或者计算着色器能够访问 MSAA 的样本并且使用任何我们所期望的重建滤波器，包括从周围像素中采样的样本。

虽然一个更宽的滤波器会丢失锐利的细节，但它能够减少走样。佩蒂诺（Pettineo）发现立方体的 smoothstep 以及有着 2 或 3 像素宽度的 B 样条滤波器在总体上得出了最好的结果。当然还有性能消耗，因为即使使用自定义着色器模拟默认的 box 滤波器解析也会花费很长的时间，而一个更宽的滤波器核心意味着增加了样本的访问成本。

英伟达（NVIDIA）的内置支持的 TXAA ，类似地在比单个像素更大的区域上使用了更好的重建滤波器，以提供更好的结果。它和更新的 MFAA（多帧反走样，multiframe antialiasing）方案都使用了 TAA（时间性反走样，temporal antialiasing），这是一类通用技术，它可以使用之前帧的结果用来改进图像。由于程序员能够逐帧设置 MSAA 采样模式的功能，这种技术在某种程度上成为了可能。这种技术可以解决例如旋转的马车车轮等反走样问题，并且能够改进边缘渲染质量。

> 想象通过生成一系列图像来“手动”执行采样模式，其中每次渲染使用不同的位置进行采样。这种偏移是通过在投影矩阵上附加一个微小的平移来完成的。

生成和取平均的图像越多，结果就越好。这种使用多个偏移图像的概念被用于时间性反走样算法。可能使用 MSAA 或其他方法生成单个图像，然后将之前的图像做混合。通常只有 2-4 帧被使用。

<strong>较旧的图像被赋予的权重可能呈指数减小</strong>，尽管如果观看者和场景不移动，这可能会导致帧闪烁，因此通常只对前一帧和当前帧赋予相同的权重。由于每帧的样本位于不同的子像素位置，因此这些样本的权重总和估计的边缘覆盖率比单帧更好。因此，使用前两帧平均的系统可以提供更好的结果。每帧都不需要额外得样本，这就是此方法如此吸引人的原因。我们甚至可以使用时间性采样来生成较低分辨率的图像，该图像将放大到显示器的分辨率的大小。此外，需要很多样本才能获得良好结果的照明方法，或者其他的技术，这两者可以用每帧使用更少样本的方法来代替，因为其结果将在多帧中混合。

在不增加额外采样成本的情况下为静态场景提供反走样功能时，这种类型的算法在用于时间性反走样功能时会遇到一些问题。如果没有对帧进行均等的加权，则静态场景中的对象可能会出现微光（shimmer）。快速移动的物体或快速的摄像机移动会导致鬼影（ghosting），即由于先前帧的影响而在物体后方留下痕迹。

- 鬼影的一种解决方案是仅对缓慢移动的对象执行这种反走样处理；
- 另一个重要的方法是使用重投影（reprojection）来更好地关联先前和当前帧的对象。在这种方案中，对象生成运动向量，这些运动向量存储在单独的“速度缓冲区”（velocity buffer）中。这些向量用于将前一帧与当前帧相关联，即从当前像素位置减去该向量，以找到该对象表面位置前一帧的彩色像素。在当前帧中不太可能成为表面一部分的样本将被丢弃。

由于时间性反走样不需要额外的样本，因此也就不需要多少额外的工作，因此近年来人们对这种算法产生了浓厚的兴趣，并且该算法也得到了广泛的应用。

#### 采样模式 (Sampling Patterns)
有效的采样模式是减少走样、时间以及其他方面的关键要素。Naiman的研究表明，在水平和垂直边缘附近的走样对人类视觉的影响最大。旋转栅格超级采样（Rotated grid supersampling，RGSS）使用旋转正方形图案来在像素内提供更多垂直和水平分辨率。

RGSS 模式是一种拉丁超立方体（Latin hypercube）或 N-rooks 采样的形式，其中 n 个采样放置在 n × n 的网格中，每行和每列一个采样。使用 RGSS时，这四个样本分别位于 4 × 4 的子像素网格中的单独行和列中。与常规 2 × 2 的采样模式相比，此类模式特别适合捕获几乎水平和垂直的边缘，在常规采样模式下，此类边缘可能覆盖偶数个样本，因此有效程度较低。

!> N-rooks 是创建良好采样模式的开始，但这还不够。例如这些样本可能都沿着子像素网格的对角线放置，因此对于几乎平行于该对角线的边缘，会得出较差的结果。

<center><img width="70%" src="CG/RTR/106.png"/></center>
<center>N-rooks 采样。左侧是一个符合规则的 N-rooks 图案，但是它在捕捉沿对角线的三角形边缘上表现较差。因为随着该三角形的移动，所有采样位置都将位于三角形的内部或外部。右侧是一种图案，它可以更有效地捕获此边缘和其他边缘</center>

为了获得更好的采样，我们要避免将两个采样彼此靠近。我们还希望分布均匀，将样本均匀分布在整个区域。为了形成这样的图案，我们会将例如拉丁超立方体采样的分层采样技术，与其他例如抖动、霍尔顿序列和泊松磁盘采样的方法相结合。

实际上，GPU 制造商通常将此类采样模式硬连接到其硬件中，以进行多重采样反走样。对于时间性反走样，因为样本位置会逐帧变化，所以其覆盖范围是程序员无论如何都想获取的。例如，Karis 发现基本的 Halton 序列（Halton sequence）比 GPU 提供的任何 MSAA 模式效果更好。霍尔顿序列会在空间中生成样本，这些样本看起来是随机的，但差异很小，也就是说，它们在空间中分布均匀，并且没有聚集（clustered）的现象。

虽然子像素网格图案可以更好地近似每个三角形如何覆盖网格单元，但这并不是理想的。场景可以由屏幕上任意小的物体组成，这意味着没有采样率可以完美地捕获它们。如果这些微小的物体或特征形成图案，则以恒定间隔进行采样可能会导致莫尔条纹和其他干涉图案。超级采样中使用的网格图案特别容易产生走样。

一种解决方案是使用随机采样，这样可以提供更加随机的图案。在过去的几十年中，偶尔会在硬件中支持交错采样（Interleaved sampling）、索引采样（index sampling），其中一组像素的每个像素都有不同的采样模式。

<center><img width="80%" src="CG/RTR/107.png"/></center>
<center>RGSS 采样模式。 每像素花费四个样本。 通过将这些位置移到像素边缘，可以跨边缘进行样本共享。 但是，要解决此问题，每个其他像素必须具有镜像的采样模式，如右图所示。 所得的样本模式称为 FLIPQUAD，每个像素花费两个样本</center>

#### 形态学方法 (Morphological Methods)
走样通常是由边缘引起的，例如由几何形状，尖锐阴影或明亮高光形成的边缘。 走样具有与边缘相关的结构，可以利用这些知识来提供更好的反走样结果。

2009年，Reshetov 沿着这些思路提出了一种算法，称其为形态学反走样（morphological antialiasing ，MLAA）。其中“形态”是指“与结构或形状有关”。早在1983年，Bloomenthal 就在这一领域做了较早的工作。之后 Reshetov 的论文重新激发了对多采样方法替代方法的研究，强调搜索和重建边缘。

这种反走样形式是在后处理（post-process）中执行的。 也就是说，以通常的方式进行渲染，然后将结果反馈到生成反走样结果的过程中去。自 2009 年以来，已经开发出了多种技术。那些依赖于其他缓冲区（例如深度和法线）的缓冲区可以提供更好的结果，例如子像素重建反走样（subpixel reconstruction antialiasing ，SRAA），但仅适用于对几何边缘进行反走样。诸如几何缓冲区反走样（geometry buffer antialiasing，GBAA）和距离边缘反走样（distance-to-edge antialiasing，DEAA）之类的分析方法，会使渲染器计算有关三角形边缘位于何处的附加信息，例如边缘距像素中心的距离有多少。

最通用的方案只需要颜色缓冲区，这意味着它们还可以从阴影，高光或之前应用的各种后处理技术（如轮廓边缘渲染）中改善边缘。 例如，方向局部反走样（directionally localized antialiasing，DLAA）是基于以下观察结果：接近垂直的边缘应水平模糊，同样，接近水平的边缘也应与其相邻像素垂直模糊。

边缘检测的更复杂形式尝试寻找可能包含任意角度的边缘的像素并确定其覆盖范围。 检查潜在边缘周围的邻域，目标是尽可能地重建原始边缘所在的位置。 然后可以使用边缘对像素的效果来融合相邻像素的颜色。

<center><img width="80%" src="CG/RTR/108.png"/></center>
<center>形态学反走样。左侧是走样图像。我们的目的是确定形成边缘的边缘的可能方向。中间，该算法通过检查相邻像素来记录其为边缘的可能性。给定样本后，显示了两个可能的边缘位置。右侧，使用最佳的推测边缘将相邻的颜色与估计的覆盖率成比例地混合到中心像素中。之后对图像中的每个像素重复此过程</center>

基于图像的算法中有几种可能会误入歧途。 首先，如果两个对象之间的色差低于算法的阈值，则可能无法检测到边缘。 具有三个或更多不同表面重叠的像素很难进行转换。颜色在像素间快速变化的，具有高对比度或高频率元素的表面，会导致算法错过边缘。特别地，当对其应用形态学反走样时，文本显示的质量通常会受到影响。 对象的角落部分可能是一个挑战，有些算法可以使它们具有圆润的外观。假设边缘是直的，曲线也会受到其不利影响。单个像素变化可能会导致边缘重建方式发生很大变化，从而在帧与帧之间产生明显的伪像（artifacts）。解决此问题的一种方法是使用 MSAA 覆盖蒙版来改善边缘确定性。

综上所述，基于图像的方法可以为较小的内存和处理成本提供反走样支持，因此它们被用于许多应用程序中。仅颜色的版本还与渲染管线分离，使其更容易修改或禁用，并且甚至可以公开为 GPU 驱动程序选项。两种最流行的算法是快速近似反走样（fast approximate antialiasing，FXAA）和子像素形态反走样（subpixel morphological antialiasing，SMAA），部分原因是它们都为各种设备提供了可靠的（以及免费的）源代码实现。两种算法都使用仅颜色的输入，SMAA 具有能够访问 MSAA 样本的优势。 每个算法都有自己可用的各种设置，以便在速度和质量之间进行权衡。 每帧消耗通常在 1-2 毫秒的范围内，主要是因为这是视频游戏所愿意花费的时间。 最后，两种算法都可以应用时间性反走样功能。 Jimenez 提出了一种改进的 SMAA 实现，比 FXAA 更快，并描述了一种时间性反走样方案。

### 透明度，Alpha值，与合成 (Transparency, Alpha, and Compositing)
光通过半透明物体的方法有许多种。对于渲染算法而言，这些方法可以大致分为基于光的效果或基于视图的效果。基于光的效果是指对象使光衰减或转移，导致场景中的其他对象被照亮和呈现不同的效果。基于视图的效果是指半透明对象自身的渲染效果。

一种制造透明感的方法称为屏幕门透明（screen-door transparency）。其思路是用像素对齐的棋盘格填充图案渲染半透明三角形。通常，屏幕上的像素足够紧凑以至于棋盘格图案本身是不易察觉的。这种方法的一个主要劣势是，通常只有一个半透明的对象可以令人信服地在屏幕的一个区域上渲染出来。举个例子，如果半透明的红色对象和半透明的绿色对象在蓝色对象之上渲染，则三种颜色中只有两种可以出现在棋盘格图案上。此外，50%的棋盘格效果是很有限的。其他更大的像素蒙版可用于给出其他百分比混合效果，但是这些倾向于创建那些可检测的图案。

这种技术的一个优势是它比较简单。半透明对象可在任意时间，以任何顺序呈现，且不需特殊的硬件支持。通过使所有对象在它覆盖的（棋盘格）像素处变为不透明，便解决了透明度的问题。同样的思路也被用于对剪切纹理的边缘进行反走样处理，但是这是在子像素级别，使用了被称为 Alpha 覆盖（alpha to coverage）的功能。

Enderton 等人提出使用随机透明（stochastic transparency）的方法使用子像素屏幕门遮罩与随机采样相结合而成。通过使用随机点画图案表示片元的 Alpha 覆盖，可以创建一个合理但含噪声的图像。为了看起来更合理，每个像素都需要大量的样本，当然，也需要为所有这些子像素样本准备相当大的内存空间。但此方法很有吸引力的是不需要进行混合操作，并且反走样，透明度，以及任何其他的创建部分覆盖像素的现象都可用此单一机制来处理。

<center><img width="80%" src="CG/RTR/109.png"/></center>
<center>随机透明。产生的噪声显示在放大区域中</center>

大多数透明度算法会将透明对象的颜色与其后面对象的颜色混合在一起。为此，我们需要 Alpha 混合的概念。当在屏幕上渲染对象时，RGB 颜色和 z 缓冲区深度这两者与每个像素都是相关联的。我们还可以为对象覆盖的每个像素定义另一个组件，称为 Alpha（α）。Alpha 是一个值，它用于描述给定像素的对象片元的不透明度和覆盖度。Alpha 为1.0 表示对象是不透明的，并且完全覆盖了像素的关注区域；0.0 表示完全不隐藏像素，即片元是完全透明的。

像素的 Alpha 值可以表示不透明度或覆盖率，或同时是两者，这具体视情况而定。举个例子，肥皂泡的边缘可能会覆盖像素的四分之三，即 0.75，并且可能几乎是透明的，从而使十分之九的光线直达眼睛，所以它的十分之一是不透明的，即 0.1。那么其 Alpha 将为 0.75 × 0.1 = 0.075。但是，如果我们使用 MSAA 或类似的反走样方案，覆盖率将通过样本自身从而被考虑在内。因此四分之三的样本将受到肥皂泡的影响。然后，在每个样本中，我们将使用 0.1 的不透明度值作为 Alpha 值。

#### 混合顺序 (Blending Order)
为了使对象看起来透明，它以小于1.0 的 Alpha 渲染到现有场景的顶部。对象覆盖的每个像素将从像素着色器接收结果 RGB_α（也称为 RGBA）。通常使用 over 运算符将此片段的值与原始像素颜色混合，如下所示：

<center><img width="50%" src="CG/RTR/110.png"/></center>

其中c_s是半透明对象的颜色（称作来源，source），α_s是对象的 Alpha 值，c_d是混合前的像素颜色（称作目标，destination），c_o是将半透明对象放置在现有场景上而产生的最终颜色。在渲染管线传入c_s和α_s的情况下，像素的原始颜色c_d被结果c_o所取代。如果传入的  实际上是不透明的（α_s = 1.0），则该公式简化为用对象的颜色完全替换像素的颜色。

over 运算符为要渲染的对象提供半透明外观。通过这种方式实现的透明性可以正常工作，即只要可以通过它看到后面的对象，我们就会将它视为透明的物体。使用 over 模拟薄纱织物的真实效果。织物背后对象的视图被部分遮挡了——织物的线是不透明的。在实践中，宽松的织物具有随角度变化的 Alpha 覆盖率。这里的重点是 Alpha 模拟了材质覆盖像素的程度。

<center><img width="70%" src="CG/RTR/111.png"/></center>
<center>红色薄纱正方形的织物与红色的塑料过滤器，它们具有不同的透明效果。注意，它们的阴影也不同</center>

over 运算符对于其他类型的半透明效果显得不是很可信，尤其是透过有色玻璃或塑料观看时。在现实世界中，放置在蓝色物体前面的红色滤镜通常会使蓝色物体看起来很暗，因为该物体反射的可以穿过红色滤镜光线很少。参见图 5.32。当使用 over 进行混合时，结果是红色和蓝色部分相加在一起。更好的方法应该是将这两种颜色相乘，并增加透明对象本身的反射。

在基本的混合阶段运算符中，over 是通常用于透明效果的运算符 [199，1429]。另一种有用的操作是加法混合（additive blending），即将像素值简单地求和。如下所示：

<center><img width="20%" src="CG/RTR/112.png"/></center>

这种混合模式能够很好地用于发光效果，例如闪电或火花，这些效果不会使后面的像素衰减，而只会使它们变得更亮。然而，此模式的透明度看起来不正确，因为不透明的表面似乎没有被过滤。对于诸如烟或火焰之类的多层分层半透明表面，加法混合具有使半透明现象的颜色更饱和的效果。

为了正确渲染半透明对象，我们需要在不透明对象之后绘制它们。首先，通过关闭混合以渲染所有不透明对象，然后开启 over 以渲染半透明对象。从理论上讲，我们总是可以让 over 开启，因为不透明的 Alpha 1.0 会给出源颜色并隐藏目标颜色，但是这样做成本更高，而且没有真正的收益。

z 缓冲区的限制是每个像素只能存储一个对象。如果多个透明对象与同一像素进行重叠，则仅 z 缓冲区无法容纳且无法在之后解决所有可见对象的影响。当使用 over 时，任何给定像素处的透明表面通常都需要以从后到前的顺序进行渲染。不这样做的话可能会给出错误的知觉暗示。一种实现这种排序的方法是，按照单个对象的质心沿相机视角的距离对其进行排序。这种粗略的分类可以很好地工作，但是在各种情况下都有许多问题。首先，这里的顺序只是一个近似值，因此分类时较远的对象可能位于较近的对象的前面。互相贯穿的对象无法针对所有视角在每个网格上都进行正确显示，除非将每个网格分解为单独的碎片。

<center><img width="80%" src="CG/RTR/113.png"/></center>
<center>在左侧，使用 z 缓冲区以透明方式渲染模型。以任意顺序渲染网格会产生严重的错误。在右侧，深度剥离可提供正确的外观，但要消耗额外的 pass 数</center>

尽管如此，由于其简单性与速度，以及它不需要额外的内存或特殊 GPU 支持，我们仍然经常使用这种对透明度进行粗糙排序的方法。如果应用了这种方法，通常最好在执行透明度时关闭 z 深度替换功能。也就是说，z 缓冲区仍然可以正常测试，但是保留下来的的曲面不会改变存储的 z 深度；最接近的不透明表面的深度保持不变。用这种方法，所有半透明物体都至少会以某种形式出现，而不是在照相机旋转导致的更改排序顺序时造成物体突然出现或消失。其他技术也可以帮助改善外观表现，例如每次绘制两次透明网格，首先渲染背面，然后渲染正面。

over 方程也可进行修改，以使从前到后混合能得到相同的结果。这种混合模式称为 under 运算符：

<center><img width="50%" src="CG/RTR/114.png"/></center>

under 要求目标保持 Alpha 值，而 over 则不需要。换句话说，目标——在它之前混合了更近的透明表面——并不是不透明的，因此需要具有 Alpha 值。under 的公式和 over 相似，但是交换了源和目标。另外需要注意的是，用于计算 Alpha 值的公式与顺序无关，因为源 Alpha 值和目标 Alpha 值可以交换，结果都是相同的最终 Alpha 值。

Alpha 公式来自将片元的 Alpha 作为覆盖率。Porter 和 Duff 注意到，由于我们不知道每个片元覆盖区域的形状，因此我们假设每个片元都按其 Alpha 值比例去覆盖另一个片元。例如，如果α_s=0.7，则以某种方式将像素分为两个区域，其中源片元覆盖 0.7，而目标片元覆盖 0.3。除非有其他新的技术，否则目标片元覆盖范围，我们称α_d=0.3，会按比例地与源片元进行重叠。该公式具有几何解释，如图：

<center><img width="80%" src="CG/RTR/115.png"/></center>
<center>一个像素和两个片元 s 和 d 。通过沿着不同的轴对齐两个片元，每个片元会按一定比例覆盖另一个片元，也就是说，它们是不相关的。两个片元覆盖的面积等于 under 输出的 Alpha 值。这意味着将两个面积相加，然后减去它们重叠的面积</center>

#### 顺序无关透明 (Order-Independent Transparency)
under 运算符的另一种用途是执行称为深度剥离（depth peeling）的与顺序无关的透明度（order-independent transparency, OIT）算法。

顺序无关意味着应用程序不需要执行排序。深度剥离的思路是使用两个 z 缓冲区和多 Pass。首先，渲染一个 Pass，以使所有表面的 z 深度（包括透明表面）都位于第一个 z 缓冲区中。在第二个 Pass 中，将会渲染所有半透明对象。如果对象的 z 深度与第一个 z 缓冲区中的值匹配，则我们就知道这是最近的半透明对象，然后将它的 RGBα 值保存到单独的颜色缓冲区中。我们还通过保存所有半透明对象（如果有）的超出第一个 z 深度并且最接近的 z 深度来“剥离”该层。此 z 深度是第二近的透明对象的距离。接下来的一系列 Pass 继续使用 under 进行剥离并添加透明层。经过一定数量的 Pass 渲染之后，我们会停下来，然后将半透明图像混合在不透明图像之上。

<center><img width="80%" src="CG/RTR/116.png"/></center>
<center>每个深度剥离 Pass 都绘制其中一个透明层。左侧是第一遍绘制，显示了直接可见的图层。中间显示的第二层在每个像素处显示了距离第二近的半透明表面，在这种情况下为对象的背面。右边的第三层是一组距离第三近的透明表面</center>

该方案的几种变体已经研发出来了。例如，Thibieroz 提供了一种从后到前计算的算法，其优点是能够立即混合透明值，这意味着我们不需要单独的 Alpha 通道。深度剥离的一个问题是需要知道究竟多少 Pass 足以捕获所有透明层。一种硬件上的解决方案是提供一个像素绘制计数器，该计数器可指示渲染过程中写入了多少个像素。当 Pass 未渲染任何像素时，渲染就直接完成了。使用 under 的好处是，最重要的半透明层——眼睛首先看到的那些——会在早期就进行渲染。每个半透明表面都会增加其覆盖的像素的 Alpha 值。如果像素的 Alpha 值接近 1.0，则混合的贡献值会使像素几乎是不透明的，因此距离较远的对象的影响可忽略不计。当通过 Pass 渲染的像素数低于某个最小值或可以指定固定数量的 Pass 时，可以减少从前到后的剥离过程。<strong>然而这对于从后到前的剥离效果不佳，因为距离最近（并且通常是最重要）的层是最后绘制的，因此可能会因早期过程的终止而丢失片元</strong>。

尽管深度剥离是有效的，但它的速度有可能很慢，因为每一层的剥离都是针对所有半透明对象的一个独立的渲染 Pass。Bavoil和Myers 提出了双重深度剥离技术，其中在每个 Pass 中剥离了两个深度剥离层，分别是最接近的和最远的剩余层，从而将渲染 Pass 的数量减少了一半。Liu 等人 探索了一种桶排序方法（bucket sort method），该方法一次可捕获多达 32 个层。这种方法的一个缺点是，它需要大量内存才能为所有层保持排序顺序。通过 MSAA 或类似方法进行反走样将极大地增加成本。

以交互速率正确地将半透明对象混合在一起的问题并不是我们缺少算法的问题，而是将这些算法有效地映射到 GPU 的问题之一。1984年，Carpenter 提出了 A 缓冲区，这是另一种多重采样的形式。在A缓冲区中，渲染的每个三角形都会为其完全或部分覆盖的每个屏幕网格创建一个覆盖蒙版（coverage mask）。每个像素存储所有相关片元的列表。不透明的片元可以清除它们后面的片元，类似于 z 缓冲区。所有片元均存储在透明表面上。一旦所有列表形成，就可以通过遍历片元和解析每个样本来产生最终结果。

A 缓冲区的优点是，仅分配每个像素所需的片元，GPU 上的链表实现也是如此。从某种意义上讲，这也可能是不利的，因为在开始渲染帧之前所需的存储量是未知的。具有头发，烟雾或其他物体的场景可能具有许多重叠的半透明表面，因此可能会产生大量的片元。Andersson 指出，对于复杂的游戏场景，最多可以重叠50个物体（例如树叶）的透明网格和最多200个半透明粒子。

<center><img width="80%" src="CG/RTR/117.png"/></center>
<center>左上方为传统的从后到前的 Alpha 混合，由于排序顺序不正确，导致渲染错误。右上方为A缓冲区用于提供完美的非交互结果。左下方显示了具有多层 Alpha 混合的渲染。右下方显示了 A 缓冲区和多层图像之间的差异，将其乘以 4 可得到可见度</center>

GPU 通常有预先分配好的内存资源，例如缓冲区和数组，并且链表方法也不例外。用户需要决定需要多少内存，而内存不足会导致明显的伪像。Salvi 和 Vaidyanathan 提出了一种由英特尔引入的，被称为像素同步的 GPU 功能来解决此问题的方法，即多层 Alpha 混合（multi-layer alpha blending）。该功能可提供可编程混合模式，且开销比原子操作要少。他们的方法重新定义了存储和混合的方式，以便在内存用完的情况下适当降低性能。此外，粗略的排序顺序也有益于该方案。DirectX 11.3 引入了光栅化程序顺序视图，这是缓冲区的一种类型，它允许在支持该功能的任何 GPU 上实现该透明方法。移动设备也具有类似的技术，我们称为图块本地存储（tile local storage），它允许它们实现多层 Alpha 混合。然而，这种机制具有性能成本，所以这种类型的算法的消耗可能很大。

这种方法建立在 Bavoil 等人提出的 k 缓冲区的概念上。其中保存了前几层的可见图层并尽可能地对其进行了排序，而更深的图层则被丢弃并尽可能地进行了合并。Maule 等人使用k缓冲区，并通过使用加权平均（weighted averaging）来解决这些较远的深层级。加权和（weighted sum）与加权平均透明技术都和顺序无关，且都是单 Pass，并且几乎可以在任意 GPU 上运行。但它们的问题在于没有考虑对象的顺序。因此，例如使用 Alpha 表示覆盖率，在一条淡蓝色围巾上的一条淡红色围巾给人一种紫罗兰色的感觉，而不是正确地看到一条带有一些蓝色的红色围巾。虽然对于接近不透明的对象给出的结果会很差，但这类算法对于可视化是有用的，并且对高度透明的表面和粒子可以很好地工作。

<center><img width="80%" src="CG/RTR/118.png"/></center>
<center>随着不透明度的增加，对象的顺序变得越来越重要</center>

在加权和透明度中，公式为：

<center><img width="40%" src="CG/RTR/119.png"/></center>

其中n是透明表面的数目，c_i和α_i表示透明值的集合，c_d是场景中不透明部分的颜色。当绘制透明表面时，将两个和累积并分别存储，并在半透明 Pass 结尾，在每个像素处计算该公式。该方法的问题在于，第一个求和是饱和的，即会得到大于（1.0,1.0,1.0）的颜色值，并且因为 Alpha 的总和可能超过 1.0，所以背景颜色可能会产生负面影响。

通常我们首选加权平均公式，因为它避免了这些问题：

<center><img width="40%" src="CG/RTR/120.png"/></center>

第一行表示半透明渲染过程中在两个单独的缓冲区中生成的结果。提供给c_sum的每个表面都受到一个由其 Alpha 加权的影响； 几乎不透明的表面提供了更多的颜色，几乎透明的表面则几乎没有影响。通过将c_sum除以α_sum，我们得到了加权的平均透明度颜色。值α_avg是所有 Alpha 值的平均。值u是在n次透明表面上应用此平均 Alpha 次数n次后，目标（不透明场景）的可见度估计值。最后一行实际上是 over 运算符，其中(1-u)代表源的 Alpha。

加权平均值的一个限制是对于相同的 Alpha，无论顺序如何，它均等地混合了所有颜色。McGuire 和 Bavoil 引入了加权混合的与顺序无关的半透明方案进行渲染，以提供更具说服力的结果。在进行模拟时，相机到表面的距离也会影响权重，更靠近的表面会受到更大的影响。而且，不是对 Alpha 进行平均，而是通过将  的多个项一起相乘，并用 1 减去它来计算 ，从而获得一组表面的真实 Alpha 覆盖率。

<center><img width="80%" src="CG/RTR/121.png"/></center>
<center>查看同一引擎模型的两个不同的摄像头位置，均使用加权混合的与顺序无关的半透明方案进行渲染。按距离加权有助于弄清哪些表面更靠近观察者</center>

该方案的缺点是，在较大的环境中，彼此靠近的对象的距离权重几乎是相等的，所以这使结果与加权平均值几乎没有区别。另外，随着相机到透明物体的距离的改变，深度权重实际上可能会发生变化，但是这种变化是逐渐的。

McGuire 和 Mara 扩展了该方法，使其包含了合理的透射颜色效果。如前所述，本节中讨论的所有透明度算法都将各种颜色混合在一起而不是对其进行过滤，从而模仿了像素覆盖率。为了得出滤色器的效果，不透明场景由像素着色器读取，每个半透明表面将它在该场景中覆盖的像素乘以它的颜色，并将结果保存在第三个缓冲区中。这个缓冲区，其中不透明的对象现在被半透明的对象染色，在接下来解析半透明缓冲区时，会用来代替不透明的场景。该方法之所以有效是因为颜色的传输与顺序无关，这与覆盖所造成的透明度是不同的。

还有其他算法用到了这里所介绍的技术中的部分元素。例如，Wyman通过内存需求，插入和合并方法对之前的这些工作进行了分类，无论是 Alpha 或者几何覆盖率，还是如何处理丢弃的碎片，都有被使用。通过寻找先前研究中的漏洞，他展示了两种被发现的新方法。他的随机分层 Alpha 混合方法使用了 k 缓冲区，加权平均值和随机透明度。他的其他算法是 Salvi 和 Vaidyanathan 方法的一种变体，使用覆盖蒙版而不是 Alpha 值。

!> 并没有完美的解决方案来呈现半透明对象


#### 预乘 Alpha 与合成 (Premultiplied Alphas and Compositing)
over 操作符还用于将照片或对象的合成渲染混合到一起。该过程我们称之为合成（compositing） 。在这种情况下，每个像素的 Alpha 值将与对象的 RGB 颜色值一起存储。由 Alpha 通道形成的图像有时称为无光粗糙层（matte）。它显示了对象的轮廓形状。

使用合成 RGBα 数据的一种方法是使用预乘 Alpha（也称为关联的 Alpha）。即在使用之前，将 RGB 值乘以 Alpha 值。这使合成 over 公式的效率更高：

<center><img width="30%" src="CG/RTR/122.png"/></center>

其中c_s'是预乘的源通道。预乘 Alpha 还可以在不更改混合状态的情况下使用 over 和叠加混合，因为现在在混合过程中添加了源颜色。

> 请注意，使用预乘的 RGBα 值，虽然可以将 RGB 分量创建为特别明亮的半透明值，但是它们通常不大于 Alpha 值。

合成图像的渲染很自然地与预乘 Alpha 相吻合。默认情况下，在黑色背景上渲染的反走样不透明对象会提供预乘值。假设白色（1、1、1）三角形沿其边缘覆盖了某些像素的 40％。使用（极精确的）反走样功能，像素值将设置成值为 0.4 的灰色，即我们将为此像素颜色保存为（0.4，0.4，0.4）。如果是存储 Alpha 值，那么也将为 0.4，因为这是三角形覆盖的区域范围。最终  值为（0.4、0.4、0.4、0.4），且这是一个预乘值。

图像存储的另一种方式是使用未相乘的（unmultiplied alphas） Alpha，它也被称为未关联的（unassociated alphas） Alpha，甚至是一个令人费解的术语，非预乘的 Alpha（nonpremultiplied alphas）。未相乘的 Alpha 就是它的字面意思：RGB 值不乘以Alpha 值。对于白色三角形的示例，未相乘的颜色为（1、1、1、0.4）。这种表示形式的优点是可以存储三角形的原始颜色，但是在显示之前，始终需要将该颜色乘以存储的 Alpha 值。最好在执行过滤和混合操作时使用使用预乘数据，因为使用未相乘的 Alpha 并不能正确执行线性插值之类的操作。这可能会产生诸如围绕对象边缘的黑色条纹之类的伪像。

与alpha通道相关的概念是色度选择（chroma-keying）。这是视频制作中的一个术语，其中演员是在绿色或蓝色屏幕上拍摄并与背景融合在一起的。在电影工业中，此过程称为绿幕（green-screening ）或蓝幕（blue-screening）。这里的思路是，将特定的色相（用于胶卷）或精确值（用于计算机图形）指定为透明；只要检测到绿幕或蓝幕，那么就会显示背景。这样，仅使用RGB 颜色就可得出图像的轮廓形状；无需存储任何Alpha。该方案的一个缺点是，对象在任何像素处要么完全不透明，要么完全透明，即，alpha实际上仅为 1.0 或 0.0。举个例子，GIF 格式图片仅允许将一种颜色指定为透明。


### 显示编码 (Display Encoding)
当我们计算照明，纹理或其他操作的效果时，假定使用的值为线性（linear）。非正式情况下，线性意味着加法和乘法按预期执行。但是，为了避免出现各种视觉伪像，显示缓冲区和纹理使用非线性编码，这也是我们必须要考虑的问题。

> 关于该问题，简短而粗略的答案如下：选取 [0，1] 范围内的着色器输出颜色并将其提高 1/2.2 的幂，执行被称为伽马校正（gamma correction）的操作。对传入的纹理和颜色执行相反的操作。在大多数情况下，你可以让 GPU 为你执行这些操作。

我们从阴极射线管（CRT）开始讲起。在数字成像的早期，CRT 显示器是标准规范。这些设备在输入电压和显示辐射率之间表现出幂律关系。随着施加到像素的能级的增加，发出的辐射不会呈现线性增长，而是（令人惊讶地）与该能级成正比地升高，从而达到大于 1 的功率。例如，假设功率为2。值被设置为 0.5 的一个像素只发出设置为 1.0 的像素的四分之一的光量，即0.5^2 = 0.25。虽然 LCD 和其他显示技术具有与 CRT 不同的固有色调响应曲线，但它们是通过转换电路制造的，这使它们能够模仿 CRT 的响应。

该幂函数几乎与人类视觉的亮度灵敏度相反。这种幸运巧合的结果是，编码是近似感知统一的（perceptually uniform）。也就是说，在可显示范围内，一对编码值 N 和 N + 1 之间的感知差大致恒定。通过测量阈值对比度（threshold contrast），我们可以在各种条件下检测到其亮度差异约为 1％。当颜色存储在精度有限的显示缓冲区中时， 这种近似最优的值分布可以最大程度上地减少条带化现象（banding artifacts）。同样的优点也适用于纹理，因为它们通常使用相同的编码。

显示传递函数（display transfer function ）描述了显示缓冲区中的数字值与从显示器发出的辐射水平之间的关系。因此，它也被称为电光学传递函数（electrical optical transfer function，EOTF）。显示传输功能是硬件的一部分，并且对于计算机显示器，电视和电影放映机，有着不同的标准。在该过程的另一端，还有图像和视频捕获设备，并且还有一个标准的传递函数，它被称为光电传递函数（optical electric transfer function，OETF）。

在对用于显示的线性颜色值进行编码时，我们的目标是要消除显示传递函数的影响，以便我们计算的任何值都将发出相应的辐射亮度级别。例如，如果我们的计算的值加倍，我们希望输出的辐射率也加倍。为了保持这种关系，我们使用了显示传递函数的逆函数来抵消其非线性效应。取消显示响应曲线的过程也称为伽玛校正（gamma correction），关于进行伽马校正的原因很快会在接下来说明。在解码纹理值时，我们需要应用显示传递函数来生成用于着色的线性值。

<center><img width="80%" src="CG/RTR/123.png"/></center>

个人计算机显示器的标准传递函数由被称为 sRGB 的颜色空间规范定义。当从纹理中读取值或将值写入颜色缓冲区时，可以将大多数控制 GPU 的 API 设置为自动应用正确的 sRGB 转换。如 6.2.2 节所述，生成 MipMap 还将考虑 sRGB 编码。通过先转换为线性值，然后执行插值，纹理值之间的双线性插值就可以正确地执行。通过将存储的值解码回线性值，混合新值，然后对结果进行编码，就可以正确完成 Alpha 的混合。

当将值写入显示的帧缓冲区时，在转换的最后阶段应用该转换是很重要的。如果在显示编码之后应用后处理，则将在非线性值上计算此类效果，这通常是不正确的，并且经常会导致伪像。我们可以将显示编码视为一种压缩形式，这可以最好地保留该值的感知效果。解决这一问题的一个好方法是使用线性值来执行物理计算，每当我们要显示结果或访问可显示图像（例如颜色纹理）时，我们需要使用适当的编码或解码转换，将数据转入或转出其显示编码形式。

如果确实需要手动应用 sRGB，则可以使用标准转换公式或一些简化版本。实际上，显示是由每个颜色通道的一些比特位数控制的，例如，对于消费者级别的显示器，该位数为 8，并提供一组在 [0，255] 范围内的级别。在这里，我们将显示编码的级别表示为 [0.0，1.0] 范围，而忽略位数。线性值也在 [0.0，1.0] 范围内，表示浮点数。我们用 x 表示这些线性值，用 y 表示存储在帧缓冲区中的非线性编码值。要将线性值转换为 sRGB 非线性编码值，我们应用 sRGB 显示传递函数的逆函数：

<center><img width="70%" src="CG/RTR/124.png"/></center>

其中 x 代表线性 RGB 三元组的通道。该公式适用于每个通道，这三个生成的值会用作显示。如果你手动应用转换功能，请当心。产生错误的原因之一是使用编码的颜色而不是其线性形式，另一种原因是将颜色解码或编码两次。

这两个变换表达式的底部是一个简单的乘法，这是由于数字硬件需要使变换完全可逆而产生的。涉及将值提高到幂的最高表达式几乎适用于输入值x的整个范围 [0.0，1.0]。考虑到偏移量和比例尺，此函数非常近似于一个更简单的公式：

<center><img width="30%" src="CG/RTR/125.png"/></center>

γ= 2.2。希腊字母 γ 是名称 “伽玛校正” 的来源。

正如必须对计算值进行编码以进行显示一样，在进行计算之前，必须将静态相机或摄像机捕获的图像转换为线性值。你在显示器或电视上看到的任何颜色都有一些显示编码的 RGB 三元组，它们可通过屏幕捕获或颜色选择器获得。这些值是以 PNG，JPEG 和 GIF 等文件格式存储的，它们都是可以直接发送到帧缓冲区并在屏幕上显示而不用进行转换的格式。换句话说，你在屏幕上看到的所有内容都是定义为显示编码的数据。在着色计算中使用这些颜色之前，我们必须将这种编码形式转换回线性值。从显示编码到线性值所需的 sRGB 转换是：

<center><img width="70%" src="CG/RTR/126.png"/></center>

其中 y 代表标准化的显示频道值，即存储在图像或帧缓冲区中的值，表示为 [0.0，1.0] 范围内的值。此解码函数与我们以前的 sRGB 公式相反。这意味着，如果着色器访问纹理并输出纹理而没有更改，则其外观将与预期的一样。解码函数与显示传递函数相同，因为存储在纹理中的值已进行编码以便正确显示。此外，我们没有转换到提供线性响应显示，而是转换到提供线性值。

更简单的伽玛显示传递函数是前一个公式的反函数：

<center><img width="30%" src="CG/RTR/127.png"/></center>

在移动应用和浏览器应用中会有一对更简单的转换公式：

<center><img width="30%" src="CG/RTR/128.png"/></center>

也就是说，我们取线性值的平方根进行转换以进行显示，而对逆值只需再与自身相乘一次就可以了。虽然是粗略近似，但这种转换比完全忽略该问题要好。

<center><img width="80%" src="CG/RTR/129.png"/></center>
<center>两个重叠的聚光灯照亮一个平面。在左侧图像中，在将亮度值 0.6 和 0.4 相加后不执行伽马校正。有效地对非线性值执行加法操作，从而导致错误。请注意，左侧的光看起来比右侧的光要明亮得多，重叠部分的亮度显得不够真实。在右图中，相加后的值将进行伽玛校正。灯光本身会成比例地变亮，并且在重叠的地方可以正确组合</center>

如果我们不注意伽玛，则较低的线性值将在屏幕上显示得太暗。一个与之相关的错误是，如果不执行伽马校正，某些颜色的色相可能会发生偏移。假设我们的 γ= 2.2。我们要从显示的像素发出与线性计算值成比例的辐射度，这意味着我们必须将线性值提高到（1 / 2.2）次幂。线性值 0.1 给出 0.351，0.2 给出 0.481，而 0.5 给出 0.730。如果未编码，则按原样使用这些值将导致显示器发出的辐射比所需的少。

忽略伽玛校正的另一个问题是，在非线性值上执行了对物理线性辐射值正确的着色计算这会影响反走样边缘的质量。

<center><img width="80%" src="CG/RTR/130.png"/></center>
<center>在左侧，黑色（显示为灰色）背景上的白色三角形边缘覆盖了四个像素，并显示了真实的区域覆盖率。如果不执行伽玛校正，则中间色调的变暗会导致边缘的感知失真</center>

<center><img width="80%" src="CG/RTR/131.png"/></center>
<center>左侧的一组反走样线经过了伽玛校正； 在中间，该集合被部分校正；在右边，没有伽马校正</center>

sRGB标准创建于1996年，已经成为大多数计算机显示器的标准。然而，自那时以来，显示技术得到了许多发展。目前已经开发出了更明亮并且可以显示更多颜色的显示器。


## Chapter 6 - Texturing - 纹理化
> 实时渲染最为强大的工具之一就是能够快速访问以及在表面(Surfaces)显示图像。这个过程被称为纹理化(Texturing)

### 什么是纹理化

在计算机图形学中，纹理化是获取表面并使用某些图片、函数或其他数据源在每个位置修改其外观的过程。例如，显示砖墙时，我们不是精确地去表示砖墙的几何形状，而是将砖墙的彩色图片应用于两个三角形组成的矩形上。查看矩形时，彩色图片会显示在矩形所在的位置。除非观察者很靠近墙壁，否则缺少的几何细节是不会引起注意的。

然而，某些带纹理的砖墙可能会因为缺乏几何形状而无法令人信服。例如，如果砂浆应该是哑光的（matte），而砖块是光滑的（glossy），则观察者会注意到两种材料的粗糙度相同。为了产生更令人信服的体验，我们可以在表面上应用第二个图片纹理。根据表面上的位置，此纹理可以<strong>更改墙壁的粗糙度</strong>，而不是更改表面的颜色。

每个砖块表面看起来都非常平坦，这是不对的，因为砖的表面通常会有一些不规则的起伏。通过应用<strong>凹凸贴图（bump mapping）</strong>，我们就可以改变砖块的着色法线，以便在渲染砖块时，使它们看起来并不十分平滑。这种纹理会扰动矩形原始表面法线的方向，以用于计算光照。

然而从低角度观看，这种凹凸不平的错觉可能会瓦解。砖块应突出在砂浆上方，以使其看不见。即使从直视角度看，砖块也应该将阴影投射到砂浆上。<strong>视差贴图（Parallax mapping）</strong>使用一张纹理让平面在渲染时似乎变形了，而<strong>视差遮蔽贴图（parallax occlusion mapping）</strong>将射线投射到高度场纹理上以提高真实感。<strong>位移贴图（Displacement mapping）</strong>通过修改形成模型的三角形高度来真正位移曲面。

### 纹理化管线 (The Texturing Pipeline)
探讨纹理化的一种方法是去思考单个着色像素在此过程中会发生什么，我们通过修改着色方程式中使用的值来进行纹理化。这些值的更改方式通常基于表面上的位置。纹理化过程可以通过概括的纹理管线来描述。

在空间中的片元位置是纹理化过程的起点，该位置可以位于世界空间中，但通常位于模型空间，因此随着模型的移动，纹理也随之移动。通常在空间点上应用投影函数（projector function），以便获得一组被称为纹理坐标（texture coordinates）的数值，这些数值将用于访问纹理。取回的值可能会通过值转换函数再次进行转换，最后，这些新值将用于修改曲面的某些属性，例如粗糙度或法线。此过程称为映射（mapping），也通常被称为纹理映射（texture mapping）。

<center><img width="80%" src="CG/RTR/132.png"/></center>
<center>单个纹理的纹理管线</center>

<center><img width="80%" src="CG/RTR/133.png"/></center>
<center>砖墙的纹理映射过程</center>

如上图，渲染砖墙纹理时，首先找到对象的局部参照系中的（x，y，z）位置； 假设是（−2.3，7.1，88.2）。然后将投影函数应用于此位置。正如世界地图是将三维对象投影到二维中一样，此处的投影函数通常将（x，y，z）向量更改为二维向量（u，v）。此示例中使用的投影函数等效于正交投影，其作用类似于幻灯片投影仪，将砖墙图片照在三角形的表面上。

回到墙这边，可以将其表面上的一个点转换为一对值，范围从 0 到 1 。这里假设获得的值为（0.32，0.29）。这些纹理坐标将用于查找此位置的图像颜色。我们砖墙纹理的分辨率为 256 × 256，因此匹配函数会将（u，v）分别乘以 256，得出（81.92，74.24）。弃掉小数点，在砖墙图片中对应像素为（81，74），它的颜色为（0.9，0.8，0.7）。纹理颜色位于 sRGB 颜色空间中，因此，如果要在着色方程式中使用该颜色，则将其转换为线性空间，得到（0.787，0.604，0.448）。

### 投影函数 (The Projector Function)
纹理处理的第一步是获取表面的位置并将其投影到纹理坐标空间中，通常是二维（u，v）空间。蒙皮包裹（Modeling packages）通常允许美术师定义每个顶点的（u，v）坐标，可以从投影函数或网格展开算法来初始化。美工也可以用编辑顶点位置的方式来编辑（u，v）坐标。投影函数通常通过将空间中的三维点转换为纹理坐标来工作。建模程序中常用的投影函数包括球形投影，圆柱形投影和平面投影。

<center><img width="70%" src="CG/RTR/134.png"/></center>
<center>不同的纹理投影。从左到右显示了球形，圆柱形，平面和自然（u，v）投影。底行显示了应用于单个对象（没有自然投影）的所有这些投影</center>

也可以使用其他的输入来进行投影，例如，可以使用表面法线来选择将六个平面投影方向中的哪个用于该表面。面部相接处的接缝处会出现纹理匹配问题；Geiss 讨论了一种将它们混合的技术。Tarini 等人提出了多立方体贴图（polycube maps），其中一个模型被映射到一组立方体投影，而不同体积的空间映射到不同的立方体。

非交互式渲染器通常将这些投影函数称为渲染过程本身的一部分。单个投影函数可能就足以满足整个模型的需要，但美术人员通常必须使用工具来划分模型并分别应用各种投影函数。

<center><img width="70%" src="CG/RTR/135.png"/></center>
<center>各种纹理投影是如何被应用在单个模型上。盒式映射（Box mapping）由六个平面映射组成，每个盒子面都有一个映射</center>

在实时渲染中，通常在建模阶段应用投影函数，并将投影结果存储在顶点上。然而并非总是如此; 有时在顶点或像素着色器中应用投影函数也是有利的。这么做可以提高精度，并有助于启用各种效果，包括动画。一些渲染方法，例如环境映射（environment mapping），具有自己的专用的投影函数，并且这些函数都会逐像素进行计算。

由于投影方向边缘的曲面存在严重的变形，因此美术人员通常必须手动将模型分解为近似平面的部分。还有一些工具可通过展开网格，或是创建一组接近最佳的平面投影来帮助其最大程度地减少变形，或者通过其他方式辅助此过程。我们的目标是使每个多边形在纹理区域中享有更公平的份额，同时还要保持尽可能多的网格连接。连接性很重要，因为采样伪像（artifacts）可以沿着纹理的各个单独部分相遇的边缘出现。具有良好展开效果的网格也可以简化美术人员的工作。

<center><img width="70%" src="CG/RTR/136.png"/></center>
<center>雕像模型的几个较小的纹理，保存为两个较大的纹理。右图显示了三角形网格如何展开并显示在纹理上以帮助其创建</center>

纹理坐标空间并不总是二维平面。有时是三维体积。在这种情况下，纹理坐标表示为三元向量（u，v，w），其中 w 为沿投影方向的深度。其他系统最多使用四个坐标，通常指定为（s，t，r，q）； q 用作齐次坐标中的第四个值。它的作用类似于电影或幻灯片的投影仪，投影纹理的大小随距离而增加。举个例子，对于将装饰性聚光图案（称为 gobo）投影到舞台或其他表面上来说，它是很有用的。

纹理坐标空间的另一种重要类型是方向型，其空间中的每个点都可以通过输入方向访问。可视化这种空间的一种方法是将其作为单位球面上的点，每个点上的法线表示用于访问该位置纹理的方向。使用方向参数化的最常见纹理类型是立方体贴图（cube map）。

另外还值得注意的是，一维纹理图像和函数也有其用途。例如，在地形模型上，可以通过其高度确定颜色，例如低地是绿色，山峰是白色。线条也可以进行纹理化；其中一种用法是将雨水渲染为一组带有半透明图像的长线。此外，这种纹理对于从一个值转换为另一值，即作为查找表，也是有用的。

由于可以将多个纹理应用于一个表面，因此可能需要定义多组纹理坐标。但如果是应用坐标值的话，思路是相同的：这些纹理坐标在表面上插值并用于检索纹理值。然而在插值之前，这些纹理坐标会由匹配函数转换。

### 匹配函数 (The Corresponder Function)
匹配函数们将纹理坐标转换为纹理空间位置。它们提供了将纹理应用于表面的灵活性。匹配函数的一个应用案例就是使用 API 选择现有纹理的一部分进行显示；只有该子图像才会传递到后续操作流程中使用。

匹配函数的另一种类型是矩阵变换，可以将其应用于顶点或像素着色器。这样就可以在表面上平移，旋转，缩放，剪切或投影纹理。转换的顺序很重要，但纹理转换的顺序必须与预期的顺序相反。这是因为纹理变换实际上会影响确定查看图像位置的空间。图像本身并不是要转换的对象，定义图片位置的空间才是被转换的对象。

还有另一类匹配函数控制应用图像的方式。我们知道图像将出现在（u，v）处于 [0，1] 范围内的表面上。但是超出此范围会发生什么？此情况下匹配函数会确定其具体行为。在OpenGL中，这种类型的匹配函数被称为“包装模式”（wrapping mode）；在DirectX 中，它被称为“纹理寻址模式”（texture addressing mode）。这种类型的常见匹配函数分别是：
- 包裹（wrap)（DirectX），重复（repeat）（OpenGL），或图块 —— 图像在整个表面上重复；在算法上，将丢弃纹理坐标的整数部分。此函数对于使材质的图像重复并覆盖表面很有用，并且这通常是默认设置。
- 镜像（mirror）—— 图像在整个表面上重复，但在其他每个重复上都被镜像（翻转）。例如，图像通常从0到1出现，然后在1和2之间反转，然后在 2 和 3 之间正常，然后反转，依此类推。这可以让纹理边缘带有连续性。
- 钳制（clamp）（DirectX）或夹取到边缘（clamp to edge）（OpenGL）—— 超出 [0，1] 范围的值都将被夹取到该范围。这会导致图像纹理的边缘像素不断重复。此函数对于在纹理的边缘附近采用双线性插值时，避免意外地从纹理的相对边缘进行采样很有用。
- 边框（border）（DirectX）或夹取到边框（clamp to border）（OpenGL）—— [0，1] 以外的纹理坐标使用单独定义的边框颜色进行渲染。例如，由于纹理的边缘将与边框颜色平滑融合，因此该函数可以很好地将贴图渲染到单色表面上。

<center><img width="80%" src="CG/RTR/137.png"/></center>
<center>图像纹理的包裹、镜像、钳制、边框函数的效果</center>

可以为每个纹理轴不同地分配这些匹配函数，例如，纹理可以沿 u 轴重复并固定在 v 轴上。在 DirectX 中，还有一个单次镜像模式（mirror once mode），该模式沿着纹理坐标的零值镜像一次纹理，然后进行钳制，这对于对称贴花很有用。

重复平铺纹理是向场景添加更多视觉细节的廉价方法。但是，这种技术在重复大约三遍纹理后通常看起来并不令人信服，因为眼睛会挑选出重复图案。避免此类周期性问题的常见解决方案是将纹理值与另一个非平铺纹理组合。如在 Andersson 描述的商业地形绘制系统中所见，这种方法可以被大大地扩展。在该系统中，会基于地形类型，高度，坡度和其他因素组合多个纹理。纹理图像还会与场景中放置几何模型位置相绑定，例如灌木和岩石。

避免周期性的另一种选择是使用着色器程序来实现专门的匹配函数，该函数随机地重新组合纹理图案或图块。王浩瓷砖（Wang tiles）是这种方法的一个例子。一个王浩瓷砖集是一小组具有匹配边缘的正方形瓦片。在纹理化过程中会随机选择图块。Lefebvre 和 Neyret 使用相关的纹理读取和表格来实现相似类型的匹配函数，以避图案重复。

### 纹理值 (Texture Values)
在使用匹配函数生成纹理空间坐标之后，会使用坐标去获取纹理值。对于图像纹理，这是通过访问纹理，并通过从图像中检索纹素信息来完成的。

图像纹理构成了实时渲染中绝大多数的纹理使用，但是也可以使用程序化函数（procedural functions）。在程序纹理化的情况下，从纹理空间位置获取纹理值的过程不涉及存储器查找，而是函数的计算。

最直接的纹理值是用于替换或修改表面颜色的 RGB 三元组。类似地，可以返回单个灰度值。另一种要返回的数据是RGBα。α值通常是颜色的不透明度，它确定颜色可能影响像素的程度。综上所述，也就是说，我们可以存储任何其他值，例如表面粗糙度。

从纹理返回的值可以在使用前进行转换。这些转换可以在着色器程序中执行。一个常见的例子是将数据从无符号范围（0.0 到 1.0）重新映射到有符号范围（-1.0 到 1.0），该范围用于对存储在颜色纹理中的法线进行着色。

### 图像纹理化 (Image Texturing)
在图像纹理化中，会将二维图像有效地粘贴到一个或多个三角形的表面上。我们已经完成了计算纹理空间位置的过程。现在，我们将解决在给定位置信息后，从图像纹理获取纹理值的相关问题和算法。

?> 另外，当我们在此处引用像素单元（pixel’s cell）时，是指围绕该像素的屏幕网格单元。像素实际上是显示的颜色值，该颜色值可能（并且应该为了更好的质量）受到与其关联的网格单元外部的样本的影响。

像素着色器通过将纹理坐标值传递给诸如 texture2D 之类的调用来访问纹理。这些值在（u，v）纹理坐标中，由对应功能映射到 [0.0，1.0] 范围。GPU 负责将此值转换为 texel 坐标。

不同 API 中的纹理坐标系之间有两个主要区别。在 DirectX 中，纹理的左上角为（0，0），右下角为（1，1）。这与存储图像数据的图像类型匹配，顶行是指文件中的第一行。在OpenGL中，纹理像素（0，0）位于左下角，是 DirectX 的 y 轴翻转。

像素具有整数坐标，但是我们经常要访问像素之间的位置，并在它们之间进行混合。这提出了像素中心的浮点坐标是什么的问题。Heckbert 讨论了为何有两种可能的系统：<strong>截断（truncating）</strong>和<strong>四舍五入（rounding）</strong>。

DirectX 9 将每个中心定义为（0.0，0.0）—— 使用四舍五入（rounding）。这个系统有些令人困惑，因为在DirectX 的原点，左上像素的左上角的值是（-0.5，-0.5）。DirectX 10 则向前更改为 OpenGL 的系统，在该系统上，纹理元素的中心具有小数值（0.5、0.5），即截断，或者更准确地讲，是向下取整（flooring），小数部分被丢弃。向下取整是一种更自然的系统，可以很好地映射到语言，例如，像素（5、9）为u坐标定义了 5.0 到 6.0 的范围，为 v 定义了 9.0 到 10.0 的范围。

关于这一点，还有一个值得解释的术语是从属纹理读取（dependent texture read），它有两个定义：
- 第一种特别适用于移动设备。当通过 texture2D 或类似方法访问纹理时，每当像素着色器计算纹理坐标而不是使用从顶点着色器传入的未修改纹理坐标时，就会产生从属纹理读取。请注意，这意味着对传入的纹理坐标进行任何更改，甚至包括交换 u 和 v 值之类的简单操作。当着色器没有相关纹理读取时，较早的不支持 OpenGL ES 3.0 的移动 GPU 可以更有效地运行，因为这可以预先获取纹理像素数据。
- 另一个较旧的定义对于早期的台式机 GPU 特别重要。在这种情况下，当一个纹理的坐标取决于某些先前纹理的值的结果时，就会发生从属纹理读取。例如，一种纹理可能会更改着色法线，进而改变用于访问立方体贴图的坐标。在早期的 GPU 上，这种功能受到限制甚至不存在。如今，此类读取可能会影响性能，具体取决于批处理中计算的像素数量以及其他因素。

GPU 中使用的纹理图像大小通常为2^m×2^n纹理像素，其中 m 和 n 为非负整数。这些被称为二次幂（power-of-two，POT）纹理。现代 GPU 可以处理任意大小的非 2 幂（non-power-of-two，NPOT）纹理，从而可以将生成的图像视为纹理。但是，某些较旧的移动 GPU 可能不支持 NPOT 纹理的 mipmapping。图形加速器对纹理大小有不同的上限。例如，DirectX 12 最多允许16384^2个纹理像素。

假设我们有一个 256×256 纹理像素的纹理，并且我们想将其用作正方形的纹理。只要屏幕上投影的正方形与纹理的大小大致相同，正方形的纹理看起来就几乎是原始图像。但是，如果投影的正方形覆盖了原始图像的十倍像素（称为放大，magnification），或者投影的正方形仅覆盖了屏幕的一小部分（缩小，minification），会发生什么呢？ 

答案是，这取决于你决定在这两种情况下使用哪种采样和滤波方法。

#### 放大 (Magnification)
例如，将大小为 48×48 纹理像素的纹理贴到一个正方形上，相对于该纹理大小而言，该正方形离观察者很近，因此基础图形系统必须放大该纹理。放大倍数最常用的滤波技术是最近邻（nearest neighbor）（实际滤波器称为 box 滤波器）和双线性插值（bilinear interpolation）。还有三次卷积（cubic convolution），它使用 4× 4或 5×5 纹素阵列的加权和。这样可以实现更高的放大质量。尽管目前尚不普遍支持三次卷积（也称为双三次插值，bicubic interpolation）的本机硬件，但它可以在着色器程序中执行。

最近邻方法技术的一个特征是各个纹理像素可能变得明显。我们将该现象称为像素化（pixelation），这是因为该方法在放大时会采用最接近每个像素中心的纹理像素值，从而导致块状的外观。尽管此方法的质量有时很差，但每个像素仅需要提取一个纹理像素。

<center><img width="80%" src="CG/RTR/138.png"/></center>
<center>48×48 图像的纹理放大率为 320×320 像素。左：最近邻滤波，其中每像素选择最近的纹理像素。中：使用四个最近的纹理像素的加权平均值进行双线性滤波。右：使用 5×5 最近的纹理像素的加权平均值进行三次滤波</center>

在中间的肖像图中，使用了双线性插值（有时称为线性插值）。对于每个像素，这种滤波都会找到四个相邻的纹理像素，并在二维上进行线性插值，以找到像素的混合值。可以看到，其结果是模糊的，与使用最近邻方法相比，产生的许多锯齿现象已消失。

?> 这里做个小实验，请在眯着眼睛的同时尝试看左边图像，因为此举的效果与低通滤波器大致相同。

<center><img width="80%" src="CG/RTR/139.png"/></center>
<center>双线性插值。涉及的四个纹理像素由左侧的四个正方形表示，纹理像素中心为蓝色。右边是由四个纹理像素的中心形成的坐标系</center>

将纹理访问函数定义为 t（x，y），其中 x 和 y 是整数，并返回纹理像素的颜色。可以将任何位置（u'，v'）的双线性插值颜色计算为两步过程：
首先，水平（使用u'）对底部纹理像素t（x，y）和t（x + 1，y）进行插值，类似地，也对最顶部的两个纹理像素t（x，y + 1）和t（ x + 1，y + 1）进行插值。对于底部的纹理像素，我们获得（1 − u'）t（x，y）+ u't（x + 1，y），对于顶部的像素，我们得出（1 − u'） t（x，y +1）+ u't（x +1，y +1）（上方的绿色圆圈）。然后使用 v' 对这两个值进行垂直插值，因此在 (p_u,p_v) 处的双线性插值颜色 b 为：

<center><img width="70%" src="CG/RTR/140.png"/></center>

凭直觉，接近我们样本位置的纹理像素将对最终值产生更大的影响。这确实是我们在等式中所看到的。在（x + 1，y +1）处的右上纹理像素具有 u'v' 的影响。

!> 这里请注意对称性：右上的影响等于由左下角和采样点形成的矩形区域。回到我们的示例，这意味着从该纹理像素检索的值将乘以 0.42×0.74，特别是 0.3108。从该纹理像素的顺时针方向，其他乘数分别为 0.42×0.26、0.58×0.26 和 0.58×0.74，所以这四个权重的总和为1.0。

一种解决放大倍率模糊的常见方法是使用细节纹理（detail textures）。这些纹理代表了精细的表面细节，从手机上的划痕到地形上的灌木丛。这样的细节作为单独的纹理以不同的比例覆盖在放大的纹理上。细节纹理的高频重复图案与低频放大的纹理相结合，具有类似于使用单个高分辨率纹理的视觉效果。

双线性插值在两个方向上进行线性插值。但是，线性插值并不是我们想要的。假设纹理由棋盘图案中的黑白像素组成。使用双线性插值会得出整个纹理上变化的灰度样本。通过重新映射这一操作，例如，所有低于 0.4 的灰度都是黑色，所有高于 0.6 的灰度都是白色，并且中间的灰度都被拉伸以填充间隙，这样就可以让纹理看起来更像是棋盘，同时还使纹理像素之间有些融合。

<center><img width="70%" src="CG/RTR/141.png"/></center>
<center>最近邻，双线性插值，以及通过重新映射介于两者之间的情况，使用相同的2×2棋盘纹理。请注意，由于纹理和图像网格不完全匹配，最近邻采样会给出略有不同的正方形大小</center>

使用更高分辨率的纹理将具有相似的效果。例如，假设每个方格正方形由 4×4 的纹理像素而不是 1×1 组成。在每个方格的中心周围，插值的颜色将完全是黑色或白色。

图右侧，使用了双三次滤波器，剩余的块状现象已被大大消除。这里需要注意的是，双三次滤波器比双线性滤波器更昂贵。但是，许多高阶滤波器可以表示为重复线性插值。其结果，就是可以通过几次的查找来利用纹理单元中用于线性插值的 GPU 硬件。

如果认为双三次滤波器太昂贵，Qu´ılez 提出了一种简单技术，即使用平滑曲线在一组 2×2 纹素之间进行插值。我们首先描述曲线，然后描述技术。两条常用的曲线是平滑步幅曲线（smoothstep curve）和五阶曲线（quintic curve）：

<center><img width="60%" src="CG/RTR/142.png"/></center>

这些在许多其他情况下都很有用，在这些情况下，你需要从一个值平滑地插值到另一个值。平滑步幅曲线具有 s'（0）= s'（1）=  0 的特性，并且在 0 和 1 之间平滑。五阶曲线具有相同的特性，但是 q''（0）= q'' （1）= 0，即，曲线的起点和终点的二阶导数也为 0。两条曲线如图所示：

<center><img width="80%" src="CG/RTR/143.png"/></center>
<center>平滑步幅曲线s（x）（左）和五阶曲线q（x）（右）</center>

该技术首先通过将样本乘以纹理尺寸并相加 0.5 来计算（u'，v'）。保留整数部分以备后来使用，并将分数存储在 u' 和 v' 中，它们在 [0，1] 的范围内。然后将（u'，v'）变换为（tu，tv）=（q（u'），q（v'）），但仍在 [0，1] 的范围内。最后，减去 0.5，再将整数部分相加； 然后，将所得的 u 坐标除以纹理宽度，并以 v 进行类似的操作。此时，新的纹理坐标与 GPU 提供的双线性插值查找配合使用。

!> 请注意，此方法将在每个纹理像素处产生平稳状态，这意味着如果这些纹理像素位于 RGB 空间中的一个平面上，则此类型的插值将给出平滑但仍然呈阶梯状的外观，但这可能不是我们想要的。

<center><img width="80%" src="CG/RTR/144.png"/></center>
<center>四种放大一维纹理的方法。橙色圆圈表示纹理像素的中心以及纹理像素值（高度）。从左到右分别是：最近邻、线性、在相邻纹理像素之间使用五阶曲线、使用三次插值</center>

#### 缩小 (Minification)
当纹理缩小时，多个纹理像素可能会覆盖像素的单元。为了获得每个像素的正确颜色值，您应该整合影响像素的纹理像素的效果。但是，很难精确地确定特定像素附近所有纹理像素的确切影响，并且实际上，我们不可能实时完美地做到这一点。

<center><img width="80%" src="CG/RTR/145.png"/></center>
<center>缩小：通过一排像素单元的棋盘纹理的正方形视图，大致显示了许多纹理像素对每个像素的影响</center>

由于此限制，在 GPU 上使用了几种不同的方法。一种方法是使用最近邻的像素，它的工作原理与相应的放大滤波器完全相同，即，它选择在像素像元中心可见的纹理像素。该滤波器可能会导致严重的走样问题。

下图中，最上面的图使用了最近邻方法。在地平线上，会出现伪像，因为我们只选择了影响像素的许多纹理像素之一来表示表面。当表面相对于观察者移动时，这些伪像甚至会更加明显，并且这是我们说的时间性走样（temporal aliasing）的一种表现形式。

<center><img width="80%" src="CG/RTR/146.png"/></center>
<center>顶部图像是通过点采样（最近邻）渲染的，中心是 mipmapping 渲染的，底部是求和区域表（summed area tables）的渲染</center>

另一个经常被使用的滤波器是双线性插值，其工作原理与放大滤波器完全相同。该滤波器仅比最邻近的方法好一点点。它混合了四个纹理像素，而不是仅使用一个，但是当一个像素受到四个以上纹理像素的影响时，滤波器便会迅速失效并产生走样。

更好的解决方案是可能的。例如，可以通过采样和滤波技术解决走样问题。纹理的信号频率取决于其纹理像素在屏幕上的间隔距离。由于奈奎斯特限制，我们需要确保纹理的信号频率不大于采样频率的一半。

例如，一个图像是由交替的黑白线组成的，相隔一个纹理像素。波长为两个纹理像素宽（从黑线到黑线），因此频率为 1/2。要在屏幕上正确显示此纹理，频率必须至少为 2 × 1/2，即每个纹理像素至少对应一个像素。因此，对于一般的纹理，每个像素最多应只有一个纹理像素，以避免走样。

为了达到这个目标，必须提高像素的采样频率或降低纹理频率。但是，这些仅会有限地增加采样频率。为了更充分地解决这个问题，目前已经开发了各种纹理缩小算法。

所有纹理反走样算法背后的基本思想是相同的：对纹理进行预处理并创建数据结构，这将有助于计算像素上一组纹理像素的效果的快速近似值。对于实时渲染，这些算法具有使用固定数量的时间和资源来执行的特征。用这种方式，每个像素会获取固定数量的样本，并将其组合起来以计算（可能很大）数量的纹理像素的效果。

#### Mipmapping 
最流行的纹理反走样方法称为 mipmapping。现在已生产的所有图形加速器均以某种形式实现了该功能。“Mip”在细小语言中代表 multum，在拉丁语中则是“在一个小地方有很多东西”的名字。

当使用 mipmapping 最小化滤镜时，在进行实际渲染之前，使用一组较小版本的纹理增强原始纹理。纹理（零级）下采样（downsampled）到原始面积的四分之一，其中每个新的纹理像素值通常计算为原始纹理中四个相邻纹理像素的平均值。新的一级纹理有时称为原始纹理的子纹理。递归执行缩小操作，直到纹理的一个或两个尺寸等于一个纹理像素。整个图像集通常称为 mipmap 链（mipmap chain）。

<center><img width="60%" src="CG/RTR/147.png"/></center>
<center>通过在金字塔的底部拍摄原始图像（级别0），然后将每个 2×2 区域平均为下一级别的纹理像素值，即可形成 mipmap。垂直轴是第三纹理坐标 d。在该图中，d 不是线性的。它用于衡量样本用于插值的两个纹理级别</center>

形成高质量 Mipmap 的两个重要元素是良好的滤波和伽马校正。形成 Mipmap 级别的常见方法是获取每 2×2 组像素，并将它们平均以得到 Mip 像素值。这样操作的话，使用的滤波器便被称为 box 滤波器（box filter），它可能是最差的滤波器之一。这可能会导致质量差，因为它会不必要地模糊低频，同时保留一些会引起混叠的高频。最好使用高斯，Lanczos，Kaiser或类似的滤波器。

!> 对于在非线性空间中编码的纹理（例如sRGB），在滤波时忽略伽玛校正将会修改感知到的 Mipmap 级别的亮度。当你离对象越来越远并且使用了未经校正的 Mipmap 时，对象的整体外观可能会更暗，并且对比度和细节也会受到影响。因此，重要的是将此类纹理从 sRGB 转换为线性空间，在该空间中执行所有 mipmap 滤波，然后将最终结果转换回 sRGB 颜色空间进行存储。

?> 大多数 API 支持 sRGB 纹理，因此将在线性空间中正确生成 mipmap，并将结果存储在 sRGB中。访问 sRGB 纹理时，首先将它们的值转换为线性空间，以便正确执行放大和缩小。

要对数百或数千个像素进行滤波时，mipmap 的生成对此问题特别敏感。为了获得最佳的结果，通常需要专门的 mipmap 生成方法。

构造纹理时访问此结构的基本过程很简单。屏幕像素将纹理自身上的区域包围起来。当像素区域投影到纹理上时，它包含了一个或多个纹理像素。我们的目的是大致确定多少的纹理会影响到像素。有两种用于计算 d 的常用量度（OpenGL 将其称为 λ，它也被称为细节纹理级别，texture level of detail）。一种方法是使用像素单元所形成的四边形的较长边缘，用它来近似像素的覆盖范围； 另一种方法是使用四个微分 ∂u/∂x，∂v/∂x，∂u/∂y 和 ∂v/∂y 的最大绝对值作为度量。每个微分是纹理坐标相对于屏幕轴的变化量的量度。例如，∂u/∂x 是一个像素的 u 纹理值沿 x 屏幕轴的变化量。

<center><img width="70%" src="CG/RTR/148.png"/></center>
<center>左侧是一个正方形像素单元及其纹理视图。右边是像素单元在纹理本身上的投影</center>

使用 Shader Model 3.0 或更高版本的像素着色器程序可以使用这些渐变值。由于它们基于相邻像素值之间的差异，在受动态流控制（dynamic flow control）影响的像素着色器的某些部分中，我们无法访问它们。为了在这样的部分中（例如，在循环内）执行纹理读取，必须较早地计算导数。请注意，由于顶点着色器无法访问渐变信息，因此在使用顶点纹理时，需要在顶点着色器本身中计算渐变或细节级别并将其提供给 GPU。

计算 d 坐标的目的是确定沿 mipmap 的金字塔轴采样的位置。目标是达到奈奎斯特比率的像素与纹理像素比至少为 1：1。这里的重要原理是，随着像素单元包含更多的纹理像素和 d 的增加，将访问更小，更模糊的纹理版本。（u，v，d）三元组用于访问 mipmap。值 d 与纹理级别类似，但是 d 是整数之间的距离的分数，而不是整数值。采样高于 d 位置的纹理级别和低于 d 位置的纹理级别。（u，v）位置用于从这两个纹理级别的每一个中检索双线性插值样本。然后再根据从每个纹理级别到 d 的距离对生成的样本进行线性插值。整个过程称为三线性插值（trilinear interpolation），是逐像素执行的。

d 坐标上的一个用户控制参数是细节偏差水平（level of detail bias，简称 LOD bias，LOD偏差）。这是与 d 相加的值，因此会影响纹理的相对清晰度。如果我们进一步向上移动金字塔以开始（增大d），则纹理将变得模糊。对于任何给定的纹理，良好的 LOD 偏差将随图像类型和使用方式而变化。例如，开始时有些模糊的图像可能会使用负偏差，而用于纹理化的滤波效果差（走样）的合成图像可能会使用正偏差。可以为纹理整体或像素着色器中的每个像素指定偏差。为了更好地控制，用户可以提供 d 坐标或用于计算它的导数。

<strong>mipmapping 的好处在于，访问并插值了预组合的像素集，而不是试图求和单独影响像素的所有纹理素。</strong>无论缩小多少，此过程都会花费固定的时间。

但是，mipmapping 有几个缺陷：
- 一个主要的缺陷是模糊。想象一下，一个像素单元在 u 方向上覆盖大量纹理像素，而在 v 方向上仅覆盖少数像素。这种情况通常发生在观看者近乎边缘地沿着带纹理的表面观看的时候。实际上，可能需要沿着纹理的一个轴进行最小化，而沿着另一个轴进行放大。
- 访问 mipmap 的效果是检索了纹理上的正方形区域。为避免产生走样，我们选择纹理上像素单元的近似覆盖率的最大度量。这导致检索到的样本通常相对模糊。

#### 求和区域表 (Summed-Area Table)
避免过度模糊的另一种方法是求和区域表（SAT）。

要使用此方法，首先要创建一个数组，该数组的大小等于纹理的大小，但包含更多的颜色存储精度位（例如，红色，绿色和蓝色分别为 16 位或更多）。在此数组的每个位置，必须计算并存储由该位置和纹理像素（0，0）（原点）形成的矩形中所有相应纹理纹理像素的总和。在纹理化过程中，像素单元在纹理上的投影会被矩形所限制。然后访问求和区域表以确定该矩形的平均颜色，该颜色作为像素的纹理颜色传回。使用如下图所示的矩形的纹理坐标计算平均值，可以使用下式来完成：

<center><img width="60%" src="CG/RTR/149.png"/></center>

<center><img width="70%" src="CG/RTR/150.png"/></center>
<center>左侧是一个正方形像素单元及其纹理视图。右边是像素单元在纹理本身上的投影</center>

在此，x 和 y 是矩形的纹素坐标，而 s [x，y] 是该纹素的求和区域值。该方程的工作原理是：从右上角到原点，取整个区域的总和，然后通过减去相邻角的贡献减去面积 A 和 B 。区域 C 已被减去两次，因此将其添加到左下角。注意（x_u，y_u）是区域 C 的右上角，即（x_u + 1，y_u + 1）是边界盒的左下角。

求和区域表是所谓的<strong>各向异性滤波算法</strong>的一个示例。这样的算法在非正方形区域上检索纹理像素值。但是，SAT 能够在主要水平和垂直方向上最有效地做到这一点。

!> 注意，对于 16 × 16 或更小的尺寸的纹理，求和区域表至少需要两倍的内存，而较大的纹理则需要更高的精度。

求和区域表可以在现代 GPU 上实现，并以合理的整体内存成本提供更高的质量。改进的滤波对于高级渲染技术的质量至关重要。

#### 无约束各向异性滤波 (Unconstrained Anisotropic Filtering)
对于当前的图形硬件，进一步改善纹理滤波的最常用方法是重用现有的 mipmap 硬件。基本思想是对像素单元进行反投影，然后对纹理上的这个四边形（四边形）进行几次采样，然后合并采样。如上所述，每个 mipmap 样本都有一个位置和一个与其关联的正方形区域。该算法不使用单个 mipmap 样本来近似四边形的覆盖范围，而是使用几个正方形覆盖四边形。

可以使用四边形的较短边来确定 d（与 mipmapping 不同，后者通常使用较长边）；这会使每个 Mipmap 样本的平均面积变小（从而减少模糊）。四边形的较长边用于创建平行于较长边并穿过四边形中间的各向异性线。当各向异性的量在 1：1 和 2：1 之间时，沿着这条线采集两个样本。在较高的各向异性比率下，沿轴将获取更多的样本。

<center><img width="70%" src="CG/RTR/151.png"/></center>
<center>各向异性滤波。像素单元的反投影产生四边形。在较长的侧面之间形成各向异性线</center>

?> 该方案允许各向异性线沿任何方向延伸，因此没有求和区域表的限制。因为它使用 mipmap 算法进行采样，所以它也不需要比 mipmaps 更多的纹理内存。

<center><img width="70%" src="CG/RTR/151.png"/></center>
<center>Mipmap 与各向异性滤波。左侧完成了三线性 mipmapping，右侧进行了 16：1 各向异性滤波。展望未来，各向异性滤波可提供更清晰的结果，同时走样程度最小</center>

### 体积纹理 (Volume Textures)
图像纹理的直接扩展是通过（u，v，w）（或（s，t，r）值）访问的三维图像数据。例如，医学成像数据可以被生成为三维网格。通过在该网格中移动多边形，可以查看这些数据的二维切片。一个相关的想法是用这种形式表示体积的灯光。通过找到其在该体积内的位置值以及光的方向，可以找到表面上某个点的照明。

大多数 GPU 支持对体积纹理进行 mipmapping。由于在体积纹理的单个 mipmap 级别内进行滤波涉及三线性插值，因此在 mipmap 级别之间进行滤波需要四线性插值。由于这涉及对 16 个纹理像素的结果进行平均，因此可能会导致精度问题，可以使用更高精度的体积纹理来解决。Sigg 和 Hadwiger 讨论了与体积纹理有关的此问题和其他问题，并提供了执行滤波和其他操作的有效方法。

尽管体积纹理具有更高的存储要求，并且滤波成本更高，但它们确实具有一些独特的优势。由于可以将三维位置直接用作纹理坐标，因此可以跳过为三维网格找到良好的二维参数化的复杂过程。这避免了二维参数化中常见的变形和接缝问题。体积纹理也可以用于表示诸如木材或大理石的材料的体积结构。具有这种纹理的模型看起来是用这种材料雕刻而成的。

由于不使用绝大多数样本，因此使用体积纹理进行表面纹理化的效率极低。Benson 、 Davis 和 DeBry 等人讨论了在稀疏八叉树（sparse octree）结构中存储纹理数据。该方案非常适合交互式三维绘画系统，因为在创建时不需要为表面分配明确的纹理坐标，并且八叉树可以将纹理细节保持在所需的任何级别。Lefebvre 等。讨论了在现代 GPU 上实现八叉树纹理的细节。Lefebvre 和 Hoppe 讨论了将稀疏体积数据打包为明显较小的纹理的方法。

### 立方体贴图 (Cube Maps)
另一类纹理是立方体纹理或立方体贴图，它具有六个方形纹理，每个纹理与一个立方体的一个面相关联。使用三分量纹理坐标向量访问立方体贴图，该向量指定了从立方体中心向外指向的光线的方向。光线与立方体相交的点如下。具有最大幅度的纹理坐标选择相应的面部（例如，向量（-3.2、5.1，-8.4）选择 -z 面部）。其余两个坐标除以最大幅度坐标的绝对值，即 8.4。它们现在的范围是 -1 到 1，并且只需将其重新映射到 [0，1] 即可计算纹理坐标。例如，坐标（-3.2，5.1）映射为（（-3.2 / 8.4 + 1）/ 2，（5.1 / 8.4 + 1）/ 2）≈（0.31，0.80）。多维数据集贴图用于表示作为方向函数的值；它们最常用于环境映射。

### 纹理表示 (Texture Representation)
处理应用程序中的许多纹理时，有几种提高性能的方法，例如使用纹理图集。

> 为了能够为 GPU 分配尽可能多的工作，通常最好更改状态的操作要尽可能少。为此，可以将几张图像放在一个较大的纹理中，我们称为<strong>纹理图集</strong>。

!> 注意，子纹理的形状可以是任意的，由于 mipmap 的上层可能包含几个单独的，不相关的形状，因此也需要注意 mipmap 的生成和访问。

<center><img width="80%" src="CG/RTR/153.png"/></center>
<center>左：一个纹理图集，其中将九个较小的图像合成为一个大纹理。右：一种更现代的方法是将较小的图像设置为纹理数组，这是大多数 API 中都存在的概念</center>

使用图集的一个困难是包裹/重复和镜像模式，这不会作用到子纹理，而只会作用到整个纹理。为图集生成 mipmap 时，可能会发生另一个问题，其中一个子纹理会渗入另一个子纹理。但是，这可以通过在将每个子纹理放入大型纹理集之前分别为它们生成 mipmap 层次结构，并对子纹理使用 2 的幂次分辨率来避免这种情况。

解决这些问题的一种更简单的解决方案是使用一种称为纹理数组（texture arrays） 的 API 构造，该构造完全避免了 mipmapping 和重复模式的所有问题。纹理数组中的所有子纹理都必须具有相同的尺寸、格式、mipmap 层次结构和 MSAA 设置。就像纹理地图集一样，仅对纹理数组执行一次设置，然后就可以使用着色器中的索引访问任何数组元素。这比绑定每个子纹理快 5 倍。

API 还支持无绑定纹理（bindless textures），这也可以帮助避免状态更改的成本。如果没有无约束纹理，则使用 API 将纹理绑定到特定的纹理单元。其中一个问题是纹理单元数量的上限，这会使程序员感到麻烦。驱动程序确保纹理位于 GPU 侧。使用无绑定纹理时，纹理数量没有上限，因为每个纹理仅由一个 64 位指针（有时称为“句柄”，handle）与其数据结构相关联。可以通过许多不同方式来访问这些句柄，例如，通过 uniforms，通过变化的数据，来自其他纹理或从着色器存储缓冲区对象（SSBO）。应用程序需要确保纹理驻留在 GPU 端。无边界纹理避免了驱动程序中的任何类型的绑定成本，从而使渲染速度更快。

### 纹理压缩 (Texture Compression)
直接解决内存和带宽问题以及缓存问题的一种方案是固定比率纹理压缩（fifixed-rate texture compression）。通过让 GPU 即时解码压缩的纹理，纹理可以需要更少的纹理内存，因此可以增加有效的缓存大小。至少同样重要的是，此类纹理的使用效率更高，因为它们在访问时消耗的内存带宽更少。一个相关但不同的用例是添加压缩以提供更大的纹理。例如，在  分辨率下每个纹理像素使用 3 字节的非压缩纹理将占用 768 kB。使用纹理压缩时，压缩比为6：1， 1024 × 1024 分辨率的纹理将仅占用 512 kB。

图像文件格式（例如 JPEG 和 PNG）中使用了多种图像压缩方法，但是在硬件中对其进行解码的消耗是昂贵的。S3 开发了一种称为 S3 纹理压缩（S3 Texture Compression，S3TC）的方案，该方案被选作 DirectX 的标准，并称为 DXTC。在 DirectX 10 中，它称为 BC（用于块压缩）。此外，它是 OpenGL 中的事实上的标准，因为几乎所有 GPU 都支持它。它具有创建大小固定的压缩图像的优点，压缩图像具有独立编码的片段，并且解码简单（因此快速）。图像的每个压缩部分都可以独立处理。没有共享的查找表或其他依赖项，从而简化了解码。

DXTC / BC 压缩方案有七个变体，它们具有一些共同的属性。编码是在 4×4 纹素块（也称为图块）上完成的。每个块分别编码。编码基于插值。对于每个编码量，存储两个参考值（例如，颜色）。将为该块中的 16 个纹理像素的每一个保存一个插值因子。它沿着两个参考值之间的直线选择一个值，即它等于或从两种存储的颜色进行插值的颜色。压缩来自仅存储两种颜色以及每个像素较短的索引值。

<center><img width="100%" src="CG/RTR/154.png"/></center>
<center>纹理压缩格式。所有这些压缩块均为4×4纹素。存储列显示每个块的字节数（B）和每个texel的位数（bpt）。参考颜色的表示法是首先是通道，然后是每个通道的位数。例如，RGB565 表示红色和蓝色为5位，而绿色通道为6位</center>

确切的编码在这七个变体之间有所不同，请注意，“ DXT” 表示 DirectX 9 中的名称，“ BC” 表示 DirectX 10 及更高版本中的名称。从表中可以看出，BC1具有两个16位参考RGB值（5位红色，6个绿色，5个蓝色），每个纹理像素具有 2 位插值因子，可以从参考值之一或两个中间值中进行选择。与未压缩的 24 位 RGB 纹理相比，这表示 6：1 的纹理压缩率。BC2 以与 BC1 相同的方式对颜色进行编码，但为量化（原始）alpha 值每纹理像素（bpt）添加4位。对于 BC3，每个块都有以与 DXT1 块相同的方式编码的 RGB 数据。此外，使用两个 8 位参考值和每个像素 3 位插值因子对 alpha 数据进行编码。每个纹理像素可以选择参考 alpha 值之一或六个中间值之一。（备用 DXT1 模式为透明像素保留了四个可能的插值因子之一，从而将插值的数量限制为三个，即两个参考值及其平均值）BC4 具有一个通道，在 BC3 中编码为 alpha。BC5 包含两个通道，每个通道都像 BC3 中那样进行编码。

BC6H 用于高动态范围（HDR）纹理，其中每个纹理像素最初每个 R，G 和 B 通道具有 16 位浮点值。此模式使用 16 个字节，它具有用于单行的一种模式（类似于上述技术），以及用于两行的另一种模式，其中每块纹理可以从一小组分区中进行选择。两种参考颜色也可以进行增量编码以获得更高的精度，并且根据所使用的模式，它们也可以具有不同的精度。在 BC7 中，每个纹理块可以包含一到三行，并存储 8 bpt。我们的目标是 8 位 RGB 和 RGBA 纹理的高质量纹理压缩。它与 BC6H 共享许多属性，但是却是 LDR 纹理的格式，而 BC6H 是 HDR 的格式。请注意，在 OpenGL 中，BC6H 和 BC7 分别称为 BPTC FLOAT 和 BPTC。立方体或体积纹理以及二维纹理都可以应用这些压缩技术。

这些压缩方案的主要缺点是它们是有损的。也就是说，通常无法从压缩版本中检索原始图像。对于 BC1 - BC5，仅使用四个或八个插值来表示 16 个像素。如果图块中包含更多数量的不同值，则会有一些损失。实际上，如果正确使用，这些压缩方案通常会提供可接受的图像保真度。

BC1 - BC5 的问题之一是，用于块的所有颜色都位于 RGB 空间中的直线上。例如，红色，绿色和蓝色不能在一个块中表示。BC6H 和 BC7 支持更多的线路，因此可以提供更高的质量。

对于 OpenGL ES，选择了另一种称为爱立信纹理压缩（Ericsson texture compression，ETC）的压缩算法以包含在 API 中。该方案具有与 S3TC 相同的功能，即快速解码，随机访问，无间接查找和固定速率。它将 4×4 像素的块编码为 64 位，即每个纹理像素使用 4 位。基本思想如图 6.21 所示。每个 2×4 块（或 4×2 块，取决于提供最佳质量的块）都存储底色。每个块还从一个小的静态查找表中选择一组四个常量，并且块中的每个纹理像素都可以选择添加此表中的值之一。这种方法修改了每个像素的亮度。其图像质量与 DXTC 相当。

<center><img width="80%" src="CG/RTR/155.png"/></center>
<center>ETC（爱立信纹理压缩）对像素块的颜色进行编码，然后修改每个像素的亮度以创建最终的纹理像素颜色</center>

在 OpenGL ES 3.0 中包含的 ETC2 中，未使用的位组合用于为原始的 ETC 算法添加更多模式。未使用的比特组合为压缩表示（例如 64 位），它被压缩为与另一压缩表示相同的图像。例如，在 BC1 中，将两个参考颜色设置为相同是没有用的，因为这将指示恒定的色块，只要一种参考颜色包含该恒定色，则可以依次获得该恒定色块。在 ETC 中，一种颜色也可以从第一种颜色加上带符号的数字进行增量编码，因此计算可能会上溢或下溢。这种情况被用来表示其他压缩模式。ETC2 添加了两个新模式，每个块具有四种颜色（以不同方式派生），而最终模式是 RGB 空间中的一个平面，用于处理平滑过渡。

爱立信Alpha压缩（Ericsson alpha compression，EAC）用一个分量（例如 Alpha）压缩图像。这种压缩类似于基本的 ETC 压缩，但仅用于一个分量，并且结果图像的每个像素纹理存储 4 位。可以选择将其与ETC2组合使用，此外，可以使用两个 EAC 通道来压缩法线。所有的 ETC1，ETC2 和 EAC 都是 OpenGL 4.0 核心配置文件，OpenGL ES 3.0， Vulkan 和 Metal 的一部分。

压缩法线贴图时需要格外小心。专为 RGB 颜色设计的压缩格式通常无法正常显示 xyz 数据。大多数方法都利用这样的事实：即已知法线为单位长度，并进一步假定其 z 分量为正（正切空间法线的合理假设）。这仅允许存储法线的 x 和 y 分量。z 分量是动态导出的：

<center><img width="25%" src="CG/RTR/156.png"/></center>

由于仅存储两个分量，而不是三个，因此它本身会导致一定的压缩。由于大多数 GPU 本身并不支持三分量纹理，因此这也避免了浪费分量的可能性（或必须在第四分量中打包其他数量的分量）。通常，通过将 x 和 y 分量存储在BC5 / 3Dc格式纹理中，可以实现进一步的压缩。

由于每块的参考值划分了最小和最大 x 和 y 分量值，因此可以将它们视为在 xy 平面上定义边界框。三位插值因子允许在每个轴上选择八个值，因此会将边界框划分为 8×8 的可能的法线网格。或者，可以使用 EAC 的两个通道（用于 x 和 y），然后按照上面的定义计算 z。

<center><img width="80%" src="CG/RTR/157.png"/></center>
<center>左：球体上的法线单位只需要编码 x 和 y 分量。右：对于 BC4 / 3Dc，xy 平面中的一个框将法线围起来，每 4×4 个法线块可在此框内使用 8×8 个法线（为清楚起见，此处仅显示 4×4 个法线）</center>

不支持 BC5 / 3Dc 或 EAC 格式的硬件上，常见的回退（fallback）是使用 DXT5 格式的纹理并将两个分量存储在绿色和 alpha 分量中（因为这些分量的存储精度最高） 。其他两个分量未使用。

PVRTC 是 Imagination Technologies 研发的在名为 PowerVR 的硬件上可用的纹理压缩格式，其最广泛的用途是用于 iPhone 和 iPad。它为每个纹理像素提供 2 位和 4 位的方案，并压缩 4×4 纹理像素的块。其关键思想是提供图像的两个低频（平滑）信号，这些信号是使用相邻的像素数据块进行插值获得的。然后，每个纹理像素使用 1 或 2 位在图像上的两个信号之间进行插值。

自适应可伸缩纹理压缩（Adaptive scalable texture compression，ASTC）的不同之处在于，它将 n×m 纹理像素的块压缩为 128 位。块大小从 4×4 到 12×12 不等，这导致了不同的比特率，从每纹理像素低至 0.89 位到每纹理像素高达 8 位。ASTC 使用多种技巧来实现紧凑的索引表示，并且每个块都可以选择行数和端点编码。此外，ASTC 可以处理每个纹理 1 至 4 个通道以及 LDR 和 HDR 纹理。ASTC 是 OpenGL ES 3.2 及更高版本的一部分。

上面介绍的所有纹理压缩方案都是<strong>有损</strong>的，并且在压缩纹理时，可以选择在此过程上花费不同的时间。可以花几秒钟甚至几分钟来进行压缩，以获得更高的质量。因此，该过程通常是作为脱机预处理完成的，并且会存储起来供以后使用。另外，如果只花费几毫秒的时间压缩，那结果的质量会较低，但是这样的话纹理可以实时压缩并立即使用。

关于实时压缩的一个例子是天空盒，每隔一秒左右就会重新生成一次，此时云层可能已经略微移动了。由于解压缩是使用固定功能的硬件完成的，因此该过程的速度非常快。其中压缩的过程会并且确实比解压缩花费更长的时间，这种差异称为数据压缩不对称（data compression asymmetry）。

Kaplanyan 提出了几种可以改善压缩纹理质量的方法。对于包含颜色的纹理和法线贴图，建议使用每个分量 16 位的方式创作贴图。对于彩色纹理，执行直方图重归一化（histogram renormalization）（在这16位上），然后使用着色器中的比例和偏置常数（每个纹理）反转其效果。直方图归一化是一种将图像中使用的值扩展到整个范围的技术，这实际上是一种对比度增强。每个分量使用 16 位可确保在重新归一化后直方图中没有闲置的时隙，这减少了许多纹理压缩方案可能引入的条带失真。如图 6.23 所示。此外，如果75％的像素高于116/255，Kaplanyan建议对纹理使用线性颜色空间，否则将纹理存储在sRGB中。对于法线贴图，他还指出BC5 / 3Dc通常独立于y来压缩x，这意味着并非总能找到最佳法线。相反，他建议对法线使用以下错误度量：

<center><img width="30%" src="CG/RTR/158.png"/></center>

其中 n 是原始法线，n_c 是相同的法线压缩，然后解压缩。

<center><img width="70%" src="CG/RTR/159.png"/></center>
<center>每个分量使用 16 位的效果，而纹理压缩时使用 8 位的效果。从左到右：原始纹理，DXT1 从每个分量 8 位压缩，DXT1 从每个分量 16 位压缩，并在着色器中进行了重新归一化。为了更清楚地显示效果，已在强光下渲染了纹理</center>

应当注意，还可以在不同的颜色空间中压缩纹理，这可以用来加速纹理压缩。常用的变换是：RGB→YC_oC_g。

<center><img width="50%" src="CG/RTR/160.png"/></center>

其中，Y 是亮度项，C_o 和 C_g 是色度项。逆变换的消耗也并不昂贵：

<center><img width="60%" src="CG/RTR/161.png"/></center>

这两个变换是线性的，它是矩阵向量乘法，其本身即是线性的，这仅仅相当于做了几次加法。这一点很重要，因为我们可以存储 YC_oC_g，而不是将 RGB 存储在纹理中。纹理处理器仍然可以在 YC_oC_g 空间中执行滤波，然后像素着色器可以根据需要转换回 RGB。应该注意的是，这种变换本身是有损的，这可能会有问题，也可能不会。

还有另一个可逆的 RGB→YC_oC_g 变换，可以总结为

<center><img width="60%" src="CG/RTR/162.png"/></center>

符号 ≫ 为右移运算。Griffin 和 Olano 的研究表明，将多个纹理应用于具有复杂着色模型的几何模型时，纹理的质量通常可以很低，但却不会有明显的视觉差异。因此，根据使用情况，降低质量是可以接受的。Fauconneau 提出了 DirectX 11 纹理压缩格式的 SIMD 实现。

### 程序纹理 (Procedural Texturing)
给定纹理空间位置，执行图像查找是生成纹理值的一种方法。另一个办法是计算一个函数，从而产生程序纹理（procedural texture）。

尽管程序纹理通常在脱机渲染的应用程序中使用，而图像纹理在实时渲染中更为常见。但这是由于现代 GPU 中图像纹理化硬件的极高效率造成的，它可以在一秒钟内执行数十亿次纹理访问。但是，GPU 体系结构正在朝着更低廉的计算和（相对）更昂贵的内存访问发展。这些趋势已使程序纹理在实时应用程序中得到了更多的使用。

考虑到体积图像纹理的高昂的存储成本，体积纹理对于程序纹理方法来说特别有吸引力。我们可以通过多种技术来合成这样的纹理。最常见的方法之一是使用一个或多个噪声函数来生成值。

噪声函数通常在两个连续的二次方频率（称为八度，octaves）上采样。每个八度都有权重，通常随着频率的增加而降低，这些加权样本的总和称为湍流函数（turbulence function）。

由于计算噪声函数的成本，通常会预先计算三维阵列中的晶格点，并将其用于内插纹理值。有多种使用颜色缓冲区混合来快速生成这些数组的方法。

Perlin 提出了一种快速，实用的方法来对该噪声函数进行采样，并展示了一些用途。Olano 提供了噪声生成算法，允许在存储纹理和执行计算之间进行权衡。McEwan等。开发了无需任何查找即可在着色器中计算经典噪声（classic noise）和 Simplex 噪声（simplex noise）的方法，并且提供了源代码。Parberry 使用动态编程在多个像素上摊销计算，以加快噪声计算。Green 提供了一种更高质量的方法，但是对于交互级的应用程序，它意味着更多的开销。Cook 和 DeRose 提出了另一种表示形式，称为小波噪声，它避免了走样问题，而成本仅增加了一点点。Liu 等使用各种噪声函数来模拟不同的木材纹理和表面光洁度。

其他程序化方法也是可行的。例如，通过测量从每个位置到散布在空间中的一组“特征点”之间的距离来形成细胞纹理。以各种方式（例如更改颜色或着色法线）映射所得到的最接近距离，可以创建一些看起来像细胞，石板，蜥蜴皮和其他自然纹理的图案。Griffiths 讨论了如何有效地找到最近邻并在 GPU 上生成蜂窝状纹理。

程序纹理的另一种类型是物理模拟或其他交互过程的结果，例如水波纹或扩展裂缝。在这种情况下，程序纹理可以对动态条件做出有效的、无限的变化。

当生成程序化二维纹理时，参数化问题可能比创作的纹理面临更大的困难，在创作的纹理中，可以手动修改或解决拉伸或接缝伪像。一种解决方案是通过将纹理直接合成到表面上来完全避免参数化。在复杂的表面上执行此操作在技术上具有挑战性，并且是研究的活跃领域。

反走样的程序纹理与反走样的图像纹理相比既困难又容易。一方面，诸如 mipmapping 之类的预计算方法不可用，这给程序员带来了负担。另一方面，程序纹理的开发者具有有关纹理内容的“内部信息”，因此可以对其进行调整以避免走样。对于通过对多个噪声函数求和而创建的程序纹理尤其如此。每个噪声函数的频率都是已知的，因此可以丢弃任何会引起走样的频率，从而在实际上降低了计算成本。

### 纹理动画 (Texture Animation)
应用于表面的图像不必是静态的。例如，视频源就可以用作逐帧变化的纹理。

纹理坐标也不必是静态的。应用程序设计人员可以在网格的数据本身中，或通过应用在顶点或像素着色器中的函数，在帧与帧之间显式地更改纹理坐标。想象一下，假设我们已经对瀑布进行了建模，并用看起来像落水的图像对其进行了纹理处理。我们假定 v 坐标是流向。为了使水运动，必须在每个连续帧的 v 坐标中减去一个量。从纹理坐标中减去的效果就是使纹理本身看起来向前移动。

通过将矩阵变换应用于纹理坐标可以创建更精细的效果。除了平移之外，还允许进行线性变换，例如缩放，旋转和剪切，图像扭曲（image warping）和变形变换（morphing transforms）以及广义投影（generalized projections）。通过在CPU或着色器中应用功能，可以创建更多精致的效果。

通过使用纹理混合技术，可以实现其他动画效果。例如，通过从大理石质地开始并以肉色进行褪色，可以使雕像变为活物。

### 材质映射 (Material Mapping)
纹理的常见用途是修改影响着色方程的材质属性。现实世界中的对象通常具有在其表面上变化的材质属性。为了模拟此类对象，像素着色器可以从纹理读取值，并在计算着色方程之前使用它们修改材质参数。最常被纹理修改的参数是表面颜色。这种纹理称为反照率颜色图（albedo color map）或漫反射颜色图（diffuse color map）。但是，可以通过纹理修改任何参数：替换，相乘或以其他方式更改它。

<center><img width="80%" src="CG/RTR/163.png"/></center>
<center>金属砖和砂浆。右侧是表面颜色，粗糙度（较浅）的凹凸贴图和凹凸贴图高度（较浅）的纹理</center>

在材质中纹理的使用可以更进一步。代替修改方程式中的参数，可以使用纹理来控制像素着色器本身的流（flow）和功能。通过使一种纹理指定表面的哪些区域具有哪种材质，可以将具有不同着色方程式和参数的两种或多种材质应用于表面，从而为每种材质执行不同的代码。例如，具有一些生锈区域的金属表面可以使用纹理来指示生锈的位置，根据纹理查找有条件地执行着色器的生锈部分，否则执行闪亮的金属着色器。

着色模型输入（例如表面颜色）与从着色器输出的最终颜色具有线性关系。因此，可以使用标准技术对包含此类输入的纹理进行滤波，并避免走样。包含非线性着色输入（例如粗糙度或凹凸贴图）的纹理需要多加注意，以避免出现走样。着色方程的滤波技术可以改善此类纹理的结果。

### 透明映射 (Alpha Mapping)
使用 alpha 混合或 alpha 测试可以将 alpha 值用于许多效果，例如有效地渲染树叶，爆炸和远处的物体，这仅仅是列举的一小部分。本节讨论了将纹理与 Alpha 结合使用的方法，并指出了各种限制和解决方案。

一种与纹理相关的效果是贴花（decaling）。例如，假设你想在茶壶上放一朵花的图片。你不想要整个图片，而只想要花所在的部分。通过将 0 的 alpha 分配给纹理元素，可以使其透明，从而使其无效。因此，通过正确设置贴花纹理的 Alpha，您可以将贴图替换或混合基础表面。通常，将夹取匹配函数与透明边框一起使用，以将贴花的单个复制（相对于重复纹理）应用于表面。

<center><img width="80%" src="CG/RTR/164.png"/></center>
<center>一种实现贴花的方法。首先使用场景渲染帧缓冲区，然后渲染一个框，对于框内的所有点，贴花纹理都投影到帧缓冲区的内容上。最左边的纹理元素是完全透明的，因此不会影响帧缓冲区。黄色纹理像素是不可见的，因为它将被投影到表面的隐藏部分上</center>

一个与 Alpha 的相似的应用是制作剪切图（cutouts）。假设您制作了灌木的贴花图像，并将其应用于场景中的矩形。其原理与贴花的原理相同，除了不与下层表面齐平外，灌木丛会绘制在其背后的任何几何形状的顶部。这样，可以使用单个矩形来渲染具有复杂轮廓的对象。

在灌木丛的案例中，如果围绕它旋转相机观察，则会露馅，因为这个灌木丛没有厚度。一种解决方法是复制此灌木丛矩形并将其沿树干旋转 90 度。这两个矩形构成了廉价的三维灌木丛，有时也称为“交叉树”（cross tree），从地面上看时，这种错觉相当有效。

将 alpha 贴图和纹理动画结合使用，可以产生令人信服的特殊效果，例如闪烁的火炬，植物生长，爆炸和大气效果。

有几种使用 alpha 贴图渲染对象的选项。Alpha 混合允许使用带小数的透明度值，该值可以对对象边缘以及部分透明的对象进行反走样。但是，alpha 混合需要在不透明的三角形之后以从后到前的顺序渲染混合的三角形。一个简单的交叉树是两个剪切纹理（cutout textures）的示例，其中没有正确的渲染顺序，因为每个四边形位于另一个的前面。即使在理论上可以排序并获得正确的顺序，通常这样做效率也不高。例如，一块田地可能有成千上万个使用剪切图的草叶。每个网格物体可以由许多单独的叶片合成。因此，明确地分出每个叶片是不切实际的。

渲染时，可以通过几种不同的方法来改善此问题。一种是使用 Alpha 测试，它是有条件地丢弃像素着色器中具有低于给定阈值的Alpha 值的片元的过程。具体做法如下：

```if (texture.a < alphaThreshold) discard;```

其中 texture.a 是纹理查找中的 alpha 值，参数 alphaThreshold 是用户提供的阈值，该阈值确定哪些片元将被丢弃。因为透明片元被丢弃了，所以该二进制的可见性测试使三角形可以以任何顺序呈现。我们通常希望对 alpha 值为 0.0 的任何片元执行此操作。丢弃完全透明的片元还有一个额外的好处，就是可以节省进一步的着色器处理和合并的成本，还可以避免将 z 缓冲区中的像素错误地标记为可见。

对于剪切图，我们通常将阈值设置为高于 0.0，例如 0.5 或更高，然后采取进一步的步骤，然后完全忽略 alpha 值，而不是将其用于混合。这样做可以避免乱码。但是，由于只有两个级别的透明度（完全不透明和完全透明）可用，因此图像质量较低。另一种解决方案是对每个模型执行两次遍历，第一次遍历针对实体剪切图，写入 z 缓冲区，另一次遍历针对半透明样本，并且不写入 z 缓冲区。

!> alpha 测试还有两个其他问题，即过度的放大(magnification) 和过度的缩小(minification) 。

当将 alpha 测试与 mipmapping 一起使用时，如果处理方式不同，效果可能令人难以信服。下图的顶部显示了一个示例，其中树的叶子变得比预期的更加透明。这可以用一个例子来解释。假设我们有一个具有四个 alpha 值的一维纹理，即（0.0，1.0，1.0，0.0）。通过平均，下一个 mipmap 级别变为（0.5，0.5），然后最高级别为（0.5）。现在，假设我们使用 α_t = 0.75。访问 mipmap 级别 0 时， 4 个纹理像素中的 1.5 个将通过丢弃测试。但是，访问下两个级别时，由于 0.5 <0.75，所有内容将被丢弃。

<center><img width="80%" src="CG/RTR/165.png"/></center>
<center>顶部：带有mipmapping的alpha测试，无任何更正。底部：alpha测试，其alpha值根据覆盖范围重新调整</center>

<center><img width="80%" src="CG/RTR/166.png"/></center>
<center>上方图片是具有混合功能的叶子图案的不同 mipmap 级别，较高的级别则进行缩放以提高可见性。在下方图片，显示mipmap，将使用 0.5 的 alpha 测试对其进行处理，以显示对象后退时如何减少像素</center>

Castano 提出了一种在 mipmap 创建期间的简单解决方案，效果很好。对于 mipmap 级别 k，覆盖率 c_k 被定义为：

<center><img width="40%" src="CG/RTR/167.png"/></center>

其中 n_k 是在 mipmap 级别 k 中的纹理像素数量，α（k，i）是在像素 i 处来自 mipmap 级别 k 的 alpha 值，而 α_t 是用户提供的 alpha 阈值。

在这里，我们假设 α（k，i）> α_t的结果为1，否则为0。注意，k = 0 表示最低的 mipmap 级别，即原始图像。然后，对于每个 mipmap 级别，我们找到一个新的 mipmap 阈值 α_k，而不是使用 α_t，以使 c_k 等于 c_0（或尽可能接近）。这可以使用二进制搜索来完成。最后，在 mipmap 级别 k 中所有纹理像素的 alpha 值按 α_t/α_k 缩放。

Wyman 和 McGuire 提出了另一种解决方案，其中理论上将公式 6.9 中的代码行替换为：

```if (texture.a < random()) discard;```

随机函数在 [0,1] 中返回一个统一值，这意味着平均而言，它将得出正确的结果。例如，假设纹理查找的 alpha 值为 0.3，则片元将以 30％ 的机会被丢弃。这是一种随机透明的形式，每个像素只有一个样本。在实践中，将随机函数替换为哈希函数，以避免时间和空间上的高频噪声：

```
float hash2D(x,y) { return fract(1.0e4 * sin(17.0 * x + 0.1 * y) * (0.1 + abs(sin(13.0 * y + x)))); }
```

通过对上述函数的嵌套调用来形成三维哈希，即 float hash3D（x，y，z）{return hash2D（hash2D（x，y），z）; }，返回[0,1）中的数字。哈希的输入是对象空间坐标除以对象空间坐标的最大屏幕空间导数（x 和 y），然后进行夹取（clamping）操作。需要进一步注意以获得 z 方向运动的稳定性，并且该方法最好与时间性反走样技术（temporal antialiasing techniques）结合使用。该技术会随着距离的增加而逐渐淡入，因此在关闭时我们根本不会获得任何随机效果。这种方法的优点是每个片元平均而言都是正确的，而 Castano 的方法为每个 mipmap 级别创建单个α_k。但是，此值可能会在每个 mipmap 级别上有所不同，这可能会降低质量并需要美术人员干预。

?> Alpha 测试会在放大下显示涟漪伪像（artifacts），可以通过将 Alpha 贴图预先计算为距离场来避免。

Alpha 覆盖（Alpha to coverage）和类似的功能半透明自适应反走样（transparency adaptive antialiasing）会获取片元的透明度值，并将其转换为覆盖像素内的多少样本。这个想法就像 5.5 节中描述的屏幕门透明，但这是在子像素级别。想象每个像素有四个样本位置，并且一个片元覆盖了一个像素，但是由于剪切图纹理的缘故，它的透明度为 25％（不透明度为 75％）。Alpha 覆盖模式使片元变得完全不透明，但仅覆盖了四个样本中的三个。例如，此模式可用于重叠草叶的剪切图纹理，例如。由于每个绘制的样本都是完全不透明的，因此最接近的叶状体将沿其边缘以一致的方式将对象隐藏在其后方。由于 Alpha 混合功能已关闭，因此无需排序即可正确地混合半透明边缘像素。

Alpha to Coverage 是反走样 Alpha 测试的好方法，但是在 Alpha 混合时会显示伪像。例如，两个具有相同 alpha 覆盖率的 alpha 混合片元将使用相同的子像素图案，这意味着一个片元将完全覆盖另一个片元，而不是与其混合。Golus讨论了使用 fwidth（）着色器指令为内容提供更清晰的边缘。

对于 alpha 贴图的各种使用方法，重要的是要了解双线性插值如何影响颜色值。想象一下彼此相邻的两个纹理像素：rgbα=（255,0,0,255）是纯红色，而它的近邻 rgbα=（0,0,0,2）是黑色，几乎完全透明。正好位于两个纹理像素中间的位置的rgbα 是多少？ 如果简单进行插值会得出（127,0,0,128），所得的 rgb 值呈“暗红色”。但是，真正的结果实际上并不是暗的，它是一个纯红色，并且它已预乘其 Alpha。

如果要插值 Alpha 值，则为了确保正确的插值，需要保证在插值之前，已被插值的颜色已经由 Alpha 进行了预乘。例如，假设我们将几乎透明的近邻设置为 rgbα=（0,255,0,2），即给出一些绿色的微小色调。并且该颜色不会与 Alpha 预乘，那么在插值时会得到结果（127,127,0,128）—— 绿色的微小色调突然将结果变为（预乘）黄色样本，这是不对的。现在先进行预乘，此近邻纹理像素的预乘版本为（0,2,0,2），在插值后，这就给出了合适的预乘结果（127,1,0,128）。这个结果更为正确，最终的预乘颜色主要是红色，而绿色则难以察觉。

!> 双线性插值后得出的预乘结果可能导致贴花和剪切对象周围出现黑色边缘。“较暗”的红色结果被其余管线视为未相乘的颜色，并且条纹变为黑色。

?> 即使使用 Alpha 测试，此效果仍然可见。最好的办法是在完成双线性插值之前进行预乘。

### 凹凸映射 (Bump Mapping)
一个对象的细节可以分为三个等级：覆盖许多像素的宏观特征（macro-features），横跨几个像素的细观特征（meso-features），和实质上小于一个像素的微观特征（micro-features）。这些分类在某种程度上是流动的，因为在动画或交互式操作期间，观看者可能在不同距离观察到同一对象。

宏观几何由顶点和三角形或其他几何图元表示。创建三维角色时，通常以宏观尺度对肢体和头部进行建模。微观的几何结构被封装在着色模型中，该着色模型通常在像素着色器中实现，并使用纹理贴图作为参数。所用的着色模型可模拟表面微观几何结构的相互作用，例如，发光物体在微观上是光滑的，而漫射表面在微观上是粗糙的。角色的皮肤和衣服似乎具有不同的材质，因为它们使用不同的着色器，或者至少使用这些着色器中的不同参数。

细观几何结构描述了宏观与微观尺度之间的一切。它包含的细节过于复杂，无法使用单个三角形进行有效渲染，但是对于观察者来说，它足以区分表面曲率在几个像素上的变化。例如角色脸上的皱纹，肌肉结构细节以及衣服上的褶皱和接缝都是细观尺度的。细观尺度建模通常使用一类方法，它们被统称凹凸映射技术。它们在像素级别调整着色参数，以使观看者感觉到远离基本几何结构的微小干扰，而基本几何结构实际上保持平坦。不同种类的凹凸映射之间的主要区别是它们如何表示细节特征。其变量包括现实级别和细节特征的复杂性。例如，数字艺术家通常将细节雕刻到模型中，然后使用软件将这些几何元素转换为一种或多种纹理，例如凹凸纹理和缝隙变暗的纹理。

布林（Blinn）在 1978 年提出了在纹理中编码细观尺度细节的想法。他观察到，如果在着色过程中用稍微受扰动的表面法线代替真实的表面，则表面似乎具有小范围的细节。他将描述表面法线微扰动的数据存储在数组中。

这里的关键思想是，我们不使用纹理来更改照明方程式中的颜色分量，而是访问纹理来修改表面法线。模型表面的几何法线实际上保持不变。我们仅修改照明方程式中使用的法线。此操作没有物理等效项。我们在曲面法线上执行更改，但曲面本身在几何意义上保持平滑。就像每个顶点具有法线一样，它给人一种幻觉，即三角形之间的表面很光滑。修改每个像素的法线会改变三角形表面本身的视觉感知，但不会改变其几何结构。

对于凹凸映射，法线必须相对于某个参考系改变方向。为此，我们将切线框架（tangent frame，也称为切线空间基底 ，tangent-space basis）存储在每个顶点上。此参考系用于将灯光转换到表面位置的空间（反之亦然），以计算干扰法线的效果。除了顶点法线外，在多边形表面上应用了法线贴图的情况下，我们还存储了切线（tangent）和副切线向量（bitangent vectors）。双切线向量也被错误地称为副法线向量（binormal vector）。

切线和副切线向量表示法线贴图本身在对象空间中的轴，因为目标是将光照转换为相对于贴图的光照。

<center><img width="80%" src="CG/RTR/168.png"/></center>
<center>展示了一个球形三角形，其切线框显示在每个角上。形状像圆球和圆环的，具有自然的切线空间基础，正如圆环上的纬度和经度线所示</center>

法线 n，切线 t 和切线 b 这三个向量形成一个基本矩阵：

<center><img width="30%" src="CG/RTR/169.png"/></center>

这个矩阵有时缩写为TBN，它将光的方向（对于给定的顶点）从世界空间转换为切线空间 这些向量不必真正彼此垂直，因为法线贴图本身可能会变形以适合曲面。但是，非正交的基底会导致纹理倾斜，这可能意味着需要更多的存储空间，并且可能会对性能产生影响，即矩阵无法通过简单的转置来反转。

?> 节省内存的一种方法是仅在顶点存储切线和副切线，并取它们的叉积来计算法线。但是，只有在矩阵的手性（handedness）始终相同的情况下，此技术才有效。

### 布林的方法 (Blinn’s Methods)
布林最初的凹凸映射方法在纹理的每个纹理像素上存储两个有符号的值b_u和b_v。这两个值对应于沿 u 和 v 图像轴改变法线的量。即，这些通常是双线性插值的纹理值用于缩放垂直于法线的两个向量。将这两个向量添加到法线以更改其方向。两个值 和  描述了曲面在该点面向哪个方向。这种类型的凹凸贴图纹理称为偏移向量凹凸贴图（offset vector bump map）或偏移贴图（offset map）。

<center><img width="80%" src="CG/RTR/170.png"/></center>
<center>在左侧，法线向量 n 通过从凹凸纹理获取的（b_u，b_v）值在 u 方向和 v 方向上进行修改，得到 n'（未归一化）。右侧显示了一个高度场及其对着色法线的影响。可以在高度之间对这些法线插值，以获得更平滑的外观</center>

表示凹凸的另一种方法是使用高度场（heightfield）来修改表面法线的方向。每个单色纹理值代表一个高度，因此在纹理中，白色是高区域，黑色是低区域（反之亦然）。这是首次创建或浏览凹凸贴图时使用的常见格式，它也是 1978 年由 Blinn 引入的。heightfield用于导出 u 和 v 符号值，类似于第一种方法中使用的值。这是通过获取相邻列之间的差异来获得 u 的斜率以及相邻列之间的差异来获取v来完成的。一种变体是使用 Sobel 滤波器，该滤波器赋予直接的近邻以更大的权重。

### 法线映射 (Normal Mapping)
凹凸贴图的常见方法是直接存储法线贴图。其算法和结果在数学上与布林的方法相同； 只有存储格式和像素着色器计算会更改。

法线图编码映射到 [-1,1] 的（x，y，z），例如，对于 8 位纹理，x轴值 0 表示 -1.0，255 表示 1.0。颜色 (128,128,255)（浅蓝色）将代表所示颜色映射的平坦表面，即法线 (0,0,1)。

法线图的表示最初是作为世界空间法线图引入的，然而这在实践中很少使用。对于这种类型的贴图，扰动非常简单：在每个像素处，从贴图中检索法线，并将其与光的方向一起直接使用，以计算表面上该位置的着色。还可以在物体空间中定义法线贴图，以便可以旋转模型，之后法线仍然有效。但是，世界和物体空间的表示都将纹理绑定到特定方向的特定几何形状，这限制了纹理的重复使用。

取而代之的是，我们通常在切线空间（即相对于曲面本身）中检索扰动的法线。这种方法允许表面变形以及正常纹理的最大重复使用。切线空间法线贴图也可以很好地压缩，因为 z 分量的符号（与不受扰动的表面法线对齐的符号）通常可以假定为正值。

<center><img width="80%" src="CG/RTR/171.png"/></center>
<center>在类似游戏的场景中使用的法线贴图凹凸映射的示例。左上方：不使用右侧的两个法线贴图。左下方：已使用法线贴图。右：法线贴图</center>

与颜色纹理的滤波相比，法线贴图的滤波是一个难题。通常，法线颜色与着色颜色之间的关系不是线性的，因此标准滤波方法可能会导致令人反感的走样。想象一下看楼梯由闪亮的白色大理石块制成。在某些角度下，楼梯的顶部或侧面可以捕捉光线并反射出明亮的镜面高光。但是，楼梯的平均法线为 45 度角。它会从与原始楼梯完全不同的方向捕获亮点。如果在没有正确滤波的情况下渲染具有锐利的镜面高光的凹凸贴图，当采样的位置恰好时，高光闪烁就会出现，从而产生分散注意力的火花效果。

Lambertian 曲面是一种特殊情况，其中法线贴图对着色几乎具有线性影响。Lambertian 着色几乎完全是一个点积，它是线性运算。平均一组法线并对其结果执行点积等效于对具有法线的单个点积进行平均：

<center><img width="40%" src="CG/RTR/172.png"/></center>

请注意，平均向量在使用前未归一化。上式表明，对于 Lambertian 曲面，标准滤波和 mipmap 几乎可以产生正确的结果。由于 Lambertian 着色方程不是点积，因此结果不是很正确。它是一个钳制的（clamped）点乘积 —— max（l·n，0）。钳制操作使其变为非线性。这将使表面过于暗淡，以至于无法直视光的方向，但是在实践中，这通常能够被接受。需要警示的是，通常用于法线贴图的某些纹理压缩方法（如从其他两个法线重构 z 分量）不支持非单位长度的法线，因此使用未归一化的法线贴图可能会带来压缩上的困难。

?> 在非 Lambertian 曲面的情况下，可以通过将着色方程的输入作为一组滤波，而不是单独对法线贴图滤波来产生更好的结果。

最后，从高度图 h（x，y）导出法线图可能是有用的。按下面的步骤进行。首先，使用中心差为 x 来计算 x 和 y 方向上的导数的近似值：

<center><img width="70%" src="CG/RTR/173.png"/></center>

然后，在纹理像素（x，y）处的未归一化法线为：

<center><img width="35%" src="CG/RTR/174.png"/></center>

?> 这里必须注意纹理的边界

通过使用凹凸映射，能够将阴影投射到其自身的表面上，可以使用“水平贴图” （horizon mapping）进一步增强法线贴图。这是通过预先计算其他纹理来实现的，每个纹理与沿着表面平面的方向相关联，并为每个纹理像素存储该方向上的地平线角度。

### 视差映射 (Parallax Mapping)
凹凸和法线贴图的问题在于，凹凸永远不会随视角移动位置，也不会相互阻挡。例如，如果你以真实的角度看一眼真实的砖墙，你将看不到砖之间的砂浆。墙壁的凹凸贴图永远不会显示这种类型的遮挡，因为它只会改变法线。最好的办法是让凸块实际影响在每个像素处渲染表面上的哪个位置。

视差映射（parallax mapping）的概念由 Kaneko 于 2001 年提出，并由 Welsh 进行了完善和推广。视差指的是当观察者移动时，对象的位置相对于彼此移动的想法。当观察者移动时，凹凸应该看起来具有高度。视差映射的关键思想是通过检查发现的可见物体的高度，来对像素中应该看到的物体进行有根据的猜测。

<center><img width="80%" src="CG/RTR/175.png"/></center>
<center>我们想达成的效果在左侧：从视图向量刺穿高度场的位置找到表面上的实际位置。视差贴图通过获取矩形上某个位置的高度并使用它来查找新位置 p_adj 来进行一阶近似</center>

对于视差贴图，将凹凸数据存储在高度场纹理中。在给定像素处查看表面时，将在该位置检索高度场值，并将其用于移动纹理坐标以检索表面的不同部分。偏移量基于所获取的高度和眼睛与表面的角度。高度场值要么存储在单独的纹理中，要么打包为其他纹理的未使用的颜色或 Alpha 通道（将不相关的纹理打包在一起时必须格外小心，因为这会对压缩质量产生负面影响）。在用于移动坐标之前，将对高度字段值进行缩放和偏置。

比例尺决定了高度场要在表面上方或下方延伸的高度，并且偏差提供了不发生任何偏移的“海平面”高度。给定纹理坐标位置 p，调整后的高度场高度 h 和具有高度值 v_z 和水平分量 v_xy 的归一化视图向量 v，新的视差调整后的纹理坐标 p_adj 为：

<center><img width="25%" src="CG/RTR/176.png"/></center>

请注意，与大多数着色方程式不同，此处执行计算的空间很重要——视图向量必须在切线空间中。

尽管是一个简单的近似值，但如果凸块高度的变化相对较慢，则这种移位在实践中效果很好。这样，附近的相邻纹理像素的高度大约相同，因此使用原始位置的高度作为新位置的高度估计的想法是合理的。但是，此方法在浅视角下会露馅。当视图向量接近表面的水平线时，高度变化较小会导致纹理坐标偏移较大。这近乎失效，因为检索到的新位置与原始曲面位置几乎没有高度相关性。

为了改善这个问题，Welsh 引入了偏移限制的思想。想法是将移动量限制为永远不大于获取的高度。公式是：

<center><img width="25%" src="CG/RTR/177.png"/></center>

请注意，该公式的计算速度比原始公式要快。从几何上讲，这种解释是，高度定义了一个半径，位置不能超出该半径。

<center><img width="80%" src="CG/RTR/178.png"/></center>
<center>在视差偏移量限制中，偏移量最多偏离原始位置的高度，以虚线圆弧表示。灰色虚线偏移是原始的结果，黑色虚线偏移显示有限结果。右边是用该技术渲染的墙</center>

由于v_z接近1，因此在陡峭的角度（面对面）时，该公式与原始公式几乎相同。在较小的角度时，偏移的作用受到限制。从视觉上看，这使得在浅角度的凹凸感减小，但是这比纹理的随机采样好得多。游泳时，随着视图的改变，纹理也存在问题，或者对于立体渲染，观看者同时感知到两个必须给出一致的深度提示的视点。即使有这些缺点，具有偏移限制的视差映射也只花费了一些额外的像素着色器程序指令，并且相对于基本法线映射提供了可观的图像质量改进。hishkovtsov 通过在凹凸贴图法线方向上移动估计的位置来改善视差遮挡的阴影。

### 视察遮蔽映射 (Parallax Occlusion Mapping)
凹凸贴图不会基于 heightfield 修改纹理坐标； 它仅在某个位置改变法线着色。假设像素的高度与其相邻像素的高度大致相同，视差贴图则提供了高度场效果的简单近似值。然而这个假设可能会很容易露馅。凹凸贴图可能永远不会相互遮挡，也不会蒙上阴影。我们想要的是在像素处可见的东西，即视图向量首先与高度场相交的地方。

为了以更好的方式解决此问题，一些研究人员建议沿视图向量使用光线步进（ray marching），直到找到一个（近似）交点。这项工作可以在像素着色器中完成，高度数据可以作为纹理访问。我们将对这些方法的研究归纳为视差映射技术的子集，该技术以一种或另一种方式利用光线步进。

这些类型的算法除一些其他名称外，通常被称为视差遮挡映射（parallax occlusion mapping，POM）或浮雕映射（relief mapping）方法。其关键思想是首先沿着投影向量测试固定数量的高度场纹理样本。这通常会在观察角度为视线生成更多样本，以免错过最近的交点。检索沿射线方向的每个三维位置，将其转​​换为纹理空间，然后进行处理以确定其是否在高度场之上或之下。一旦找到高度场下方的样本，则其下方的数量以及之前一个样本上方的数量将用于查找相交位置。然后该位置会被用来应用附加的法线贴图，颜色贴图和任何其他纹理，以对表面进行着色。多层高度场可用于产生悬垂（overhangs），独立的重叠表面以及两侧浮雕映射的假物体（impostors）。高度场跟踪方法也可以用于使凹凸的表面在自身上投射阴影，包括硬阴影和软阴影。

<center><img width="70%" src="CG/RTR/179.png"/></center>
<center>代表观察者的绿色射线投射到表面上，以固定的时间间隔（紫色点）进行采样，并获取高度。该算法找到了观察射线与黑色线段的第一个交点，近似于弯曲的高度场</center>

<center><img width="80%" src="CG/RTR/180.png"/></center>
<center>与光线步进（右）相比，没有光线步进的视差贴图（左）。不使用光线步进时，立方体的顶部会变平。使用光线步进时，也会产生自阴影效果</center>

关于这个话题有很多文献。尽管所有这些方法都沿着光线步进，但存在一些差异。我们可以使用简单的纹理来获取高度，但是也可以使用更高级的数据结构和更高级的根查找方法。一些技术可能涉及着色器丢弃像素或写入深度缓冲区，这可能对性能产生损害。下面我们总结了一大堆方法，但是请记住，随着 GPU 的发展，最佳方法也会随之发展。这种“最佳”方法取决于光线步进期间的内容和完成的步数。

确定两个常规样本之间的实际交点的问题是根查找问题（root-finding problem）。实际上，高度场更多地被视为深度场，其矩形的平面定义了表面的上限。这样的话，平面上的初始点会在高度场上方。在找到高度场的上方的最后一个点和下方的第一个点之后，Tatarchuk 使用割线方法的单个步骤来找到一个近似解。Policarpo 等在发现的两个点之间使用二分法搜索，以在更近的交叉点上进行磨练（hone in）。Risser等人通过使用割线方法进行迭代来加快收敛速度。折衷的方案是可以并行地进行常规采样，尽管迭代方法仅需更少的整体纹理访问，但是必须等待结果并执行较慢的依赖纹理提取。这种蛮力方法似乎在整体上表现良好。

以足够高的频率对高度场进行采样是至关重要的。McGuire 和 McGuire 提出对 mipmap 查找进行偏置（biasing），并使用各向异性的 mipmap 以确保对高频高度场（例如代表尖峰或头发的高频高度场）进行正确采样。人们还可以用比法线贴图更高的分辨率存储高度场纹理。最后，某些渲染系统甚至不存储法线贴图，而是更喜欢使用交叉滤镜（cross filter）从高度场中动态导出法线。

提高性能和采样精度的另一种方法是，首先不以固定的间隔对高度场进行采样，而是尝试跳过中间的空白空间。Donnelly 将高度场预处理为一组体素，在每个体素中存储它与高度场表面的距离。以这种方式，可以快速跳过中间的空间，但代价是每个高度场的存储空间会更大。Wang 等使用五维位移映射方案来保持从所有方向和位置到表面的距离。这种方法将会允许复杂的曲面，自遮蔽和其他效果，但是要消耗大量内存。Mehra 和 Kumar 出于类似目的使用定向距离图。Dummer 引入了圆锥阶跃映射（cone step mapping）的概念，而 Policarpo 和 Oliveira 对其进行了改进。这里的概念是还要为每个高度场位置存储一个圆锥半径（cone radius）。该半径定义了射线的间隔，在该间隔中与高度场最多有一个交点。该属性允许沿射线快速跳过而不会丢失任何可能的交点，但是代价是需要依赖纹理读取。另一个缺点是创建圆锥阶跃贴图（cone step map）所需的预计算，这使得该方法无法用于动态更改高度场。Schroders和Gulik 提出了四叉树浮雕映射（quadtree relief mapping），这是一种在遍历期间跳过体积的分层方法。Tevs等使用 “最大mipmap” 来进行跳过，同时将预计算成本降至最低。Drobot 还使用存储在 mipmap 中的类似四叉树的结构来加速遍历，并提出了一种在不同的高度场之间进行混合的方法，其中一种地形类型（terrain type）会转换为另一种地形类型。

上述所有方法的一个问题是，立体的幻觉会沿着对象的轮廓边缘逐渐分崩离析，最后会显示出原始表面的平滑轮廓。这里的关键思想是渲染的三角形应该定义哪些像素由像素着色器程序计算，而不是表面实际所在的位置。另外，对于弯曲表面，轮廓问题变得更加复杂。Oliveira 和 Policarpo 描述和开发了一种方法，该方法使用了二次轮廓逼近技术（ quadratic silhouette approximation technique）。Jeschke等和Dachsbacher 等都给出了一种更通用，更鲁棒的方法（并回顾了以前的工作）来正确处理轮廓和曲面。这在最初是由 Hirche进行探索，其总体思想是向外挤出网格中的每个三角形并形成一个棱镜。渲染此棱镜时会强制计算可能会出现高度场的所有像素。这种方法称为外壳映射（shell mapping），因为扩展的网格在原始模型上形成了一个单独的外壳。通过保留棱镜与光线相交时的非线性特性，可以实现高度场的无伪像渲染，尽管这个计算成本很高。下图显示了这种技术的令人印象深刻的用法。

<center><img width="80%" src="CG/RTR/181.png"/></center>
<center>视差遮挡贴图（也称为浮雕贴图），用于使路面上的石头看起来更逼真。路面实际上是一组应用了高度场的简单三角形</center>

### 纹理灯光 (Textured Lights)
<center><img width="80%" src="CG/RTR/182.png"/></center>
<center>投射的纹理光。纹理被投影到茶壶和地面上，并用于在投影视锥中调整光的分布（在视锥外设置为0）</center>

纹理还可以用于为光源增加视觉丰富度，并允许复杂的强度分布或聚光灯功能。对于所有照明都限于圆锥形或截头圆锥形的灯，可以使用投影纹理来调整光照强度。这样可以形成聚光灯，图案光，甚至“幻灯机”效果。

对于不限于视锥体但可以在所有方向照亮的灯光，可以使用立方体贴图（cubemap）来调整光照强度，而不是使用二维投影纹理。一维纹理可用于定义任意距离衰减函数。结合二维角度衰减图，可以考虑复杂的体积照明模式。更普遍的可能是使用三维（体积）纹理控制光的衰减。这种方法允许任意数量的效果，包括光束效果（light beams）。此技术会占用大量内存（所有体积纹理都是如此）。如果光线的影响体积是沿三个轴对称的，那么就可以通过将数据镜像到每个八分之一球体中来将内存占用量减少八倍。

可以将纹理添加到任何灯光类型，以启用其他视觉效果。带纹理的灯光使艺术家可以轻松控制照明，而艺术家可以简单地编辑所使用的纹理。


## Chapter 7 - Shadows - 阴影
> 介绍了目前比较流行的快速计算阴影的算法


## Chapter 8 - Light and Color - 光与颜色
> 在实现基于物理的渲染之前，我们首先需要了解如何去量化光和颜色。在物理渲染过程完成后，我们需要将得到的数量值显示出来。<br>本章涵盖两个话题：计算屏幕参数（accounting for the properties of the screen）和观察环境（viewing environment）


## Chapter 9 - Physically Based Shading - 基于物理的着色
> 本章从物理现象背后的规律讲起，涵盖大量的渲染材质的模型，并且会在最后提出一个方法，此方法可以用来混合材质，对材质进行过滤以避免锯齿（走样），并且保持原有的表面外观


## Chapter 10 - Local Illumination - 局部光照
> 本章探索了描绘更精细光源的算法。在表面着色时我们会考虑到光是由具有特别形状的物理对象所发射出的


## Chapter 11 - Global Illumination - 全局光照
> 模拟光源与场景之间多重交互的算法大大提升了图像的真实感。我们会讨论环境和方向光遮挡，在漫反射和高光表面上渲染全局光照效果的实现方法，另外还有一些有前景的统一方法


## Chapter 12 - Image-Space Eﬀects - 图像空间特效
> 图形硬件擅长快速的图像处理。本章首先会讨论图像滤波（Image filtering）和重投影技术（reprojection techniques），然后会探讨几种常用的后处理效果：镜头光晕（lens flares）、动态模糊（motion blur）和景深（depth of field）


## Chapter 13 - Beyond Polygons - 多边形之外
> 三角形（Triangles）并不总是描述对象的最快或最真实的方式。基于使用图像（images）、点云（point clouds）、体素（voxels）和其他采样集的交替表现都有其各自的优点


## Chapter 14 - Volumetric and Translucency Rendering - 体积和半透明渲染
> 本章将聚焦于体积材质呈现以及其与光源相互作用的理论与实践。模拟的范围将从大尺度的大气层效果（large-scale atmospheric effects）到细的头发纤维内的光线散射（light scattering）


## Chapter 15 - Non-Photorealistic Rendering - 非真实感渲染
> 试图使场景看起来更逼真（realistic）只是渲染场景方法中的一种而已。本章会探讨一下其他的渲染风格，如卡通阴影和水彩画效果。此外，线框（line）和文本（text）生成技术也会在本章讨论


## Chapter 16 - Polygonal Techniques - 多边形技术
> 几何数据来源广泛，有时需要进行修改以便渲染得快速、准确。本章将会从多方面介绍多边形数据的呈现和压缩


## Chapter 17 - Curves and Curved Surfaces - 曲线和曲面
> 更复杂的曲面表示提供了一些优势，例如能够在图像质量和渲染速度之间进行权衡、更紧凑的描绘以及平滑的曲面生成


## Chapter 18 - Pipeline Optimization - 管线优化
> 一旦应用程序运行并使用了高效的算法，就可以使用各种优化技术使其变得更快。本章讨论的主题是怎样找到性能优化瓶颈（bottleneck）并如何去解决它。此外，本章还讨论了多进程（Multiprocessing）的相关内容


## Chapter 19 - Acceleration Algorithms - 加速算法
> 本章涵盖了各种形式的剔除（Culling）和细节层次渲染（LOD, Level Of Detail）方法


## Chapter 20 - Eﬃcient Shading - 高效着色
> 场景中的大量灯光会大大降低性能。另外，在确定表面片元（Fragment）是否会显示之前就进行完全的着色计算，也是性能浪费的一大来源。本章探索了一系列的方法来消除低效的着色操作


## Chapter 21 - Virtual and Augmented Reality - 虚拟现实与增强现实
> 这些领域有着特殊的挑战和技术，要求高效、快速、稳定地生成真实的图像


## Chapter 22 - Intersection Test Methods - 相交测试方法
> 相交测试（Intersection testing）对于渲染、用户交互和碰撞检测非常重要。本章将深度涵盖一系列最有效的通用几何相交测试算法


## Chapter 23 - Graphics Hardware - 图形硬件
> 这里的重点是一些组件（Components），如颜色深度（color depth）、帧缓冲区（framebuffers）和基本架构类型（basic architecture types）


## Chapter 24 - The Future - 展望未来
> 猜猜看未来有啥？
